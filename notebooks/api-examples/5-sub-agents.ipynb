{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/vectara/example-notebooks/blob/main/notebooks/api-examples/5-sub-agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "# Vectara Sub-Agents: Building Modular AI Workflows\n",
    "\n",
    "This notebook demonstrates how to use Vectara's **sub-agents** capability to build modular, specialized AI workflows. Sub-agents allow a parent agent to delegate tasks to specialized child agents, enabling:\n",
    "\n",
    "- **Context isolation**: Each sub-agent maintains its own conversation history\n",
    "- **Specialized configuration**: Each sub-agent can have distinct instructions and tools\n",
    "- **Reusability**: Build once, invoke from any parent agent\n",
    "- **Parallel execution**: Run multiple sub-agents simultaneously\n",
    "- **Better performance**: Smaller, focused agents make fewer mistakes\n",
    "\n",
    "### Why Sub-Agents?\n",
    "\n",
    "When agents face complex, multi-step tasks, they often run into context window limits or need specialized capabilities. Consider a comprehensive research assistant that needs to:\n",
    "\n",
    "1. Analyze academic papers for theoretical foundations\n",
    "2. Search product documentation for implementation details\n",
    "3. Synthesize findings into actionable recommendations\n",
    "\n",
    "A single monolithic agent trying to handle all of this might:\n",
    "- Become confused between different instruction sets\n",
    "- Consume excessive context with domain-specific guidelines\n",
    "- Produce lower quality results due to competing priorities\n",
    "\n",
    "**Sub-agents solve this by delegation**: the parent agent orchestrates, while specialized sub-agents focus on their domains.\n",
    "\n",
    "We also demonstrate combining sub-agents with a **Lambda Tool** (API Payload Validator) that validates generated API code to catch hallucinations and ensure correctness before presenting to users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "This notebook assumes you've completed Notebooks 1-4:\n",
    "- Notebook 1: Created two corpora (ai-research-papers and vectara-docs)\n",
    "- Notebook 2: Ingested AI research papers and Vectara documentation\n",
    "- Notebook 3: Queried the data with various techniques\n",
    "- Notebook 4: Created agents that can search and reason across data\n",
    "\n",
    "Now we'll create a multi-agent system where specialized sub-agents handle domain-specific tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Corpus: tutorial-ai-research-papers\n",
      "Docs Corpus: tutorial-vectara-docs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Get credentials from environment variables\n",
    "api_key = os.environ['VECTARA_API_KEY']\n",
    "\n",
    "# Corpus keys from previous notebooks\n",
    "research_corpus_key = 'tutorial-ai-research-papers'\n",
    "docs_corpus_key = 'tutorial-vectara-docs'\n",
    "\n",
    "# Base API URL\n",
    "BASE_URL = \"https://api.vectara.io/v2\"\n",
    "\n",
    "# Common headers\n",
    "headers = {\n",
    "    \"x-api-key\": api_key,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "print(f\"Research Corpus: {research_corpus_key}\")\n",
    "print(f\"Docs Corpus: {docs_corpus_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 1: Create Specialized Sub-Agents\n",
    "\n",
    "We'll create three specialized agents that will serve as sub-agents:\n",
    "\n",
    "1. **Research Paper Analyst**: Expert at analyzing academic papers on RAG, embeddings, and retrieval\n",
    "2. **Documentation Expert**: Expert at finding implementation guidance from Vectara docs\n",
    "3. **Web Search Expert**: Expert at searching the web for current information and news\n",
    "\n",
    "Each agent has focused instructions and tools optimized for its domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### Sub-Agent 1: Research Paper Analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to delete and create agent\n",
    "def delete_and_create_agent(agent_config, agent_name):\n",
    "    \"\"\"Delete agent if it exists, then create a new one.\"\"\"\n",
    "    # Check if agent already exists and delete it\n",
    "    list_response = requests.get(f\"{BASE_URL}/agents\", headers=headers)\n",
    "\n",
    "    if list_response.status_code == 200:\n",
    "        agents = list_response.json().get('agents', [])\n",
    "        for agent in agents:\n",
    "            if agent.get('name') == agent_name:\n",
    "                existing_key = agent['key']\n",
    "                print(f\"Deleting existing agent '{agent_name}' ({existing_key})\")\n",
    "                delete_response = requests.delete(f\"{BASE_URL}/agents/{existing_key}\", headers=headers)\n",
    "                if delete_response.status_code == 204:\n",
    "                    print(f\"Deleted agent: {existing_key}\")\n",
    "                else:\n",
    "                    print(f\"Error deleting {existing_key}: {delete_response.text}\")\n",
    "                break\n",
    "\n",
    "    # Create new agent\n",
    "    response = requests.post(f\"{BASE_URL}/agents\", headers=headers, json=agent_config)\n",
    "\n",
    "    if response.status_code == 201:\n",
    "        agent_data = response.json()\n",
    "        print(f\"Created agent '{agent_name}'\")\n",
    "        print(f\"Agent Key: {agent_data['key']}\")\n",
    "        return agent_data['key']\n",
    "    else:\n",
    "        print(f\"Error creating agent: {response.status_code}\")\n",
    "        print(f\"{response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent 'Research Paper Analyst'\n",
      "Agent Key: agt_research_paper_analyst_957d\n"
     ]
    }
   ],
   "source": [
    "# Create Research Paper Analyst sub-agent\n",
    "reranker_config = {\n",
    "    \"type\": \"chain\",\n",
    "    \"rerankers\": [\n",
    "        {\n",
    "            \"type\": \"customer_reranker\",\n",
    "            \"reranker_id\": \"rnk_272725719\", \n",
    "            \"limit\": 25,\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"mmr\",\n",
    "            \"diversity_bias\": 0.05\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "research_analyst_config = {\n",
    "    \"name\": \"Research Paper Analyst\",\n",
    "    \"description\": \"Specialized agent for analyzing academic research papers on RAG, embeddings, and retrieval techniques\",\n",
    "    \"model\": {\"name\": \"gpt-4o\"},\n",
    "    \"first_step\": {\n",
    "        \"type\": \"conversational\",\n",
    "        \"instructions\": [\n",
    "            {\n",
    "                \"type\": \"inline\",\n",
    "                \"name\": \"research_analyst_instructions\",\n",
    "                \"template\": \"\"\"You are an expert academic research analyst specializing in AI, machine learning, and natural language processing.\n",
    "\n",
    "Your expertise includes:\n",
    "- Retrieval Augmented Generation (RAG) architectures\n",
    "- Dense and sparse retrieval methods\n",
    "- Embedding models and vector representations\n",
    "- Transformer architectures and attention mechanisms\n",
    "- Information retrieval benchmarks and evaluation metrics\n",
    "\n",
    "When analyzing research papers:\n",
    "1. Identify the key contributions and novel techniques\n",
    "2. Explain technical concepts clearly with examples\n",
    "3. Highlight practical implications and limitations\n",
    "4. Compare with related work when relevant\n",
    "5. Provide citations to the source papers\n",
    "\n",
    "Always use tools to retrieve relevant content to answer user queries.\n",
    "Always ground your response in the retrieved content. \n",
    "If you cannot answer the user question from the retrieved content from tools, just say \"I don't know\"\n",
    "\n",
    "IMPORTANT: When responding, provide a complete, self-contained summary that includes all relevant findings.\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        \"output_parser\": {\"type\": \"default\"}\n",
    "    },\n",
    "    \"tool_configurations\": {\n",
    "        \"research_search\": {\n",
    "            \"type\": \"corpora_search\",\n",
    "            \"query_configuration\": {\n",
    "                \"search\": {\n",
    "                    \"corpora\": [{\"corpus_key\": research_corpus_key}],\n",
    "                    \"limit\": 100,\n",
    "                    \"context_configuration\": {\n",
    "                        \"sentences_before\": 2,\n",
    "                        \"sentences_after\": 2\n",
    "                    },\n",
    "                    \"reranker\": reranker_config,                   \n",
    "                },\n",
    "                \"save_history\": True,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "research_analyst_key = delete_and_create_agent(research_analyst_config, \"Research Paper Analyst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "### Sub-Agent 2: Vectara Documentation Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent 'Documentation Expert'\n",
      "Agent Key: agt_documentation_expert_1571\n"
     ]
    }
   ],
   "source": [
    "# Create Documentation Expert sub-agent\n",
    "\n",
    "docs_expert_config = {\n",
    "    \"name\": \"Documentation Expert\",\n",
    "    \"description\": \"Specialized agent for finding implementation guidance and best practices from Vectara documentation\",\n",
    "    \"model\": {\"name\": \"gpt-4o\"},\n",
    "    \"first_step\": {\n",
    "        \"type\": \"conversational\",\n",
    "        \"instructions\": [\n",
    "            {\n",
    "                \"type\": \"inline\",\n",
    "                \"name\": \"docs_expert_instructions\",\n",
    "                \"template\": \"\"\"You are a Vectara platform expert who helps developers implement AI solutions.\n",
    "\n",
    "Your expertise includes:\n",
    "- Vectara API integration (indexing, querying, agents)\n",
    "- Corpus management and configuration\n",
    "- Search optimization (hybrid search, reranking, filters)\n",
    "- RAG implementation best practices\n",
    "- SDK usage and code examples\n",
    "\n",
    "When providing guidance:\n",
    "1. Give specific, actionable implementation steps using the API.\n",
    "2. Include relevant API endpoints and parameters\n",
    "3. Your examples should show how to use the API, not using Vectara SDK.\n",
    "4. Highlight configuration options and trade-offs\n",
    "5. Point to relevant documentation sections\n",
    "\n",
    "Always use tools to retrieve relevant content to answer user queries.\n",
    "Always ground your response in the retrieved content. \n",
    "If you cannot answer the user question from the retrieved content from tools, just say \"I don't know\"\n",
    "\n",
    "When responding, provide a complete, self-contained answer with all implementation details.\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        \"output_parser\": {\"type\": \"default\"}\n",
    "    },\n",
    "    \"tool_configurations\": {\n",
    "        \"docs_search\": {\n",
    "            \"type\": \"corpora_search\",\n",
    "            \"query_configuration\": {\n",
    "                \"search\": {\n",
    "                    \"corpora\": [{\"corpus_key\": docs_corpus_key}],\n",
    "                    \"limit\": 100,\n",
    "                    \"context_configuration\": {\n",
    "                        \"sentences_before\": 2,\n",
    "                        \"sentences_after\": 2\n",
    "                    },\n",
    "                    \"reranker\": reranker_config,                   \n",
    "                },\n",
    "                \"save_history\": True,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "docs_expert_key = delete_and_create_agent(docs_expert_config, \"Documentation Expert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ir8dahqid7b",
   "metadata": {},
   "source": [
    "### Sub-Agent 3: Web Search Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8j6idifi4m3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent 'Web Search Expert'\n",
      "Agent Key: agt_web_search_expert_b15c\n"
     ]
    }
   ],
   "source": [
    "# Create Web Search Expert sub-agent\n",
    "\n",
    "web_search_expert_config = {\n",
    "    \"name\": \"Web Search Expert\",\n",
    "    \"description\": \"Specialized agent for searching the web for current information, news, and general knowledge\",\n",
    "    \"model\": {\"name\": \"gpt-4o\"},\n",
    "    \"first_step\": {\n",
    "        \"type\": \"conversational\",\n",
    "        \"instructions\": [\n",
    "            {\n",
    "                \"type\": \"inline\",\n",
    "                \"name\": \"web_search_expert_instructions\",\n",
    "                \"template\": \"\"\"You are a web search expert who helps find current and relevant information from the internet.\n",
    "\n",
    "Your expertise includes:\n",
    "- Finding up-to-date information on any topic\n",
    "- Researching current events and news\n",
    "- Locating authoritative sources and references\n",
    "- Comparing information across multiple sources\n",
    "- Fact-checking and verification\n",
    "\n",
    "When searching and responding:\n",
    "1. Use web search to find relevant, current information\n",
    "2. Prioritize authoritative and credible sources\n",
    "3. Provide context about when information was published\n",
    "4. Cite your sources with URLs when available\n",
    "5. Synthesize information from multiple sources when appropriate\n",
    "\n",
    "Always use the web search tool to find information.\n",
    "If you cannot find relevant information, say so clearly.\n",
    "\n",
    "IMPORTANT: When responding, provide a complete, well-sourced answer with citations.\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        \"output_parser\": {\"type\": \"default\"}\n",
    "    },\n",
    "    \"tool_configurations\": {\n",
    "        \"web_search\": {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "web_search_expert_key = delete_and_create_agent(web_search_expert_config, \"Web Search Expert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4n995hnpf",
   "metadata": {},
   "source": [
    "## Step 2: Create an API Validator Lambda Tool\n",
    "\n",
    "Before creating the orchestrator, we'll add a **Lambda Tool** that validates Vectara API payloads. This tool is *essential* for answering implementation questions because:\n",
    "\n",
    "- LLMs may hallucinate field names (e.g., `corpus_id` instead of `corpus_key`)\n",
    "- Parameter ranges need validation (e.g., `lexical_interpolation` must be 0-1)\n",
    "- Required fields must be present for the code to actually work\n",
    "- The orchestrator can't claim code is \"working\" without validating it first\n",
    "\n",
    "Unlike optional analysis tools that LLMs may skip, this validator is essentialâ€”the orchestrator must use it before presenting API code examples to ensure correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "nurhxwplzh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to manage lambda tools\n",
    "def delete_and_create_tool(tool_config, tool_name):\n",
    "    \"\"\"Delete tool if it exists, then create a new one.\"\"\"\n",
    "    list_response = requests.get(f\"{BASE_URL}/tools\", headers=headers)\n",
    "    \n",
    "    if list_response.status_code == 200:\n",
    "        tools = list_response.json().get('tools', [])\n",
    "        for tool in tools:\n",
    "            if tool.get('name') == tool_name:\n",
    "                existing_id = tool['id']\n",
    "                print(f\"Deleting existing tool '{tool_name}' ({existing_id})\")\n",
    "                delete_response = requests.delete(f\"{BASE_URL}/tools/{existing_id}\", headers=headers)\n",
    "                if delete_response.status_code == 204:\n",
    "                    print(f\"Deleted tool: {existing_id}\")\n",
    "                break\n",
    "    \n",
    "    response = requests.post(f\"{BASE_URL}/tools\", headers=headers, json=tool_config)\n",
    "    \n",
    "    if response.status_code == 201:\n",
    "        tool_data = response.json()\n",
    "        print(f\"Created tool '{tool_name}'\")\n",
    "        print(f\"Tool ID: {tool_data['id']}\")\n",
    "        return tool_data['id']\n",
    "    else:\n",
    "        print(f\"Error creating tool: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3umya5qan8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created tool 'vectara_api_validator'\n",
      "Tool ID: tol_2306\n"
     ]
    }
   ],
   "source": [
    "# Create the Vectara API Payload Validator lambda tool\n",
    "api_validator_code = '''\n",
    "import json\n",
    "\n",
    "def process(\n",
    "    endpoint: str,\n",
    "    payload: str,\n",
    "    method: str = \"POST\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Validate a Vectara API request payload.\n",
    "    \n",
    "    Args:\n",
    "        endpoint: API endpoint (query, index, corpus, agents)\n",
    "        payload: JSON string of the request body\n",
    "        method: HTTP method (POST, GET, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        Validation result with errors, warnings, and corrected payload\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    warnings = []\n",
    "    \n",
    "    # Parse the payload\n",
    "    try:\n",
    "        data = json.loads(payload)\n",
    "    except json.JSONDecodeError as e:\n",
    "        return {\n",
    "            \"valid\": False,\n",
    "            \"endpoint\": endpoint,\n",
    "            \"errors\": [f\"Invalid JSON: {str(e)}\"],\n",
    "            \"warnings\": [],\n",
    "            \"corrected_payload\": None\n",
    "        }\n",
    "    \n",
    "    corrected = dict(data)\n",
    "\n",
    "    # Validate API version - must use v2, not v1\n",
    "    if 'vectara.io' in endpoint:\n",
    "        if '/v1/' in endpoint or '/v1' in endpoint:\n",
    "            errors.append(\"Invalid API version: v1 is deprecated. Use https://api.vectara.io/v2 endpoints.\")\n",
    "\n",
    "    # Validation rules by endpoint\n",
    "    if endpoint == \"query\":\n",
    "        # Required fields\n",
    "        if \"query\" not in data:\n",
    "            errors.append(\"Missing required field: 'query'\")\n",
    "            corrected[\"query\"] = \"<YOUR_QUERY>\"\n",
    "        \n",
    "        if \"search\" not in data:\n",
    "            errors.append(\"Missing required field: 'search'\")\n",
    "            corrected[\"search\"] = {\"corpora\": [{\"corpus_key\": \"<YOUR_CORPUS_KEY>\"}]}\n",
    "        else:\n",
    "            search = data.get(\"search\", {})\n",
    "            if \"corpora\" not in search:\n",
    "                errors.append(\"Missing required field: 'search.corpora'\")\n",
    "            else:\n",
    "                for i, corpus in enumerate(search.get(\"corpora\", [])):\n",
    "                    if \"corpus_key\" not in corpus:\n",
    "                        errors.append(f\"Missing corpus_key in corpora[{i}]\")\n",
    "                    \n",
    "                    # Validate lexical_interpolation range\n",
    "                    if \"lexical_interpolation\" in corpus:\n",
    "                        li = corpus[\"lexical_interpolation\"]\n",
    "                        if not isinstance(li, (int, float)) or li < 0 or li > 1:\n",
    "                            errors.append(f\"lexical_interpolation must be 0-1, got: {li}\")\n",
    "                            corrected[\"search\"][\"corpora\"][i][\"lexical_interpolation\"] = 0.025\n",
    "            \n",
    "            # Validate limit\n",
    "            if \"limit\" in search:\n",
    "                limit = search[\"limit\"]\n",
    "                if not isinstance(limit, int) or limit < 1:\n",
    "                    warnings.append(f\"limit should be positive integer, got: {limit}\")\n",
    "        \n",
    "        # Check for common hallucinations\n",
    "        hallucinated_fields = [\"corpus_id\", \"customer_id\", \"num_results\", \"query_text\"]\n",
    "        for field in hallucinated_fields:\n",
    "            if field in data:\n",
    "                errors.append(f\"Invalid field '{field}' - this is a hallucination. Did you mean: \" +\n",
    "                            {\"corpus_id\": \"search.corpora[].corpus_key\",\n",
    "                             \"customer_id\": \"(not needed with API key)\",\n",
    "                             \"num_results\": \"search.limit\",\n",
    "                             \"query_text\": \"query\"}.get(field, \"check docs\"))\n",
    "    \n",
    "    elif endpoint == \"index\":\n",
    "        if \"document_id\" not in data and \"id\" not in data:\n",
    "            errors.append(\"Missing required field: 'document_id' or 'id'\")\n",
    "        \n",
    "        has_content = \"parts\" in data or \"document_parts\" in data or \"content\" in data\n",
    "        if not has_content:\n",
    "            errors.append(\"Missing content: need 'parts', 'document_parts', or 'content'\")\n",
    "        \n",
    "        # Check for hallucinations\n",
    "        if \"text\" in data and \"parts\" not in data:\n",
    "            warnings.append(\"'text' alone is not valid - use 'parts' array with 'text' inside\")\n",
    "    \n",
    "    elif endpoint == \"agents\":\n",
    "        if \"name\" not in data:\n",
    "            errors.append(\"Missing required field: 'name'\")\n",
    "        if \"model\" not in data:\n",
    "            errors.append(\"Missing required field: 'model'\")\n",
    "        if \"first_step\" not in data:\n",
    "            errors.append(\"Missing required field: 'first_step'\")\n",
    "    \n",
    "    elif endpoint == \"corpus\":\n",
    "        if \"key\" not in data and \"name\" not in data:\n",
    "            warnings.append(\"Consider providing 'key' or 'name' for the corpus\")\n",
    "    \n",
    "    return {\n",
    "        \"valid\": len(errors) == 0,\n",
    "        \"endpoint\": endpoint,\n",
    "        \"method\": method,\n",
    "        \"errors\": errors,\n",
    "        \"warnings\": warnings,\n",
    "        \"corrected_payload\": corrected if errors else data\n",
    "    }\n",
    "'''\n",
    "\n",
    "api_validator_config = {\n",
    "    \"type\": \"lambda\",\n",
    "    \"language\": \"python\",\n",
    "    \"name\": \"vectara_api_validator\",\n",
    "    \"title\": \"Vectara API Payload Validator\",\n",
    "    \"description\": \"Validate Vectara API request payloads before presenting to users. Checks required fields, validates parameter ranges (e.g., lexical_interpolation 0-1), and catches common LLM hallucinations (wrong field names). Returns validation status, errors, and corrected payload. ALWAYS use this before showing API code examples.\",\n",
    "    \"code\": api_validator_code\n",
    "}\n",
    "\n",
    "api_validator_id = delete_and_create_tool(api_validator_config, \"vectara_api_validator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 3: Create the Parent Orchestrator Agent\n",
    "\n",
    "Now we'll create a parent agent that can delegate to the sub-agents and use the API validator. The parent agent:\n",
    "- Analyzes user requests to determine which sub-agent(s) to invoke\n",
    "- Delegates domain-specific tasks to the appropriate sub-agent\n",
    "- **Uses the API validator** to ensure generated code is correct before presenting it back to the user.\n",
    "- Synthesizes responses from multiple sub-agents into a cohesive answer\n",
    "\n",
    "### Sub-Agent Tool Configuration\n",
    "\n",
    "Sub-agents are configured as tools using the `sub_agent` type:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"type\": \"sub_agent\",\n",
    "  \"description_template\": \"Description the LLM sees when deciding to use this tool\",\n",
    "  \"sub_agent_configuration\": {\n",
    "    \"agent_key\": \"the_sub_agent_key\",\n",
    "    \"session_mode\": \"ephemeral\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### Session Modes\n",
    "\n",
    "When specifying in the parent agent how sub-agents are to be used, you need to define the \"session mode\":\n",
    "- **`persistent`**: Always reuse the same session, accumulating knowledge across invocations\n",
    "- **`ephemeral`**: Create a fresh session every time, ensuring no state leakage\n",
    "- **`llm_controlled`**: The LLM decides whether to resume an existing session or create a new one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent 'AI Research Orchestrator'\n",
      "Agent Key: agt_ai_research_orchestrator_85ef\n"
     ]
    }
   ],
   "source": [
    "# Create the Orchestrator Agent with sub-agent tools and API validator\n",
    "orchestrator_config = {\n",
    "    \"name\": \"AI Research Orchestrator\",\n",
    "    \"description\": \"Orchestrator agent that delegates to specialized sub-agents for comprehensive AI research assistance\",\n",
    "    \"model\": {\"name\": \"gpt-4o\"},\n",
    "    \"first_step\": {\n",
    "        \"type\": \"conversational\",\n",
    "        \"instructions\": [\n",
    "            {\n",
    "                \"type\": \"inline\",\n",
    "                \"name\": \"orchestrator_instructions\",\n",
    "                \"template\": \"\"\"You are an AI research orchestrator that helps users understand and implement AI technologies.\n",
    "\n",
    "Your workflow:\n",
    "1. Analyze the user's question to determine what expertise is needed.\n",
    "2. Use appropriate sub-agent(s) to gather information:\n",
    "   - research_analyst: for academic/theoretical content\n",
    "   - docs_expert: for implementation guidance\n",
    "   - web_search_expert: for current news/trends\n",
    "3. When your response includes Vectara API code examples or implementation details:\n",
    "   - Generate the JSON payload\n",
    "   - ALWAYS validate it using the api_validator tool before presenting\n",
    "   - If validation fails, fix the errors and validate again\n",
    "   - Only present validated, working code to the user\n",
    "4. Synthesize all responses into a comprehensive answer.\n",
    "\n",
    "IMPORTANT: \n",
    "- Never show API code without validating it first. Users trust that code examples will work.\n",
    "- When responding, provide a complete, well-sourced answer with citations.\n",
    "\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        \"output_parser\": {\"type\": \"default\"}\n",
    "    },\n",
    "    \"tool_configurations\": {\n",
    "        \"research_analyst\": {\n",
    "            \"type\": \"sub_agent\",\n",
    "            \"description_template\": \"Research academic research papers for theoretical foundations and research findings.\",\n",
    "            \"sub_agent_configuration\": {\n",
    "                \"agent_key\": research_analyst_key,\n",
    "                \"session_mode\": \"ephemeral\"\n",
    "            }\n",
    "        },\n",
    "        \"docs_expert\": {\n",
    "            \"type\": \"sub_agent\",\n",
    "            \"description_template\": \"Research Vectara documentation for API usage, code examples, configuration, and best practices.\",\n",
    "            \"sub_agent_configuration\": {\n",
    "                \"agent_key\": docs_expert_key,\n",
    "                \"session_mode\": \"ephemeral\"\n",
    "            }\n",
    "        },\n",
    "        \"web_search_expert\": {\n",
    "            \"type\": \"sub_agent\",\n",
    "            \"description_template\": \"Search the web for up-to-date information, news, and current trends.\",\n",
    "            \"sub_agent_configuration\": {\n",
    "                \"agent_key\": web_search_expert_key,\n",
    "                \"session_mode\": \"ephemeral\"\n",
    "            }\n",
    "        },\n",
    "        \"api_validator\": {\n",
    "            \"type\": \"lambda\",\n",
    "            \"tool_id\": api_validator_id\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "orchestrator_key = delete_and_create_agent(orchestrator_config, \"AI Research Orchestrator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Step 4: Test the Multi-Agent Workflow\n",
    "\n",
    "Now let's test the orchestrator with different types of questions to see how it delegates to sub-agents and uses the API validator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to send messages and display responses\n",
    "def chat_with_agent(agent_key, session_key, message, show_events=False):\n",
    "    \"\"\"Send a message to an agent and return the response.\"\"\"\n",
    "    message_data = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"content\": message\n",
    "            }\n",
    "        ],\n",
    "        \"stream_response\": False\n",
    "    }\n",
    "    \n",
    "    url = f\"{BASE_URL}/agents/{agent_key}/sessions/{session_key}/events\"\n",
    "    response = requests.post(url, headers=headers, json=message_data)\n",
    "    \n",
    "    if response.status_code == 201:\n",
    "        event_data = response.json()\n",
    "        \n",
    "        if show_events:\n",
    "            print(\"\\n------ Agent Events ------\")\n",
    "            for event in event_data.get('events', []):\n",
    "                event_type = event.get('type', 'INVALID')\n",
    "                print(f\"Event: {event_type}\")\n",
    "                if event_type == 'tool_input':\n",
    "                    tool_name = event.get('tool_configuration_name', 'N/A')\n",
    "                    print(f\"  Tool: {tool_name}\")\n",
    "                    tool_input = event.get(\"tool_input\", {})\n",
    "                    if tool_input.get(\"message\"):\n",
    "                        print(f\"  Input: {tool_input['message']}...\")\n",
    "                    # Show API validator inputs\n",
    "                    if tool_input.get(\"endpoint\"):\n",
    "                        print(f\"  Validating endpoint: {tool_input['endpoint']}\")\n",
    "                if event_type == 'tool_output':\n",
    "                    tool_name = event.get('tool_configuration_name', 'N/A')\n",
    "                    print(f\"  Tool: {tool_name}\")\n",
    "                    tool_output = event.get(\"tool_output\", {})\n",
    "                    # Show sub-agent response preview\n",
    "                    if tool_output.get(\"sub_agent_response\"):\n",
    "                        print(f\"  Response (200 chars): {tool_output['sub_agent_response'][:200]}...\")\n",
    "                    # Show API validator output\n",
    "                    if tool_output.get(\"lambda_response\"):\n",
    "                        lambda_resp = tool_output[\"lambda_response\"]\n",
    "                        if \"valid\" in lambda_resp:\n",
    "                            valid = lambda_resp[\"valid\"]\n",
    "                            print(f\"  Validation Result: {'VALID' if valid else 'INVALID'}\")\n",
    "                            if lambda_resp.get(\"errors\"):\n",
    "                                print(f\"    Errors: {lambda_resp['errors']}\")\n",
    "                            if lambda_resp.get(\"warnings\"):\n",
    "                                print(f\"    Warnings: {lambda_resp['warnings']}\")\n",
    "            print(\"-\"*25)\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        # Extract agent output\n",
    "        for event in event_data.get('events', []):\n",
    "            if event.get('type') == 'agent_output':\n",
    "                return event.get('content', 'No content')\n",
    "        \n",
    "        return \"No agent output found\"\n",
    "    else:\n",
    "        return f\"Error: {response.status_code} - {response.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session Created: ase_orchestrator_session_20251215-163417_9b8c\n"
     ]
    }
   ],
   "source": [
    "# Create a session for the orchestrator\n",
    "session_name = f\"Orchestrator Session {datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "session_config = {\n",
    "    \"name\": session_name,\n",
    "    \"metadata\": {\n",
    "        \"purpose\": \"sub_agent_demo\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{BASE_URL}/agents/{orchestrator_key}/sessions\",\n",
    "    headers=headers,\n",
    "    json=session_config\n",
    ")\n",
    "\n",
    "if response.status_code == 201:\n",
    "    session_data = response.json()\n",
    "    orchestrator_session_key = session_data[\"key\"]\n",
    "    print(f\"Session Created: {orchestrator_session_key}\")\n",
    "else:\n",
    "    print(f\"Error: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "### Test 1: Research-Focused Question\n",
    "\n",
    "This question should primarily use the research_analyst sub-agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What are the key innovations in RAG?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "------ Agent Events ------\n",
      "Event: input_message\n",
      "Event: tool_input\n",
      "  Tool: research_analyst\n",
      "  Input: Research the latest academic findings and theoretical advancements in Retrieval-Augmented Generation (RAG) models. Focus on key innovations and improvements in this field....\n",
      "Event: tool_input\n",
      "  Tool: web_search_expert\n",
      "  Input: Find the latest news and articles about innovations and trends in Retrieval-Augmented Generation (RAG) models. Focus on recent developments and practical applications....\n",
      "Event: tool_output\n",
      "  Tool: research_analyst\n",
      "  Response (200 chars): Recent advancements in Retrieval-Augmented Generation (RAG) models focus on addressing challenges in combining parametric and non-parametric memory for more effective language generation. Here are the...\n",
      "Event: tool_output\n",
      "  Tool: web_search_expert\n",
      "  Response (200 chars): Recent advancements in Retrieval-Augmented Generation (RAG) models, as of 2023, highlight several key innovations and practical applications:\n",
      "\n",
      "1. **Integration with Large Language Models (LLMs)**: RAG...\n",
      "Event: agent_output\n",
      "-------------------------\n",
      "\n",
      "\n",
      "Agent Response:\n",
      "\n",
      "Retrieval-Augmented Generation (RAG) models have seen some exciting innovations and advancements, both in academic research and practical applications. Here's a synthesis of key developments in this field:\n",
      "\n",
      "### Academic and Theoretical Innovations:\n",
      "1. **Hybrid Memory Usage**:\n",
      "   - RAG models use a mix of pre-trained parametric memory (like seq2seq transformers) and non-parametric memory (e.g., dense vector indices from Wikipedia) accessed through pre-trained neural retrievers. This combination allows for blending precise factual retrieval with flexible generative modeling [Lewis et al., 2020](https://arxiv.org/abs/2005.11401).\n",
      "\n",
      "2. **Improved Retrieval and Generation Process**:\n",
      "   - These models are trained end-to-end using a probabilistic framework, enhancing retrieval accuracy and supporting dynamic index updates. This results in better adaptability to new information and improved response generation [Lewis et al., 2020](https://arxiv.org/abs/2005.11401).\n",
      "\n",
      "3. **Hallucination Mitigation**:\n",
      "   - Innovations in detecting and mitigating hallucinations have been crucial. New benchmarks like RAGTruth assess hallucination levels, aiming for more trustworthy outputs in knowledge-conditioned generation [Cheng Niu et al., 2024](https://arxiv.org/abs/2401.06855).\n",
      "\n",
      "4. **Diverse and Specific Outputs**:\n",
      "   - RAG models outperform traditional models in generating more diverse, specific, and factually accurate outputs, particularly in open-domain QA tasks [Brown et al., 2020](https://arxiv.org/abs/2005.14165).\n",
      "\n",
      "5. **Potential for Joint Pre-Training**:\n",
      "   - Suggestions have been made to explore joint pre-training of both memory components, potentially enhancing efficiency using objectives like denoising autoencoding [Lewis et al., 2020](https://arxiv.org/abs/2005.11401).\n",
      "\n",
      "### Practical and Industry Advancements:\n",
      "1. **Integration with Large Language Models (LLMs)**:\n",
      "   - By integrating RAG with LLMs, models can manage complex queries more effectively, useful in applications like customer service and knowledge systems [Medium](https://medium.com/@bharathkalluru12/title-the-latest-trends-in-retrieval-augmented-generation-rag-revolutionizing-ai-powered-4af2e699eb48).\n",
      "\n",
      "2. **Real-Time Knowledge Updates**:\n",
      "   - RAG models enable real-time updates, maintaining relevance particularly in fast-evolving fields like medicine and technology [Ayadata](https://www.ayadata.ai/the-state-of-retrieval-augmented-generation-rag-in-2025-and-beyond/).\n",
      "\n",
      "3. **Multimodal RAG Systems**:\n",
      "   - Evolving to incorporate multimodal data allows for richer interactions, enhancing capabilities in digital assistants and various retrieval scenarios [Medium](https://medium.com/@bharathkalluru12/title-the-latest-trends-in-retrieval-augmented-generation-rag-revolutionizing-ai-powered-4af2e699eb48).\n",
      "\n",
      "4. **Performance in KILT Tasks**:\n",
      "   - RAG models excel in KILT tasks and few-shot QA, demonstrating adaptability and performance across natural language processing challenges [ArXiv](https://arxiv.org/html/2507.18910v1).\n",
      "\n",
      "These advancements highlight the ongoing evolution of RAG models, emphasizing their adaptability, efficiency, and enhanced capability in leveraging external knowledge bases across diverse sectors.\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the key innovations in RAG?\"\n",
    "print(f\"User: {query}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "response = chat_with_agent(\n",
    "    orchestrator_key,\n",
    "    orchestrator_session_key,\n",
    "    query,\n",
    "    show_events=True\n",
    ")\n",
    "\n",
    "print(f\"Agent Response:\\n\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "### Test 2: Implementation Question with API Validation\n",
    "\n",
    "This question asks for working code, which should trigger the API validator to ensure correctness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Give me working code to search a corpus for AI research papers using hybrid search with Vectara's API.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "------ Agent Events ------\n",
      "Event: input_message\n",
      "Event: tool_input\n",
      "  Tool: docs_expert\n",
      "  Input: Provide a code example for using Vectara's API to perform a hybrid search on a corpus for AI research papers. The code should include the necessary steps and configurations for authenticating and querying the API....\n",
      "Event: tool_output\n",
      "  Tool: docs_expert\n",
      "  Response (200 chars): To perform a hybrid search using Vectara's API for querying a corpus containing AI research papers, follow these steps. This will include setting up the necessary configuration, authenticating, and ma...\n",
      "Event: tool_input\n",
      "  Tool: api_validator\n",
      "  Validating endpoint: https://api.vectara.io/v2/queries\n",
      "Event: tool_output\n",
      "  Tool: api_validator\n",
      "Event: agent_output\n",
      "-------------------------\n",
      "\n",
      "\n",
      "Agent Response:\n",
      "\n",
      "Here is the validated code to perform a hybrid search using Vectara's API to query a corpus for AI research papers:\n",
      "\n",
      "### Step 1: Prepare API Authentication\n",
      "\n",
      "You will need to authenticate using an API key. Make sure to replace `YOUR_API_KEY` with your actual API key and `YOUR_CORPUS_KEY` with the specific key for your corpus.\n",
      "\n",
      "### Step 2: Setup API Request\n",
      "\n",
      "You will be making a POST request to Vectara's API. Below is how you should configure the request:\n",
      "\n",
      "#### Request URL\n",
      "- `https://api.vectara.io/v2/queries`\n",
      "\n",
      "#### HTTP Method\n",
      "- POST\n",
      "\n",
      "#### Headers\n",
      "- `Authorization`: `ApiKey YOUR_API_KEY`\n",
      "- `Content-Type`: `application/json`\n",
      "\n",
      "#### Request Body\n",
      "\n",
      "Here is the JSON payload for the request body:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"query\": \"Recent advancements in AI research\",\n",
      "  \"search\": {\n",
      "    \"corpora\": [\n",
      "      {\n",
      "        \"corpus_key\": \"YOUR_CORPUS_KEY\",\n",
      "        \"lexical_interpolation\": 0.5\n",
      "      }\n",
      "    ],\n",
      "    \"limit\": 10,\n",
      "    \"reranker\": {\n",
      "      \"type\": \"bm25\",\n",
      "      \"reranker_id\": \"your_reranker_id\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "### Step 3: Execute the API Call\n",
      "\n",
      "You can perform this API call using `curl` or within a script in Python or another language. Below is an example using `curl`:\n",
      "\n",
      "```bash\n",
      "curl -X POST https://api.vectara.io/v2/queries \\\n",
      "-H \"Authorization: ApiKey YOUR_API_KEY\" \\\n",
      "-H \"Content-Type: application/json\" \\\n",
      "-d '{\n",
      "  \"query\": \"Recent advancements in AI research\",\n",
      "  \"search\": {\n",
      "    \"corpora\": [\n",
      "      {\n",
      "        \"corpus_key\": \"YOUR_CORPUS_KEY\",\n",
      "        \"lexical_interpolation\": 0.5\n",
      "      }\n",
      "    ],\n",
      "    \"limit\": 10,\n",
      "    \"reranker\": {\n",
      "      \"type\": \"bm25\",\n",
      "      \"reranker_id\": \"your_reranker_id\"\n",
      "    }\n",
      "  }\n",
      "}'\n",
      "```\n",
      "\n",
      "### Step 4: Handle the Response\n",
      "\n",
      "The response from the API will include documents or sections from your corpus that match your query, each associated with relevance scores.\n",
      "\n",
      "#### Further Optimization\n",
      "\n",
      "You may wish to adjust parameters like `lexical_interpolation` and implement metadata-based filters to fine-tune your search results.\n",
      "\n",
      "For further exploration and to dive deeper into advanced features like metadata filtering and reranking strategies, check the [Vectara API documentation](https://docs.vectara.com/docs/api-reference).\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me working code to search a corpus for AI research papers using hybrid search with Vectara's API.\"\n",
    "print(f\"User: {query}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "response = chat_with_agent(\n",
    "    orchestrator_key,\n",
    "    orchestrator_session_key,\n",
    "    query,\n",
    "    show_events=True\n",
    ")\n",
    "\n",
    "print(f\"Agent Response:\\n\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wr04o4ujvoh",
   "metadata": {},
   "source": [
    "### Test 3: Current Information Question (Web Search)\n",
    "\n",
    "This question asks about recent developments that wouldn't be in our indexed research papers or documentation, demonstrating the value of the web search sub-agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7elqfu25p1k",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What are the latest developments in RAG technology in 2025? Are there any new techniques or frameworks that have emerged recently?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "------ Agent Events ------\n",
      "Event: input_message\n",
      "Event: tool_input\n",
      "  Tool: web_search_expert\n",
      "  Input: Search for the latest developments and innovations in Retrieval-Augmented Generation (RAG) technologies in 2025. Look for new techniques, frameworks, and any emerging trends or industry news relevant to this field....\n",
      "Event: tool_output\n",
      "  Tool: web_search_expert\n",
      "  Response (200 chars): In 2025, Retrieval-Augmented Generation (RAG) continues to advance with several innovative techniques and trends that enhance AI's ability to integrate external data for more dynamic performance:\n",
      "\n",
      "1. ...\n",
      "Event: agent_output\n",
      "-------------------------\n",
      "\n",
      "\n",
      "Agent Response:\n",
      "\n",
      "In 2025, there have been several notable advancements and innovations in Retrieval-Augmented Generation (RAG) technology that aim to enhance AI capabilities through improved data integration and interaction. Here are the latest developments:\n",
      "\n",
      "1. **Real-Time RAG**:\n",
      "   - This approach focuses on enabling RAG systems to fetch and use information in real-time, allowing for responses that reflect the most up-to-date data. It is particularly beneficial for applications involving rapidly changing information, such as news reporting and financial markets.\n",
      "\n",
      "2. **Hybrid Models**:\n",
      "   - These models merge multiple data sources and types, such as structured databases and unstructured text, to enrich AI's contextual understanding and enhance the accuracy and depth of information retrieval.\n",
      "\n",
      "3. **Long RAG and Self-RAG**:\n",
      "   - Long RAG is designed to handle extended pieces of information, thereby offering more comprehensive responses. Self-RAG involves self-improvement mechanisms where the system adapts and enhances its capabilities over time using user feedback and interactions.\n",
      "\n",
      "4. **Multimodal Content and Personalized Implementation**:\n",
      "   - A significant trend is the integration of various content types (text, audio, images) and tailoring RAG outputs to suit individual user needs, thus enhancing personalization in applications like virtual assistants and customer service bots.\n",
      "\n",
      "5. **Bridging Static AI and Dynamic Data**:\n",
      "   - Advances in RAG are addressing the gap between static AI models and the dynamic need for contextual data, enabling AI systems to provide more relevant and context-aware interactions.\n",
      "\n",
      "These innovations are part of broader efforts to render AI systems more flexible, adaptive, and contextually aware, making them more relevant in dynamic scenarios. For further insights, you might find it useful to explore resources such as [The 2025 Guide to Retrieval-Augmented Generation (RAG)](https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag) and articles on [Trends in Active Retrieval Augmented Generation](https://www.signitysolutions.com/blog/trends-in-active-retrieval-augmented-generation).\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the latest developments in RAG technology in 2025? Are there any new techniques or frameworks that have emerged recently?\"\n",
    "print(f\"User: {query}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "response = chat_with_agent(\n",
    "    orchestrator_key,\n",
    "    orchestrator_session_key,\n",
    "    query,\n",
    "    show_events=True\n",
    ")\n",
    "\n",
    "print(f\"Agent Response:\\n\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "If you want to delete the agents created in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted agent: agt_ai_research_orchestrator_85ef\n",
      "Deleted agent: agt_research_paper_analyst_957d\n",
      "Deleted agent: agt_documentation_expert_1571\n",
      "Deleted agent: agt_web_search_expert_b15c\n",
      "Deleted tool: tol_2306\n"
     ]
    }
   ],
   "source": [
    "# Delete agents\n",
    "agents_to_delete = [\n",
    "    orchestrator_key,\n",
    "    research_analyst_key,\n",
    "    docs_expert_key,\n",
    "    web_search_expert_key\n",
    "]\n",
    "\n",
    "for agent_key in agents_to_delete:\n",
    "    if agent_key:\n",
    "        response = requests.delete(f\"{BASE_URL}/agents/{agent_key}\", headers=headers)\n",
    "        if response.status_code == 204:\n",
    "            print(f\"Deleted agent: {agent_key}\")\n",
    "        else:\n",
    "            print(f\"Error deleting {agent_key}: {response.text}\")\n",
    "\n",
    "# Delete the lambda tool\n",
    "if api_validator_id:\n",
    "    response = requests.delete(f\"{BASE_URL}/tools/{api_validator_id}\", headers=headers)\n",
    "    if response.status_code == 204:\n",
    "        print(f\"Deleted tool: {api_validator_id}\")\n",
    "    else:\n",
    "        print(f\"Error deleting tool: {response.text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
