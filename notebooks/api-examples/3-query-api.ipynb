{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adf7d63d",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/vectara/example-notebooks/blob/main/notebooks/api-examples/3-query-api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397bea86",
   "metadata": {},
   "source": [
    "# Vectara Query API Examples\n",
    "\n",
    "In this notebook we demonstrate how to use Vectara's Query API using direct REST API calls. We'll cover:\n",
    "- Single corpus queries with hybrid search and reranking\n",
    "- Multiple corpora queries\n",
    "- Metadata filtering\n",
    "- Streaming responses\n",
    "- Conversational chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0855d0",
   "metadata": {},
   "source": [
    "## About Vectara\n",
    "\n",
    "[Vectara](https://vectara.com/) is the Agent Operating System for trusted enterprise AI: a unified Agentic RAG platform with built-in multi-modal retrieval, orchestration, and always-on governance. Deploy it on-prem (air-gapped), in your VPC, or as SaaS. Vectara agents deliver grounded answers and safe actions with source citations, step-level audit trails, fine-grained access controls, and real-time policy and factual-consistency enforcement, so teams ship faster with lower risk, and with trusted, production-grade AI agents at scale.\n",
    "\n",
    "Vectara provides a complete API-first platform for building production RAG and agentic applications:\n",
    "\n",
    "- **Simple Integration**: RESTful APIs and SDKs (Python, JavaScript) for quick integration into any stack\n",
    "- **Flexible Deployment**: Choose SaaS, VPC, or on-premises deployment based on your requirements\n",
    "- **Multi-Modal Support**: Index and search across text, tables, and images from PDFs, documents, and structured data\n",
    "- **Advanced Retrieval**: Hybrid search combining semantic and keyword matching with state-of-the-art reranking\n",
    "- **Grounded Generation**: LLM responses with citations and factual consistency scores to reduce hallucinations\n",
    "- **Enterprise-Ready**: Built-in access controls, audit logging, and compliance (SOC2, HIPAA) from day one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe2497c",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "This notebook assumes you've completed Notebooks 1 and 2:\n",
    "- Notebook 1: Created two corpora (ai-research-papers and vectara-docs) with Boomerang embeddings\n",
    "- Notebook 2: Ingested AI research papers and Vectara documentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6019e01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Corpus: tutorial-ai-research-papers\n",
      "Docs Corpus: tutorial-vectara-docs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Set up authentication\n",
    "api_key = os.environ['VECTARA_API_KEY']\n",
    "\n",
    "# Get corpus keys from environment (set these from Notebook 1 output)\n",
    "research_corpus_key = 'tutorial-ai-research-papers'\n",
    "docs_corpus_key = 'tutorial-vectara-docs'\n",
    "\n",
    "# Base URL for Vectara API v2\n",
    "BASE_URL = \"https://api.vectara.io/v2\"\n",
    "\n",
    "# Common headers for all requests\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Accept': 'application/json',\n",
    "    'x-api-key': api_key\n",
    "}\n",
    "\n",
    "print(f\"Research Corpus: {research_corpus_key}\")\n",
    "print(f\"Docs Corpus: {docs_corpus_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7010b1d-d1bb-4f08-9309-a328bb4ea396",
   "metadata": {},
   "source": [
    "## Example 1: Basic Query with Hybrid Search and Reranking\n",
    "\n",
    "This example demonstrates a single corpus query using:\n",
    "- Hybrid search (lexical_interpolation=0.005 for best semantic search)\n",
    "- Chain reranker combining multilingual reranker with MMR (diversity_bias=0.05) for improved relevance and diversity\n",
    "- Two-stage retrieval: fetch 30 results, rerank to top 10\n",
    "- Generation with vectara-summary-ext-24-05-med-omni preset\n",
    "- Factual Consistency Score to detect potential hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40947545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generated Summary ===\n",
      "Retrieval-augmented generation (RAG) is a method that combines pre-trained parametric memory, such as a sequence-to-sequence (seq2seq) model, with non-parametric memory, like a dense vector index of Wikipedia, accessed through a pre-trained neural retriever. This approach is used for language generation tasks, allowing the model to retrieve relevant information from a large dataset to enhance its responses. RAG models can condition on the same retrieved passages for the entire generated sequence or use different passages for each token, providing flexibility in generating knowledge-intensive content [1], [4].\n",
      "\n",
      "=== Factual Consistency Score: 0.9921875 ===\n"
     ]
    }
   ],
   "source": [
    "# Construct the query request - querying research papers corpus\n",
    "query_request = {\n",
    "    \"query\": \"What is retrieval augmented generation?\",\n",
    "    \"search\": {\n",
    "        \"corpora\": [\n",
    "            {\n",
    "                \"corpus_key\": research_corpus_key,\n",
    "                \"lexical_interpolation\": 0.005\n",
    "            }\n",
    "        ],\n",
    "        \"limit\": 100,\n",
    "        \"context_configuration\": {\n",
    "            \"sentences_before\": 2,\n",
    "            \"sentences_after\": 2\n",
    "        },\n",
    "        \"reranker\": {\n",
    "            \"type\": \"chain\",\n",
    "            \"rerankers\": [\n",
    "                {\n",
    "                    \"type\": \"customer_reranker\",\n",
    "                    \"reranker_id\": \"rnk_272725719\", \n",
    "                    \"limit\": 30,\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"mmr\",\n",
    "                    \"diversity_bias\": 0.05\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    },\n",
    "    \"generation\": {\n",
    "        \"generation_preset_name\": \"vectara-summary-ext-24-05-med-omni\",\n",
    "        \"max_used_search_results\": 10,\n",
    "        \"response_language\": \"eng\",\n",
    "        \"enable_factual_consistency_score\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Make the query request\n",
    "url = f\"{BASE_URL}/query\"\n",
    "response = requests.post(url, headers=headers, json=query_request)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(\"\\n=== Generated Summary ===\")\n",
    "    print(result['summary'])\n",
    "    print(f\"\\n=== Factual Consistency Score: {result.get('factual_consistency_score', 'N/A')} ===\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c163ade",
   "metadata": {},
   "source": [
    "### Examining Search Results and Citations\n",
    "\n",
    "The response includes the retrieved documents that were used to generate the summary, along with citation information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c154dd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Top Search Results ===\n",
      "\n",
      "--- Result 1 ---\n",
      "Text: Additionally, providing provenance for their\n",
      "decisions and updating their world knowledge remain open research problems. Pre-\n",
      "trained models with a differentiable access mechanism to explicit non-para...\n",
      "Score: 0.9941574335098267\n",
      "Document ID: rag-retrieval-augmented-generation.pdf\n",
      "Metadata: {'PTEX.Fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'CreationDate': 'D:20210413004838Z', 'Keywords': '', 'Producer': 'pdfTeX-1.40.21', 'Author': '', 'Title': '', 'Creator': 'LaTeX with hyperref', 'ModDate': 'D:20210413004838Z', 'Trapped': '/False', 'Subject': '', 'source': 'arxiv', 'year': 2020, 'topic': 'RAG', 'title': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', 'authors': 'Lewis et al.'}\n",
      "\n",
      "--- Result 2 ---\n",
      "Text: arXiv preprint arXiv:2203.05115, 2022. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal,\n",
      "    Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et...\n",
      "Score: 0.8947174549102783\n",
      "Document ID: retrieval-evaluation-metrics.pdf\n",
      "Metadata: {'PTEX.Fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'CreationDate': 'D:20230313000911Z', 'Keywords': '', 'Producer': 'pdfTeX-1.40.21', 'Author': '', 'Title': '', 'Creator': 'LaTeX with hyperref', 'ModDate': 'D:20230313000911Z', 'Trapped': '/False', 'Subject': '', 'source': 'arxiv', 'year': 2022, 'topic': 'retrieval', 'title': 'Retrieval Evaluation Metrics and Methods', 'authors': 'ArXiv 2022'}\n",
      "\n",
      "--- Result 3 ---\n",
      "Text: Additionally, providing provenance for their\n",
      "decisions and updating their world knowledge remain open research problems. Pre-\n",
      "trained models with a differentiable access mechanism to explicit non-para...\n",
      "Score: 0.8945203423500061\n",
      "Document ID: gpt3-language-models.pdf\n",
      "Metadata: {'PTEX.Fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'CreationDate': 'D:20210413004838Z', 'Keywords': '', 'Producer': 'pdfTeX-1.40.21', 'Author': '', 'Title': '', 'Creator': 'LaTeX with hyperref', 'ModDate': 'D:20210413004838Z', 'Trapped': '/False', 'Subject': '', 'source': 'arxiv', 'year': 2020, 'topic': 'LLMs', 'title': 'Language Models are Few-Shot Learners', 'authors': 'Brown et al.'}\n",
      "\n",
      "--- Result 4 ---\n",
      "Text: but have only explored open-domain extractive question answering. Here, we bring hybrid parametric\n",
      "and non-parametric memory to the “workhorse of NLP,” i.e. sequence-to-sequence (seq2seq) models. We e...\n",
      "Score: 0.8935925364494324\n",
      "Document ID: rag-retrieval-augmented-generation.pdf\n",
      "Metadata: {'PTEX.Fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'CreationDate': 'D:20210413004838Z', 'Keywords': '', 'Producer': 'pdfTeX-1.40.21', 'Author': '', 'Title': '', 'Creator': 'LaTeX with hyperref', 'ModDate': 'D:20210413004838Z', 'Trapped': '/False', 'Subject': '', 'source': 'arxiv', 'year': 2020, 'topic': 'RAG', 'title': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', 'authors': 'Lewis et al.'}\n",
      "\n",
      "--- Result 5 ---\n",
      "Text: but have only explored open-domain extractive question answering. Here, we bring hybrid parametric\n",
      "and non-parametric memory to the “workhorse of NLP,” i.e. sequence-to-sequence (seq2seq) models. We e...\n",
      "Score: 0.891611635684967\n",
      "Document ID: gpt3-language-models.pdf\n",
      "Metadata: {'PTEX.Fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'CreationDate': 'D:20210413004838Z', 'Keywords': '', 'Producer': 'pdfTeX-1.40.21', 'Author': '', 'Title': '', 'Creator': 'LaTeX with hyperref', 'ModDate': 'D:20210413004838Z', 'Trapped': '/False', 'Subject': '', 'source': 'arxiv', 'year': 2020, 'topic': 'LLMs', 'title': 'Language Models are Few-Shot Learners', 'authors': 'Brown et al.'}\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    \n",
    "    # Display first 5 search results\n",
    "    print(\"\\n=== Top Search Results ===\")\n",
    "    for i, search_result in enumerate(result.get('search_results', [])[:5], 1):\n",
    "        print(f\"\\n--- Result {i} ---\")\n",
    "        print(f\"Text: {search_result['text'][:200]}...\")\n",
    "        print(f\"Score: {search_result.get('score', 'N/A')}\")\n",
    "        print(f\"Document ID: {search_result.get('document_id', 'N/A')}\")\n",
    "        if 'document_metadata' in search_result:\n",
    "            print(f\"Metadata: {search_result['document_metadata']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee4473a-094f-4d0a-a825-e1213db07240",
   "metadata": {},
   "source": [
    "## Example 2: Querying Multiple Corpora\n",
    "\n",
    "Vectara allows you to query across multiple corpora simultaneously. This is useful when you have data organized across different collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21facbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generated Summary (Multiple Corpora) ===\n",
      "Vectara Agents work by enabling enterprises to build sophisticated, enterprise-grade intelligent applications that go beyond basic question answering. These agents interpret user input, reason through context, leverage external tools, and maintain continuity across multi-turn interactions. Unlike traditional Retrieval Augmented Generation (RAG) systems that simply retrieve documents and pass them to a language model, Vectara agents provide orchestrated workflows capable of taking action, retrieving information, invoking APIs, or maintaining user sessions. This comprehensive framework allows for the creation of AI-powered applications that can autonomously reason through problems, orchestrate multiple tools, maintain conversation context, and integrate with enterprise systems through standardized protocols [1], [6].\n",
      "\n",
      "=== Factual Consistency Score: 0.9609375 ===\n",
      "\n",
      "=== Result Sources ===\n",
      "1. Source: vectara_docs, Title: Agents\n",
      "2. Source: vectara_docs, Title: The Vectara Platform\n",
      "3. Source: vectara_docs, Title: Getting Started\n",
      "4. Source: vectara_docs, Title: Agents\n",
      "5. Source: vectara_docs, Title: Community Collaborations and Partnerships\n"
     ]
    }
   ],
   "source": [
    "# Query both corpora simultaneously\n",
    "# This combines results from research papers AND documentation\n",
    "multi_corpus_request = {\n",
    "    \"query\": \"How do Agents work with Vectara?\",\n",
    "    \"search\": {\n",
    "        \"corpora\": [\n",
    "            {\n",
    "                \"corpus_key\": research_corpus_key,\n",
    "                \"lexical_interpolation\": 0.005\n",
    "            },\n",
    "            {\n",
    "                \"corpus_key\": docs_corpus_key,\n",
    "                \"lexical_interpolation\": 0.005\n",
    "            }\n",
    "        ],\n",
    "        \"limit\": 100,\n",
    "        \"context_configuration\": {\n",
    "            \"sentences_before\": 2,\n",
    "            \"sentences_after\": 2\n",
    "        },\n",
    "        \"reranker\": {\n",
    "            \"type\": \"chain\",\n",
    "            \"rerankers\": [\n",
    "                {\n",
    "                    \"type\": \"customer_reranker\",\n",
    "                    \"reranker_id\": \"rnk_272725719\",\n",
    "                    \"limit\": 30\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"mmr\",\n",
    "                    \"diversity_bias\": 0.05\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    },\n",
    "    \"generation\": {\n",
    "        \"generation_preset_name\": \"vectara-summary-ext-24-05-med-omni\",\n",
    "        \"max_used_search_results\": 10,\n",
    "        \"response_language\": \"eng\",\n",
    "        \"enable_factual_consistency_score\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/query\", headers=headers, json=multi_corpus_request)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(\"\\n=== Generated Summary (Multiple Corpora) ===\")\n",
    "    print(result['summary'])\n",
    "    print(f\"\\n=== Factual Consistency Score: {result.get('factual_consistency_score', 'N/A')} ===\")\n",
    "    \n",
    "    # Show which corpus each result came from\n",
    "    print(\"\\n=== Result Sources ===\")\n",
    "    for i, search_result in enumerate(result.get('search_results', [])[:5], 1):\n",
    "        doc_meta = search_result.get('document_metadata', {})\n",
    "        source = doc_meta.get('source', 'unknown')\n",
    "        title = doc_meta.get('title', 'N/A')\n",
    "        print(f\"{i}. Source: {source}, Title: {title}\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760bd62a-d6cb-4899-bfda-29f632c3b482",
   "metadata": {},
   "source": [
    "## Example 3: Metadata Filtering\n",
    "\n",
    "You can filter search results using metadata filters. This allows you to narrow down results based on document or chunk-level metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fe7a8fe-cfb8-4132-a676-5aa2b38d21d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generated Summary (With Metadata Filter) ===\n",
      "The key innovations in Retrieval-Augmented Generation (RAG) include the integration of retrieval mechanisms with generation models to enhance the accuracy and reliability of generated content. This approach allows large language models (LLMs) to access external knowledge sources, thereby reducing the likelihood of hallucinations—instances where the model generates unsupported or incorrect information. Innovations also involve the development of benchmarks like RAGTruth, which provide datasets for evaluating and improving the factual accuracy of RAG systems. Additionally, there are advancements in hallucination detection and editing techniques, which aim to identify and correct inaccuracies in generated text, further enhancing the trustworthiness of RAG applications [5], [10].\n",
      "\n",
      "=== Number of results: 30 ===\n",
      "\n",
      "=== Filtered Papers ===\n",
      "- Hallucination Detection in RAG Systems (2025) - Topic: RAG\n",
      "- Hallucination Detection in RAG Systems (2025) - Topic: RAG\n",
      "- Hallucination Detection in RAG Systems (2025) - Topic: RAG\n"
     ]
    }
   ],
   "source": [
    "# Example with metadata filtering\n",
    "# Filter to only get research papers from 2020 or later\n",
    "filtered_request = {\n",
    "    \"query\": \"What are the key innovations in retrieval augmented generation?\",\n",
    "    \"search\": {\n",
    "        \"corpora\": [\n",
    "            {\n",
    "                \"corpus_key\": research_corpus_key,\n",
    "                \"lexical_interpolation\": 0.005,\n",
    "                # Filter for recent RAG papers\n",
    "                \"metadata_filter\": \"doc.year >= 2023\"\n",
    "            }\n",
    "        ],\n",
    "        \"limit\": 100,\n",
    "        \"context_configuration\": {\n",
    "            \"sentences_before\": 2,\n",
    "            \"sentences_after\": 2\n",
    "        },\n",
    "        \"reranker\": {\n",
    "            \"type\": \"chain\",\n",
    "            \"rerankers\": [\n",
    "                {\n",
    "                    \"type\": \"customer_reranker\",\n",
    "                    \"reranker_id\": \"rnk_272725719\",\n",
    "                    \"limit\": 30\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"mmr\",\n",
    "                    \"diversity_bias\": 0.05\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    },\n",
    "    \"generation\": {\n",
    "        \"generation_preset_name\": \"vectara-summary-ext-24-05-med-omni\",\n",
    "        \"max_used_search_results\": 10,\n",
    "        \"response_language\": \"eng\",\n",
    "        \"enable_factual_consistency_score\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/query\", headers=headers, json=filtered_request)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(\"\\n=== Generated Summary (With Metadata Filter) ===\")\n",
    "    print(result['summary'])\n",
    "    print(f\"\\n=== Number of results: {len(result.get('search_results', []))} ===\")\n",
    "    \n",
    "    # Show filtered results\n",
    "    print(\"\\n=== Filtered Papers ===\")\n",
    "    for search_result in result.get('search_results', [])[:3]:\n",
    "        doc_meta = search_result.get('document_metadata', {})\n",
    "        print(f\"- {doc_meta.get('title', 'N/A')} ({doc_meta.get('year', 'N/A')}) - Topic: {doc_meta.get('topic', 'N/A')}\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9643b59-2424-4a54-89aa-5116f052a541",
   "metadata": {},
   "source": [
    "## Example 4: Streaming Responses\n",
    "\n",
    "For better user experience, you can stream the generated response in real-time using Server-Sent Events (SSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe64d30c-eead-4f40-969e-be18033bdea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Streaming Response ===\n",
      "To use chunking with Vectara, you can choose between sentence-based and character-based chunking strategies. By default, Vectara uses sentence-based chunking, where each chunk contains one complete sentence. This method can lead to higher retrieval latency due to the increased number of chunks. Alternatively, you can opt for character-based chunking to create larger chunks by setting the type to `max_chars_chunking_strategy` and defining the `max_chars_per_chunk` value. This allows you to create chunks containing 3-7 sentences (512 to 1024 characters), balancing retrieval speed and contextual integrity [1], [2], [3].\n",
      "\n",
      "=== FCS: 0.78125 ===\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Streaming query request - query the documentation corpus\n",
    "streaming_request = {\n",
    "    \"query\": \"How do I use chunking with Vectara\",\n",
    "    \"stream_response\": True,\n",
    "    \"search\": {\n",
    "        \"corpora\": [\n",
    "            {\n",
    "                \"corpus_key\": docs_corpus_key,\n",
    "                \"lexical_interpolation\": 0.005\n",
    "            }\n",
    "        ],\n",
    "        \"limit\": 100,\n",
    "        \"context_configuration\": {\n",
    "            \"sentences_before\": 2,\n",
    "            \"sentences_after\": 2\n",
    "        },\n",
    "        \"reranker\": {\n",
    "            \"type\": \"chain\",\n",
    "            \"rerankers\": [\n",
    "                {\n",
    "                    \"type\": \"customer_reranker\",\n",
    "                    \"reranker_id\": \"rnk_272725719\",\n",
    "                    \"limit\": 30\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"mmr\",\n",
    "                    \"diversity_bias\": 0.05\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    },\n",
    "    \"generation\": {\n",
    "        \"generation_preset_name\": \"vectara-summary-ext-24-05-med-omni\",\n",
    "        \"max_used_search_results\": 15,\n",
    "        \"response_language\": \"eng\",\n",
    "        \"enable_factual_consistency_score\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Make streaming request\n",
    "streaming_headers = headers.copy()\n",
    "streaming_headers['Accept'] = 'text/event-stream'\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{BASE_URL}/query\",\n",
    "    headers=streaming_headers,\n",
    "    json=streaming_request,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "print(\"\\n=== Streaming Response ===\")\n",
    "if response.status_code == 200:\n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            line_str = line.decode('utf-8')\n",
    "            if line_str.startswith('data:'):\n",
    "                try:\n",
    "                    data = json.loads(line_str[5:])  # Remove 'data: ' prefix\n",
    "                    # Handle different event types\n",
    "                    if data.get('type') == 'generation_chunk':\n",
    "                        # Print generation text as it arrives\n",
    "                        print(data.get('generation_chunk', ''), end='', flush=True)\n",
    "                    elif data.get('type') == 'factual_consistency_score':\n",
    "                        print(f\"\\n\\n=== FCS: {data.get('factual_consistency_score')} ===\")\n",
    "                    elif data.get('type') == 'search_results':\n",
    "                        # Search results arrive before generation starts\n",
    "                        pass\n",
    "                except json.JSONDecodeError:\n",
    "                    pass\n",
    "    print(\"\\n\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t98ft4j3tmg",
   "metadata": {},
   "source": [
    "## Example 5: Custom Prompts with prompt_template\n",
    "\n",
    "Vectara's Prompt Engine allows you to customize the LLM behavior beyond the default presets by using the `prompt_template` parameter. You can use Velocity Template syntax to access variables like:\n",
    "- `$vectaraQuery` - The user's query text\n",
    "- `$vectaraQueryResults` - Array of retrieved search results\n",
    "- `$vectaraLangCode` - ISO639 language code (e.g., \"eng\")\n",
    "- `$vectaraOutChars` - Character limit for output\n",
    "\n",
    "This example demonstrates how to create a custom prompt that formats responses in a specific way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5wuzfuoidbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generated Response with Custom Prompt ===\n",
      "To improve retrieval quality in Retrieval-Augmented Generation (RAG) systems, it is essential to focus on optimizing the retrieval mechanism, as it plays a crucial role in the overall performance of the system. The retrieved context highlights several strategies and considerations for enhancing retrieval quality.\n",
      "\n",
      "### Key Points\n",
      "\n",
      "- **Learned Retrieval vs. Fixed Systems**: \n",
      "  - RAG systems benefit from learned retrieval mechanisms, which have been shown to improve results across various tasks compared to fixed systems like BM25. \n",
      "  - For specific tasks like FEVER, which are entity-centric, BM25 may perform better due to its word overlap-based retrieval approach.\n",
      "\n",
      "- **Retrieval Ablations**:\n",
      "  - Freezing the retriever during training can help assess the effectiveness of the retrieval mechanism. Learned retrieval consistently improves task performance, indicating the importance of dynamic retrieval learning.\n",
      "\n",
      "- **Avoiding Retrieval Collapse**:\n",
      "  - In some tasks, the retrieval component may \"collapse,\" retrieving the same documents regardless of input. This can lead to the generator ignoring the retrieved documents, reducing the system's effectiveness.\n",
      "  - Ensuring a diverse and informative retrieval process is crucial to prevent this collapse.\n",
      "\n",
      "- **Diversity in Generation**:\n",
      "  - Promoting diversity in the generated outputs can enhance the system's ability to provide varied and contextually relevant information, which indirectly supports better retrieval by encouraging a broader exploration of the document space.\n",
      "\n",
      "- **Hot-Swapping Retrieval Index**:\n",
      "  - The retrieval index in RAG models can be updated without retraining the entire model, allowing for flexibility and adaptability in retrieval strategies.\n",
      "\n",
      "### Conclusion and Recommendations\n",
      "\n",
      "To improve retrieval quality in RAG systems, it is recommended to:\n",
      "\n",
      "1. **Implement Learned Retrieval**: Focus on training the retrieval component dynamically rather than relying on static systems like BM25, except in specific cases where word overlap is advantageous.\n",
      "   \n",
      "2. **Monitor and Prevent Retrieval Collapse**: Regularly evaluate the retrieval process to ensure it remains diverse and informative, preventing the system from defaulting to non-informative retrieval patterns.\n",
      "\n",
      "3. **Enhance Generation Diversity**: Encourage diversity in the generated outputs to support a more robust retrieval process, which can lead to more accurate and contextually relevant information retrieval.\n",
      "\n",
      "4. **Utilize Flexible Retrieval Indexing**: Take advantage of the ability to update the retrieval index without full retraining, allowing the system to adapt to new information and improve retrieval quality over time.\n",
      "\n",
      "By focusing on these strategies, RAG systems can achieve higher retrieval quality, leading to better performance across various tasks.\n",
      "\n",
      "=== Factual Consistency Score: 0.734375 ===\n"
     ]
    }
   ],
   "source": [
    "# Custom prompt template using Velocity syntax\n",
    "# This example creates a structured response with sections and bullet points\n",
    "custom_prompt_template = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are a helpful AI assistant that provides clear, well-structured answers. \n",
    "Your responses should be formatted with the following sections:\n",
    "1. A brief summary (2-3 sentences)\n",
    "2. Key points as bullet points\n",
    "3. A conclusion with actionable recommendations\n",
    "\n",
    "Use the search results provided to ground your answer in facts.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"\"\"Question: $vectaraQuery\n",
    "\n",
    "Retrieved Context:\n",
    "#foreach ($qResult in $vectaraQueryResults)\n",
    "- $qResult.text()\n",
    "#end\n",
    "\n",
    "Please provide a well-structured answer to the question above using the retrieved context. Format your response with clear sections as instructed.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Query request with custom prompt\n",
    "custom_prompt_request = {\n",
    "    \"query\": \"How can I improve retrieval quality in RAG systems?\",\n",
    "    \"search\": {\n",
    "        \"corpora\": [\n",
    "            {\n",
    "                \"corpus_key\": research_corpus_key,\n",
    "                \"lexical_interpolation\": 0.005\n",
    "            }\n",
    "        ],\n",
    "        \"limit\": 100,\n",
    "        \"context_configuration\": {\n",
    "            \"sentences_before\": 2,\n",
    "            \"sentences_after\": 2\n",
    "        },\n",
    "        \"reranker\": {\n",
    "            \"type\": \"chain\",\n",
    "            \"rerankers\": [\n",
    "                {\n",
    "                    \"type\": \"customer_reranker\",\n",
    "                    \"reranker_id\": \"rnk_272725719\",\n",
    "                    \"limit\": 30\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"mmr\",\n",
    "                    \"diversity_bias\": 0.05\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    },\n",
    "    \"generation\": {\n",
    "        \"prompt_template\": json.dumps(custom_prompt_template),\n",
    "        \"generation_preset_name\": \"vectara-summary-ext-24-05-med-omni\",\n",
    "        \"max_used_search_results\": 10,\n",
    "        \"response_language\": \"eng\",\n",
    "        \"enable_factual_consistency_score\": True\n",
    "    },\n",
    "    \"save_history\": True\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/query\", headers=headers, json=custom_prompt_request)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(\"\\n=== Generated Response with Custom Prompt ===\")\n",
    "    print(result['summary'])\n",
    "    print(f\"\\n=== Factual Consistency Score: {result.get('factual_consistency_score', 'N/A')} ===\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w354a6255rs",
   "metadata": {},
   "source": [
    "### Advanced Custom Prompt: Accessing Metadata\n",
    "\n",
    "You can also access document and part metadata within your custom prompts using:\n",
    "- `$qResult.docMetadata()` - Access document-level metadata\n",
    "- `$qResult.partMetadata()` - Access chunk-level metadata\n",
    "- `.get('fieldname')` - Retrieve specific metadata fields\n",
    "\n",
    "This example shows how to create a prompt that includes citation information with metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mbsnuv6fnfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Response with Metadata-Rich Custom Prompt ===\n",
      "Retrieval-Augmented Generation (RAG) systems, while offering significant advantages in generating more specific and factually accurate responses, also face several challenges. These challenges are highlighted in the research papers \"Language Models are Few-Shot Learners\" and \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.\"\n",
      "\n",
      "1. **Factual Inaccuracies and Bias**: One of the primary challenges with RAG systems is the reliance on external knowledge sources, such as Wikipedia, which may not always be entirely factual or free from bias. This can lead to the generation of content that is misleading or biased. The paper \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\" notes that these external sources are never entirely factual and devoid of bias, which poses a risk when RAG systems are used to generate content (Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks).\n",
      "\n",
      "2. **Potential for Misuse**: Similar to other advanced language models, RAG systems can be misused to generate abusive, fake, or misleading content, impersonate others, or automate spam/phishing content. This concern is echoed in both papers, which draw parallels to the potential misuse of models like GPT-2. The paper \"Language Models are Few-Shot Learners\" highlights these risks, suggesting that RAG systems could be used to generate misleading content in news or social media (Language Models are Few-Shot Learners).\n",
      "\n",
      "3. **Automation of Jobs**: The automation capabilities of RAG systems could lead to the displacement of jobs, as they can perform tasks that traditionally require human intervention. This is a broader concern associated with advanced AI systems, as noted in the paper \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks,\" which mentions the potential for job automation in the coming decades (Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks).\n",
      "\n",
      "4. **Complexity in Training and Fine-Tuning**: RAG systems involve complex architectures that integrate both parametric and non-parametric memory components. The training and fine-tuning of these systems require careful consideration to ensure that both the retriever and generator components are effectively learned. The paper \"Language Models are Few-Shot Learners\" discusses the intricacies of marginalizing latent documents and the joint learning of the generator and retriever, which adds to the complexity of deploying RAG systems (Language Models are Few-Shot Learners).\n",
      "\n",
      "5. **Dependence on Retrieval Quality**: The performance of RAG systems heavily depends on the quality of the retrieval component. If the retriever fails to provide relevant documents, the generation component may produce inaccurate or irrelevant responses. The paper \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\" emphasizes the importance of the retriever, which is initialized using the Dense Passage Retriever (DPR), to ensure high-quality retrieval (Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks).\n",
      "\n",
      "In summary, while RAG systems offer enhanced capabilities for generating knowledge-intensive content, they also present challenges related to factual accuracy, potential misuse, job automation, training complexity, and retrieval quality. Addressing these challenges is crucial for the responsible deployment of RAG systems in various applications.\n",
      "\n",
      "=== Factual Consistency Score: 0.05834961 ===\n"
     ]
    }
   ],
   "source": [
    "# Advanced custom prompt with metadata access\n",
    "# This prompt includes paper titles and authors in the context\n",
    "advanced_prompt_template = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are a research assistant helping to synthesize information from academic papers. \n",
    "Provide a comprehensive answer citing specific papers by their title and authors.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Question: $vectaraQuery\n",
    "\n",
    "Research Papers Context:\n",
    "#foreach ($qResult in $vectaraQueryResults)\n",
    "---\n",
    "Title: $qResult.docMetadata().get('title')\n",
    "Topic: $qResult.docMetadata().get('topic')\n",
    "Content: $qResult.text()\n",
    "\n",
    "#end\n",
    "\n",
    "Based on the research papers above, provide a detailed answer that cites specific papers by title.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Query with advanced custom prompt\n",
    "advanced_prompt_request = {\n",
    "    \"query\": \"What are the challenges with RAG systems?\",\n",
    "    \"search\": {\n",
    "        \"corpora\": [\n",
    "            {\n",
    "                \"corpus_key\": research_corpus_key,\n",
    "                \"lexical_interpolation\": 0.005\n",
    "            }\n",
    "        ],\n",
    "        \"limit\": 100,\n",
    "        \"context_configuration\": {\n",
    "            \"sentences_before\": 2,\n",
    "            \"sentences_after\": 2\n",
    "        },\n",
    "        \"reranker\": {\n",
    "            \"type\": \"chain\",\n",
    "            \"rerankers\": [\n",
    "                {\n",
    "                    \"type\": \"customer_reranker\",\n",
    "                    \"reranker_id\": \"rnk_272725719\",\n",
    "                    \"limit\": 30\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"mmr\",\n",
    "                    \"diversity_bias\": 0.05\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    },\n",
    "    \"generation\": {\n",
    "        \"prompt_template\": json.dumps(advanced_prompt_template),\n",
    "        \"generation_preset_name\": \"vectara-summary-ext-24-05-med-omni\",\n",
    "        \"max_used_search_results\": 7,\n",
    "        \"response_language\": \"eng\",\n",
    "        \"enable_factual_consistency_score\": True\n",
    "    },\n",
    "    \"save_history\": True,\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/query\", headers=headers, json=advanced_prompt_request)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(\"\\n=== Response with Metadata-Rich Custom Prompt ===\")\n",
    "    print(result['summary'])\n",
    "    print(f\"\\n=== Factual Consistency Score: {result.get('factual_consistency_score', 'N/A')} ===\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74489379-3dc3-42ff-a40c-098fb96d4047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ce665e-b9bb-4a6e-aa0e-235dd8c84c44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
