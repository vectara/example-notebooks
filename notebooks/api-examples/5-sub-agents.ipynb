{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/vectara/example-notebooks/blob/main/notebooks/api-examples/5-sub-agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "# Vectara Sub-Agents: Building Modular AI Workflows\n",
    "\n",
    "This notebook demonstrates how to use Vectara's **sub-agents** capability to build modular, specialized AI workflows. Sub-agents allow a parent agent to delegate tasks to specialized child agents, enabling:\n",
    "\n",
    "- **Context isolation**: Each sub-agent maintains its own conversation history\n",
    "- **Specialized configuration**: Each sub-agent can have distinct instructions and tools\n",
    "- **Reusability**: Build once, invoke from any parent agent\n",
    "- **Parallel execution**: Run multiple sub-agents simultaneously\n",
    "- **Better performance**: Smaller, focused agents make fewer mistakes\n",
    "\n",
    "We also demonstrate combining sub-agents with a **Lambda Tool** (API Payload Validator) that validates generated API code to catch hallucinations and ensure correctness before presenting to users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## About Vectara\n",
    "\n",
    "[Vectara](https://vectara.com/) is the Agent Operating System for trusted enterprise AI: a unified Agentic RAG platform with built-in multi-modal retrieval, orchestration, and always-on governance. Deploy it on-prem (air-gapped), in your VPC, or as SaaS.\n",
    "\n",
    "Vectara provides a complete API-first platform for building production RAG and agentic applications:\n",
    "\n",
    "- **Simple Integration**: RESTful APIs and SDKs (Python, JavaScript) for quick integration into any stack\n",
    "- **Flexible Deployment**: Choose SaaS, VPC, or on-premises deployment based on your security requirements\n",
    "- **Multi-Modal Support**: Index and search across text, tables, and images from PDFs, documents, and structured data\n",
    "- **Advanced Retrieval**: Hybrid search combining semantic and keyword matching with state-of-the-art reranking\n",
    "- **Grounded Generation**: LLM responses with citations and factual consistency scores to reduce hallucinations\n",
    "- **Enterprise-Ready**: Built-in access controls, audit logging, and compliance (SOC2, HIPAA) from day one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "This notebook assumes you've completed Notebooks 1-4:\n",
    "- Notebook 1: Created two corpora (ai-research-papers and vectara-docs)\n",
    "- Notebook 2: Ingested AI research papers and Vectara documentation\n",
    "- Notebook 3: Queried the data with various techniques\n",
    "- Notebook 4: Created agents that can search and reason across data\n",
    "\n",
    "Now we'll create a multi-agent system where specialized sub-agents handle domain-specific tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Why Sub-Agents?\n",
    "\n",
    "When agents face complex, multi-step tasks, they often run into context window limits or need specialized capabilities. Consider a comprehensive research assistant that needs to:\n",
    "\n",
    "1. Analyze academic papers for theoretical foundations\n",
    "2. Search product documentation for implementation details\n",
    "3. Synthesize findings into actionable recommendations\n",
    "\n",
    "A single monolithic agent trying to handle all of this might:\n",
    "- Become confused between different instruction sets\n",
    "- Consume excessive context with domain-specific guidelines\n",
    "- Produce lower quality results due to competing priorities\n",
    "\n",
    "**Sub-agents solve this by delegation**: the parent agent orchestrates, while specialized sub-agents focus on their domains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Corpus: tutorial-ai-research-papers\n",
      "Docs Corpus: tutorial-vectara-docs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Get credentials from environment variables\n",
    "api_key = os.environ['VECTARA_API_KEY']\n",
    "\n",
    "# Corpus keys from previous notebooks\n",
    "research_corpus_key = 'tutorial-ai-research-papers'\n",
    "docs_corpus_key = 'tutorial-vectara-docs'\n",
    "\n",
    "# Base API URL\n",
    "BASE_URL = \"https://api.vectara.io/v2\"\n",
    "\n",
    "# Common headers\n",
    "headers = {\n",
    "    \"x-api-key\": api_key,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "print(f\"Research Corpus: {research_corpus_key}\")\n",
    "print(f\"Docs Corpus: {docs_corpus_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 1: Create Specialized Sub-Agents\n",
    "\n",
    "We'll create three specialized agents that will serve as sub-agents:\n",
    "\n",
    "1. **Research Paper Analyst**: Expert at analyzing academic papers on RAG, embeddings, and retrieval\n",
    "2. **Documentation Expert**: Expert at finding implementation guidance from Vectara docs\n",
    "3. **Web Search Expert**: Expert at searching the web for current information and news\n",
    "\n",
    "Each agent has focused instructions and tools optimized for its domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### Sub-Agent 1: Research Paper Analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to delete and create agent\n",
    "def delete_and_create_agent(agent_config, agent_name):\n",
    "    \"\"\"Delete agent if it exists, then create a new one.\"\"\"\n",
    "    # Check if agent already exists and delete it\n",
    "    list_response = requests.get(f\"{BASE_URL}/agents\", headers=headers)\n",
    "\n",
    "    if list_response.status_code == 200:\n",
    "        agents = list_response.json().get('agents', [])\n",
    "        for agent in agents:\n",
    "            if agent.get('name') == agent_name:\n",
    "                existing_key = agent['key']\n",
    "                print(f\"Deleting existing agent '{agent_name}' ({existing_key})\")\n",
    "                delete_response = requests.delete(f\"{BASE_URL}/agents/{existing_key}\", headers=headers)\n",
    "                if delete_response.status_code == 204:\n",
    "                    print(f\"Deleted agent: {existing_key}\")\n",
    "                else:\n",
    "                    print(f\"Error deleting {existing_key}: {delete_response.text}\")\n",
    "                break\n",
    "\n",
    "    # Create new agent\n",
    "    response = requests.post(f\"{BASE_URL}/agents\", headers=headers, json=agent_config)\n",
    "\n",
    "    if response.status_code == 201:\n",
    "        agent_data = response.json()\n",
    "        print(f\"Created agent '{agent_name}'\")\n",
    "        print(f\"Agent Key: {agent_data['key']}\")\n",
    "        return agent_data['key']\n",
    "    else:\n",
    "        print(f\"Error creating agent: {response.status_code}\")\n",
    "        print(f\"{response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent 'Research Paper Analyst'\n",
      "Agent Key: agt_research_paper_analyst_084e\n"
     ]
    }
   ],
   "source": [
    "# Create Research Paper Analyst sub-agent\n",
    "reranker_config = {\n",
    "    \"type\": \"chain\",\n",
    "    \"rerankers\": [\n",
    "        {\n",
    "            \"type\": \"customer_reranker\",\n",
    "            \"reranker_id\": \"rnk_272725719\", \n",
    "            \"limit\": 25,\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"mmr\",\n",
    "            \"diversity_bias\": 0.05\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "research_analyst_config = {\n",
    "    \"name\": \"Research Paper Analyst\",\n",
    "    \"description\": \"Specialized agent for analyzing academic research papers on RAG, embeddings, and retrieval techniques\",\n",
    "    \"model\": {\"name\": \"gpt-4o\"},\n",
    "    \"first_step\": {\n",
    "        \"type\": \"conversational\",\n",
    "        \"instructions\": [\n",
    "            {\n",
    "                \"type\": \"inline\",\n",
    "                \"name\": \"research_analyst_instructions\",\n",
    "                \"template\": \"\"\"You are an expert academic research analyst specializing in AI, machine learning, and natural language processing.\n",
    "\n",
    "Your expertise includes:\n",
    "- Retrieval Augmented Generation (RAG) architectures\n",
    "- Dense and sparse retrieval methods\n",
    "- Embedding models and vector representations\n",
    "- Transformer architectures and attention mechanisms\n",
    "- Information retrieval benchmarks and evaluation metrics\n",
    "\n",
    "When analyzing research papers:\n",
    "1. Identify the key contributions and novel techniques\n",
    "2. Explain technical concepts clearly with examples\n",
    "3. Highlight practical implications and limitations\n",
    "4. Compare with related work when relevant\n",
    "5. Provide citations to the source papers\n",
    "\n",
    "Always use tools to retrieve relevant content to answer user queries.\n",
    "Always ground your response in the retrieved content. \n",
    "If you cannot answer the user question from the retrieved content from tools, just say \"I don't know\"\n",
    "\n",
    "IMPORTANT: When responding, provide a complete, self-contained summary that includes all relevant findings.\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        \"output_parser\": {\"type\": \"default\"}\n",
    "    },\n",
    "    \"tool_configurations\": {\n",
    "        \"research_search\": {\n",
    "            \"type\": \"corpora_search\",\n",
    "            \"query_configuration\": {\n",
    "                \"search\": {\n",
    "                    \"corpora\": [{\"corpus_key\": research_corpus_key}],\n",
    "                    \"limit\": 100,\n",
    "                    \"context_configuration\": {\n",
    "                        \"sentences_before\": 2,\n",
    "                        \"sentences_after\": 2\n",
    "                    },\n",
    "                    \"reranker\": reranker_config,                   \n",
    "                },\n",
    "                \"save_history\": True,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "research_analyst_key = delete_and_create_agent(research_analyst_config, \"Research Paper Analyst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "### Sub-Agent 2: Vectara Documentation Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent 'Documentation Expert'\n",
      "Agent Key: agt_documentation_expert_004b\n"
     ]
    }
   ],
   "source": [
    "# Create Documentation Expert sub-agent\n",
    "\n",
    "docs_expert_config = {\n",
    "    \"name\": \"Documentation Expert\",\n",
    "    \"description\": \"Specialized agent for finding implementation guidance and best practices from Vectara documentation\",\n",
    "    \"model\": {\"name\": \"gpt-4o\"},\n",
    "    \"first_step\": {\n",
    "        \"type\": \"conversational\",\n",
    "        \"instructions\": [\n",
    "            {\n",
    "                \"type\": \"inline\",\n",
    "                \"name\": \"docs_expert_instructions\",\n",
    "                \"template\": \"\"\"You are a Vectara platform expert who helps developers implement AI solutions.\n",
    "\n",
    "Your expertise includes:\n",
    "- Vectara API integration (indexing, querying, agents)\n",
    "- Corpus management and configuration\n",
    "- Search optimization (hybrid search, reranking, filters)\n",
    "- RAG implementation best practices\n",
    "- SDK usage and code examples\n",
    "\n",
    "When providing guidance:\n",
    "1. Give specific, actionable implementation steps using the API.\n",
    "2. Include relevant API endpoints and parameters\n",
    "3. Your examples should show how to use the API, not using Vectara SDK.\n",
    "4. Highlight configuration options and trade-offs\n",
    "5. Point to relevant documentation sections\n",
    "\n",
    "Always use tools to retrieve relevant content to answer user queries.\n",
    "Always ground your response in the retrieved content. \n",
    "If you cannot answer the user question from the retrieved content from tools, just say \"I don't know\"\n",
    "\n",
    "When responding, provide a complete, self-contained answer with all implementation details.\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        \"output_parser\": {\"type\": \"default\"}\n",
    "    },\n",
    "    \"tool_configurations\": {\n",
    "        \"docs_search\": {\n",
    "            \"type\": \"corpora_search\",\n",
    "            \"query_configuration\": {\n",
    "                \"search\": {\n",
    "                    \"corpora\": [{\"corpus_key\": docs_corpus_key}],\n",
    "                    \"limit\": 100,\n",
    "                    \"context_configuration\": {\n",
    "                        \"sentences_before\": 2,\n",
    "                        \"sentences_after\": 2\n",
    "                    },\n",
    "                    \"reranker\": reranker_config,                   \n",
    "                },\n",
    "                \"save_history\": True,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "docs_expert_key = delete_and_create_agent(docs_expert_config, \"Documentation Expert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ir8dahqid7b",
   "metadata": {},
   "source": [
    "### Sub-Agent 3: Web Search Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8j6idifi4m3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent 'Web Search Expert'\n",
      "Agent Key: agt_web_search_expert_235c\n"
     ]
    }
   ],
   "source": [
    "# Create Web Search Expert sub-agent\n",
    "\n",
    "web_search_expert_config = {\n",
    "    \"name\": \"Web Search Expert\",\n",
    "    \"description\": \"Specialized agent for searching the web for current information, news, and general knowledge\",\n",
    "    \"model\": {\"name\": \"gpt-4o\"},\n",
    "    \"first_step\": {\n",
    "        \"type\": \"conversational\",\n",
    "        \"instructions\": [\n",
    "            {\n",
    "                \"type\": \"inline\",\n",
    "                \"name\": \"web_search_expert_instructions\",\n",
    "                \"template\": \"\"\"You are a web search expert who helps find current and relevant information from the internet.\n",
    "\n",
    "Your expertise includes:\n",
    "- Finding up-to-date information on any topic\n",
    "- Researching current events and news\n",
    "- Locating authoritative sources and references\n",
    "- Comparing information across multiple sources\n",
    "- Fact-checking and verification\n",
    "\n",
    "When searching and responding:\n",
    "1. Use web search to find relevant, current information\n",
    "2. Prioritize authoritative and credible sources\n",
    "3. Provide context about when information was published\n",
    "4. Cite your sources with URLs when available\n",
    "5. Synthesize information from multiple sources when appropriate\n",
    "\n",
    "Always use the web search tool to find information.\n",
    "If you cannot find relevant information, say so clearly.\n",
    "\n",
    "IMPORTANT: When responding, provide a complete, well-sourced answer with citations.\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        \"output_parser\": {\"type\": \"default\"}\n",
    "    },\n",
    "    \"tool_configurations\": {\n",
    "        \"web_search\": {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "web_search_expert_key = delete_and_create_agent(web_search_expert_config, \"Web Search Expert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4n995hnpf",
   "metadata": {},
   "source": [
    "## Step 2: Create an API Validator Lambda Tool\n",
    "\n",
    "Before creating the orchestrator, we'll add a **Lambda Tool** that validates Vectara API payloads. This tool is *essential* for answering implementation questions because:\n",
    "\n",
    "- LLMs may hallucinate field names (e.g., `corpus_id` instead of `corpus_key`)\n",
    "- Parameter ranges need validation (e.g., `lexical_interpolation` must be 0-1)\n",
    "- Required fields must be present for the code to actually work\n",
    "- The orchestrator can't claim code is \"working\" without validating it first\n",
    "\n",
    "Unlike optional analysis tools that LLMs may skip, this validator is essential—the orchestrator must use it before presenting API code examples to ensure correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "nurhxwplzh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to manage lambda tools\n",
    "def delete_and_create_tool(tool_config, tool_name):\n",
    "    \"\"\"Delete tool if it exists, then create a new one.\"\"\"\n",
    "    list_response = requests.get(f\"{BASE_URL}/tools\", headers=headers)\n",
    "    \n",
    "    if list_response.status_code == 200:\n",
    "        tools = list_response.json().get('tools', [])\n",
    "        for tool in tools:\n",
    "            if tool.get('name') == tool_name:\n",
    "                existing_id = tool['id']\n",
    "                print(f\"Deleting existing tool '{tool_name}' ({existing_id})\")\n",
    "                delete_response = requests.delete(f\"{BASE_URL}/tools/{existing_id}\", headers=headers)\n",
    "                if delete_response.status_code == 204:\n",
    "                    print(f\"Deleted tool: {existing_id}\")\n",
    "                break\n",
    "    \n",
    "    response = requests.post(f\"{BASE_URL}/tools\", headers=headers, json=tool_config)\n",
    "    \n",
    "    if response.status_code == 201:\n",
    "        tool_data = response.json()\n",
    "        print(f\"Created tool '{tool_name}'\")\n",
    "        print(f\"Tool ID: {tool_data['id']}\")\n",
    "        return tool_data['id']\n",
    "    else:\n",
    "        print(f\"Error creating tool: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3umya5qan8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created tool 'vectara_api_validator'\n",
      "Tool ID: tol_2221\n"
     ]
    }
   ],
   "source": [
    "# Create the Vectara API Payload Validator lambda tool\n",
    "api_validator_code = '''\n",
    "import json\n",
    "\n",
    "def process(\n",
    "    endpoint: str,\n",
    "    payload: str,\n",
    "    method: str = \"POST\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Validate a Vectara API request payload.\n",
    "    \n",
    "    Args:\n",
    "        endpoint: API endpoint (query, index, corpus, agents)\n",
    "        payload: JSON string of the request body\n",
    "        method: HTTP method (POST, GET, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        Validation result with errors, warnings, and corrected payload\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    warnings = []\n",
    "    \n",
    "    # Parse the payload\n",
    "    try:\n",
    "        data = json.loads(payload)\n",
    "    except json.JSONDecodeError as e:\n",
    "        return {\n",
    "            \"valid\": False,\n",
    "            \"endpoint\": endpoint,\n",
    "            \"errors\": [f\"Invalid JSON: {str(e)}\"],\n",
    "            \"warnings\": [],\n",
    "            \"corrected_payload\": None\n",
    "        }\n",
    "    \n",
    "    corrected = dict(data)\n",
    "\n",
    "    # Validate API version - must use v2, not v1\n",
    "    if 'vectara.io' in endpoint:\n",
    "        if '/v1/' in endpoint or '/v1' in endpoint:\n",
    "            errors.append(\"Invalid API version: v1 is deprecated. Use https://api.vectara.io/v2 endpoints.\")\n",
    "\n",
    "    # Validation rules by endpoint\n",
    "    if endpoint == \"query\":\n",
    "        # Required fields\n",
    "        if \"query\" not in data:\n",
    "            errors.append(\"Missing required field: 'query'\")\n",
    "            corrected[\"query\"] = \"<YOUR_QUERY>\"\n",
    "        \n",
    "        if \"search\" not in data:\n",
    "            errors.append(\"Missing required field: 'search'\")\n",
    "            corrected[\"search\"] = {\"corpora\": [{\"corpus_key\": \"<YOUR_CORPUS_KEY>\"}]}\n",
    "        else:\n",
    "            search = data.get(\"search\", {})\n",
    "            if \"corpora\" not in search:\n",
    "                errors.append(\"Missing required field: 'search.corpora'\")\n",
    "            else:\n",
    "                for i, corpus in enumerate(search.get(\"corpora\", [])):\n",
    "                    if \"corpus_key\" not in corpus:\n",
    "                        errors.append(f\"Missing corpus_key in corpora[{i}]\")\n",
    "                    \n",
    "                    # Validate lexical_interpolation range\n",
    "                    if \"lexical_interpolation\" in corpus:\n",
    "                        li = corpus[\"lexical_interpolation\"]\n",
    "                        if not isinstance(li, (int, float)) or li < 0 or li > 1:\n",
    "                            errors.append(f\"lexical_interpolation must be 0-1, got: {li}\")\n",
    "                            corrected[\"search\"][\"corpora\"][i][\"lexical_interpolation\"] = 0.025\n",
    "            \n",
    "            # Validate limit\n",
    "            if \"limit\" in search:\n",
    "                limit = search[\"limit\"]\n",
    "                if not isinstance(limit, int) or limit < 1:\n",
    "                    warnings.append(f\"limit should be positive integer, got: {limit}\")\n",
    "        \n",
    "        # Check for common hallucinations\n",
    "        hallucinated_fields = [\"corpus_id\", \"customer_id\", \"num_results\", \"query_text\"]\n",
    "        for field in hallucinated_fields:\n",
    "            if field in data:\n",
    "                errors.append(f\"Invalid field '{field}' - this is a hallucination. Did you mean: \" +\n",
    "                            {\"corpus_id\": \"search.corpora[].corpus_key\",\n",
    "                             \"customer_id\": \"(not needed with API key)\",\n",
    "                             \"num_results\": \"search.limit\",\n",
    "                             \"query_text\": \"query\"}.get(field, \"check docs\"))\n",
    "    \n",
    "    elif endpoint == \"index\":\n",
    "        if \"document_id\" not in data and \"id\" not in data:\n",
    "            errors.append(\"Missing required field: 'document_id' or 'id'\")\n",
    "        \n",
    "        has_content = \"parts\" in data or \"document_parts\" in data or \"content\" in data\n",
    "        if not has_content:\n",
    "            errors.append(\"Missing content: need 'parts', 'document_parts', or 'content'\")\n",
    "        \n",
    "        # Check for hallucinations\n",
    "        if \"text\" in data and \"parts\" not in data:\n",
    "            warnings.append(\"'text' alone is not valid - use 'parts' array with 'text' inside\")\n",
    "    \n",
    "    elif endpoint == \"agents\":\n",
    "        if \"name\" not in data:\n",
    "            errors.append(\"Missing required field: 'name'\")\n",
    "        if \"model\" not in data:\n",
    "            errors.append(\"Missing required field: 'model'\")\n",
    "        if \"first_step\" not in data:\n",
    "            errors.append(\"Missing required field: 'first_step'\")\n",
    "    \n",
    "    elif endpoint == \"corpus\":\n",
    "        if \"key\" not in data and \"name\" not in data:\n",
    "            warnings.append(\"Consider providing 'key' or 'name' for the corpus\")\n",
    "    \n",
    "    return {\n",
    "        \"valid\": len(errors) == 0,\n",
    "        \"endpoint\": endpoint,\n",
    "        \"method\": method,\n",
    "        \"errors\": errors,\n",
    "        \"warnings\": warnings,\n",
    "        \"corrected_payload\": corrected if errors else data\n",
    "    }\n",
    "'''\n",
    "\n",
    "api_validator_config = {\n",
    "    \"type\": \"lambda\",\n",
    "    \"language\": \"python\",\n",
    "    \"name\": \"vectara_api_validator\",\n",
    "    \"title\": \"Vectara API Payload Validator\",\n",
    "    \"description\": \"Validate Vectara API request payloads before presenting to users. Checks required fields, validates parameter ranges (e.g., lexical_interpolation 0-1), and catches common LLM hallucinations (wrong field names). Returns validation status, errors, and corrected payload. ALWAYS use this before showing API code examples.\",\n",
    "    \"code\": api_validator_code\n",
    "}\n",
    "\n",
    "api_validator_id = delete_and_create_tool(api_validator_config, \"vectara_api_validator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 3: Create the Parent Orchestrator Agent\n",
    "\n",
    "Now we'll create a parent agent that can delegate to the sub-agents and use the API validator. The parent agent:\n",
    "- Analyzes user requests to determine which sub-agent(s) to invoke\n",
    "- Delegates domain-specific tasks to the appropriate sub-agent\n",
    "- **Uses the API validator** to ensure generated code is correct before presenting it back to the user.\n",
    "- Synthesizes responses from multiple sub-agents into a cohesive answer\n",
    "\n",
    "### Sub-Agent Tool Configuration\n",
    "\n",
    "Sub-agents are configured as tools using the `sub_agent` type:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"type\": \"sub_agent\",\n",
    "  \"description_template\": \"Description the LLM sees when deciding to use this tool\",\n",
    "  \"sub_agent_configuration\": {\n",
    "    \"agent_key\": \"the_sub_agent_key\",\n",
    "    \"session_mode\": \"ephemeral\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### Session Modes\n",
    "\n",
    "When specifying in the parent agent how sub-agents are to be used, you need to define the \"session mode\":\n",
    "- **`persistent`**: Always reuse the same session, accumulating knowledge across invocations\n",
    "- **`ephemeral`**: Create a fresh session every time, ensuring no state leakage\n",
    "- **`llm_controlled`**: The LLM decides whether to resume an existing session or create a new one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent 'AI Research Orchestrator'\n",
      "Agent Key: agt_ai_research_orchestrator_d6b1\n"
     ]
    }
   ],
   "source": [
    "# Create the Orchestrator Agent with sub-agent tools and API validator\n",
    "orchestrator_config = {\n",
    "    \"name\": \"AI Research Orchestrator\",\n",
    "    \"description\": \"Orchestrator agent that delegates to specialized sub-agents for comprehensive AI research assistance\",\n",
    "    \"model\": {\"name\": \"gpt-4o\"},\n",
    "    \"first_step\": {\n",
    "        \"type\": \"conversational\",\n",
    "        \"instructions\": [\n",
    "            {\n",
    "                \"type\": \"inline\",\n",
    "                \"name\": \"orchestrator_instructions\",\n",
    "                \"template\": \"\"\"You are an AI research orchestrator that helps users understand and implement AI technologies.\n",
    "\n",
    "Your workflow:\n",
    "1. Analyze the user's question to determine what expertise is needed.\n",
    "2. Use appropriate sub-agent(s) to gather information:\n",
    "   - research_analyst: for academic/theoretical content\n",
    "   - docs_expert: for implementation guidance\n",
    "   - web_search_expert: for current news/trends\n",
    "3. When your response includes Vectara API code examples or implementation details:\n",
    "   - Generate the JSON payload\n",
    "   - ALWAYS validate it using the api_validator tool before presenting\n",
    "   - If validation fails, fix the errors and validate again\n",
    "   - Only present validated, working code to the user\n",
    "4. Synthesize all responses into a comprehensive answer.\n",
    "\n",
    "IMPORTANT: \n",
    "- Never show API code without validating it first. Users trust that code examples will work.\n",
    "- When responding, provide a complete, well-sourced answer with citations.\n",
    "\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        \"output_parser\": {\"type\": \"default\"}\n",
    "    },\n",
    "    \"tool_configurations\": {\n",
    "        \"research_analyst\": {\n",
    "            \"type\": \"sub_agent\",\n",
    "            \"description_template\": \"Research academic research papers for theoretical foundations and research findings.\",\n",
    "            \"sub_agent_configuration\": {\n",
    "                \"agent_key\": research_analyst_key,\n",
    "                \"session_mode\": \"ephemeral\"\n",
    "            }\n",
    "        },\n",
    "        \"docs_expert\": {\n",
    "            \"type\": \"sub_agent\",\n",
    "            \"description_template\": \"Research Vectara documentation for API usage, code examples, configuration, and best practices.\",\n",
    "            \"sub_agent_configuration\": {\n",
    "                \"agent_key\": docs_expert_key,\n",
    "                \"session_mode\": \"llm_controlled\"\n",
    "            }\n",
    "        },\n",
    "        \"web_search_expert\": {\n",
    "            \"type\": \"sub_agent\",\n",
    "            \"description_template\": \"Search the web for up-to-date information, news, and current trends.\",\n",
    "            \"sub_agent_configuration\": {\n",
    "                \"agent_key\": web_search_expert_key,\n",
    "                \"session_mode\": \"ephemeral\"\n",
    "            }\n",
    "        },\n",
    "        \"api_validator\": {\n",
    "            \"type\": \"lambda\",\n",
    "            \"tool_id\": api_validator_id\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "orchestrator_key = delete_and_create_agent(orchestrator_config, \"AI Research Orchestrator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Step 4: Test the Multi-Agent Workflow\n",
    "\n",
    "Now let's test the orchestrator with different types of questions to see how it delegates to sub-agents and uses the gap analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to send messages and display responses\n",
    "def chat_with_agent(agent_key, session_key, message, show_events=False):\n",
    "    \"\"\"Send a message to an agent and return the response.\"\"\"\n",
    "    message_data = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"content\": message\n",
    "            }\n",
    "        ],\n",
    "        \"stream_response\": False\n",
    "    }\n",
    "    \n",
    "    url = f\"{BASE_URL}/agents/{agent_key}/sessions/{session_key}/events\"\n",
    "    response = requests.post(url, headers=headers, json=message_data)\n",
    "    \n",
    "    if response.status_code == 201:\n",
    "        event_data = response.json()\n",
    "        \n",
    "        if show_events:\n",
    "            print(\"\\n------ Agent Events ------\")\n",
    "            for event in event_data.get('events', []):\n",
    "                event_type = event.get('type', 'INVALID')\n",
    "                print(f\"Event: {event_type}\")\n",
    "                if event_type == 'tool_input':\n",
    "                    tool_name = event.get('tool_configuration_name', 'N/A')\n",
    "                    print(f\"  Tool: {tool_name}\")\n",
    "                    tool_input = event.get(\"tool_input\", {})\n",
    "                    if tool_input.get(\"message\"):\n",
    "                        print(f\"  Input: {tool_input['message']}...\")\n",
    "                    # Show API validator inputs\n",
    "                    if tool_input.get(\"endpoint\"):\n",
    "                        print(f\"  Validating endpoint: {tool_input['endpoint']}\")\n",
    "                if event_type == 'tool_output':\n",
    "                    tool_name = event.get('tool_configuration_name', 'N/A')\n",
    "                    print(f\"  Tool: {tool_name}\")\n",
    "                    tool_output = event.get(\"tool_output\", {})\n",
    "                    # Show sub-agent response preview\n",
    "                    if tool_output.get(\"sub_agent_response\"):\n",
    "                        print(f\"  Response (200 chars): {tool_output['sub_agent_response'][:200]}...\")\n",
    "                    # Show API validator output\n",
    "                    if tool_output.get(\"lambda_response\"):\n",
    "                        lambda_resp = tool_output[\"lambda_response\"]\n",
    "                        if \"valid\" in lambda_resp:\n",
    "                            valid = lambda_resp[\"valid\"]\n",
    "                            print(f\"  Validation Result: {'VALID' if valid else 'INVALID'}\")\n",
    "                            if lambda_resp.get(\"errors\"):\n",
    "                                print(f\"    Errors: {lambda_resp['errors']}\")\n",
    "                            if lambda_resp.get(\"warnings\"):\n",
    "                                print(f\"    Warnings: {lambda_resp['warnings']}\")\n",
    "            print(\"-\"*25)\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        # Extract agent output\n",
    "        for event in event_data.get('events', []):\n",
    "            if event.get('type') == 'agent_output':\n",
    "                return event.get('content', 'No content')\n",
    "        \n",
    "        return \"No agent output found\"\n",
    "    else:\n",
    "        return f\"Error: {response.status_code} - {response.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session Created: ase_orchestrator_session_20251205-063235_ea91\n"
     ]
    }
   ],
   "source": [
    "# Create a session for the orchestrator\n",
    "session_name = f\"Orchestrator Session {datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "session_config = {\n",
    "    \"name\": session_name,\n",
    "    \"metadata\": {\n",
    "        \"purpose\": \"sub_agent_demo\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{BASE_URL}/agents/{orchestrator_key}/sessions\",\n",
    "    headers=headers,\n",
    "    json=session_config\n",
    ")\n",
    "\n",
    "if response.status_code == 201:\n",
    "    session_data = response.json()\n",
    "    orchestrator_session_key = session_data[\"key\"]\n",
    "    print(f\"Session Created: {orchestrator_session_key}\")\n",
    "else:\n",
    "    print(f\"Error: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "### Test 1: Research-Focused Question\n",
    "\n",
    "This question should primarily use the research_analyst sub-agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What are the key innovations in RAG?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "------ Agent Events ------\n",
      "Event: input_message\n",
      "Event: tool_input\n",
      "  Tool: research_analyst\n",
      "  Input: Research the key innovations in Retrieval-Augmented Generation (RAG) to provide an overview of advancements and techniques in this area. Focus on recent academic findings and theoretical advancements....\n",
      "Event: tool_input\n",
      "  Tool: web_search_expert\n",
      "  Input: Find recent news and trends concerning key innovations in Retrieval-Augmented Generation (RAG). Look for articles, blog posts, or news releases from 2023 that highlight innovations in this technology....\n",
      "Event: tool_output\n",
      "  Tool: research_analyst\n",
      "  Response (200 chars): Retrieval-Augmented Generation (RAG) has seen significant advancements in recent years, particularly focusing on enhancing the capabilities of language models by integrating retrieval mechanisms with ...\n",
      "Event: tool_output\n",
      "  Tool: web_search_expert\n",
      "  Response (200 chars): In 2023, there have been several notable innovations in the field of Retrieval-Augmented Generation (RAG). Here are some of the key developments:\n",
      "\n",
      "1. **RASG and CAG Models**: Newer models such as Retr...\n",
      "Event: agent_output\n",
      "-------------------------\n",
      "\n",
      "\n",
      "Agent Response:\n",
      "The field of Retrieval-Augmented Generation (RAG) has witnessed substantial innovations in both academic research and practical applications. Here's a comprehensive overview of the key advancements:\n",
      "\n",
      "### Academic and Theoretical Innovations\n",
      "\n",
      "1. **Hybrid Memory Integration**: RAG models utilize both parametric and non-parametric memory, enabling them to access a wide range of factual information during content generation. This dual-memory setup combines the flexibility of generative models with the precision of retrieval models [Lewis et al., 2020].\n",
      "\n",
      "2. **Probabilistic Model Training**: These models are trained end-to-end with a probabilistic framework that optimizes retrieval and generation processes to ensure accurate and relevant output [Lewis et al., 2020].\n",
      "\n",
      "3. **Enhanced Retrieval Mechanisms**: Improvements in the retrieval components, often through fine-tuning with specific datasets, have led to better model performances across diverse tasks [Lewis et al., 2020].\n",
      "\n",
      "4. **Hallucination Mitigation**: Research has focused on reducing hallucinations—where models generate unsupported or incorrect details—by implementing detection and editing mechanisms aimed at improving response reliability [Cheng Niu et al., 2024].\n",
      "\n",
      "5. **New Evaluation Metrics and Benchmarks**: New datasets and evaluation metrics have been developed to assess the quality, accuracy, and factual consistency of retrieval-augmented outputs [ArXiv 2022].\n",
      "\n",
      "6. **Robustness without Specialized Pre-training**: Unlike some models, RAG achieves strong results without needing costly specialized pre-training techniques [Lewis et al., 2020].\n",
      "\n",
      "### Recent Industry Trends and Applications\n",
      "\n",
      "1. **RASG and CAG Models**: Models like Retrieval-Augmented Self-Generated learning (RASG) and Context-Aware Generation (CAG) are emerging. RASG self-initiates queries to retrieve and refine output, significantly advancing AI’s integration with external knowledge ([Computer.org](https://www.computer.org/publications/tech-news/trends/augmented-generation-in-ai)).\n",
      "\n",
      "2. **Integration with Large Language Models**: Companies like NVIDIA are incorporating RAG into AI frameworks to boost model accuracy and context sensitivity by merging generative capabilities with retrieval functions ([Analytics Vidhya](https://www.analyticsvidhya.com/blog/2023/09/retrieval-augmented-generation-rag-in-ai/)).\n",
      "\n",
      "3. **On-Demand Information Retrieval**: RAG systems now offer real-time retrieval of relevant information to refine AI model outputs without continuous retraining, mitigating hallucinations ([Cisco Blog](https://outshift.cisco.com/blog/what-is-retrieval-augmented-generation)).\n",
      "\n",
      "4. **Applications in Question-Answering Systems**: RAG technology is enhancing question-answering agents, particularly in FAQs, by integrating domain-specific knowledge for generating authentic responses ([Springer](https://link.springer.com/article/10.1007/s12599-025-00945-3)).\n",
      "\n",
      "5. **Oracle's Select AI**: Oracle has integrated RAG to leverage LLMs for producing insights and creative content from private datasets ([Oracle Blog](https://blogs.oracle.com/database/announcing-select-ai-with-rag-on-adb)).\n",
      "\n",
      "These developments illustrate the growing importance of RAG in enhancing AI's functionality and reliability across various domains, improving both academic pursuits and industrial applications.\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the key innovations in RAG?\"\n",
    "print(f\"User: {query}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "response = chat_with_agent(\n",
    "    orchestrator_key,\n",
    "    orchestrator_session_key,\n",
    "    query,\n",
    "    show_events=True\n",
    ")\n",
    "\n",
    "print(f\"Agent Response:\\n\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "### Test 2: Implementation Question with API Validation\n",
    "\n",
    "This question asks for working code, which should trigger the API validator to ensure correctness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Give me working code to search a corpus for AI research papers using hybrid search with Vectara's API.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "------ Agent Events ------\n",
      "Event: input_message\n",
      "Event: tool_input\n",
      "  Tool: docs_expert\n",
      "  Input: Provide a code example for using Vectara's API to perform a hybrid search in a corpus for AI research papers. The example should include JSON payloads for both keyword and semantic searches, and any necessary configurations. Ensure to specify the API endpoint and method. Validate the JSON payload with the api_validator tool before returning....\n",
      "Event: tool_output\n",
      "  Tool: docs_expert\n",
      "  Response (200 chars): To perform a hybrid search in a Vectara corpus for AI research papers, you can use Vectara's REST API by making a POST request to the Vectara search endpoint. A hybrid search combines both semantic an...\n",
      "Event: tool_input\n",
      "  Tool: api_validator\n",
      "  Validating endpoint: https://api.vectara.io/v2/query\n",
      "Event: tool_output\n",
      "  Tool: api_validator\n",
      "Event: agent_output\n",
      "-------------------------\n",
      "\n",
      "\n",
      "Agent Response:\n",
      "Here's a working code example to perform a hybrid search for AI research papers using Vectara's API. The JSON payload has been validated to ensure it meets the API's requirements.\n",
      "\n",
      "### API Endpoint\n",
      "- **Endpoint**: `https://api.vectara.io/v2/query`\n",
      "\n",
      "### HTTP Method\n",
      "- **Method**: `POST`\n",
      "\n",
      "### JSON Payload\n",
      "This payload performs a hybrid search with a balance between semantic and keyword searches.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"query\": \"AI research papers\",\n",
      "  \"search\": {\n",
      "    \"corpora\": [\n",
      "      {\n",
      "        \"corpus_key\": \"your_corpus_key_here\",\n",
      "        \"lexical_interpolation\": 0.5\n",
      "      }\n",
      "    ],\n",
      "    \"limit\": 10,\n",
      "    \"context_configuration\": {\n",
      "      \"sentences_before\": 3,\n",
      "      \"sentences_after\": 3\n",
      "    },\n",
      "    \"reranker\": {\n",
      "      \"type\": \"default\",\n",
      "      \"reranker_id\": \"your_reranker_id\"\n",
      "    }\n",
      "  },\n",
      "  \"generation\": {\n",
      "    \"max_used_search_results\": 5,\n",
      "    \"response_language\": \"en\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "### Implementation Notes\n",
      "- **lexical_interpolation**: A value of `0.5` gives equal weight to keyword and semantic searches.\n",
      "- **limit**: Specifies the maximum number of results returned, here limited to 10.\n",
      "- **context_configuration**: Provides context by including sentences before and after the search term.\n",
      "- **reranker**: May be customized based on available configurations or kept as default.\n",
      "\n",
      "### Authentication\n",
      "Include authentication using your API keys or OAuth 2.0 tokens in the request headers as a Bearer token.\n",
      "\n",
      "You can adjust these configurations based on your specific corpus and search needs. For detailed configurations and additional examples, refer to the [Vectara API Documentation](https://docs.vectara.com/docs/rest-api/vectara-rest-api-v-2).\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me working code to search a corpus for AI research papers using hybrid search with Vectara's API.\"\n",
    "print(f\"User: {query}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "response = chat_with_agent(\n",
    "    orchestrator_key,\n",
    "    orchestrator_session_key,\n",
    "    query,\n",
    "    show_events=True\n",
    ")\n",
    "\n",
    "print(f\"Agent Response:\\n\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wr04o4ujvoh",
   "metadata": {},
   "source": [
    "### Test 3: Current Information Question (Web Search)\n",
    "\n",
    "This question asks about recent developments that wouldn't be in our indexed research papers or documentation, demonstrating the value of the web search sub-agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7elqfu25p1k",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What are the latest developments in RAG technology in 2025? Are there any new techniques or frameworks that have emerged recently?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "------ Agent Events ------\n",
      "Event: input_message\n",
      "Event: tool_input\n",
      "  Tool: web_search_expert\n",
      "  Input: Search for the latest developments in Retrieval-Augmented Generation (RAG) technology in 2025. Look for new techniques, frameworks, and research advancements that have emerged recently. Include any industry news, academic papers, or tech blog posts from 2025....\n",
      "Event: tool_output\n",
      "  Tool: web_search_expert\n",
      "  Response (200 chars): The latest developments in Retrieval-Augmented Generation (RAG) technology in 2025 highlight significant advancements and innovations in the field. Here are some key insights:\n",
      "\n",
      "1. **Hybrid Search and ...\n",
      "Event: agent_output\n",
      "-------------------------\n",
      "\n",
      "\n",
      "Agent Response:\n",
      "In 2025, Retrieval-Augmented Generation (RAG) technology has made significant strides, leading to substantial advancements and the emergence of new techniques and frameworks. Here are the latest developments in RAG technology:\n",
      "\n",
      "1. **Hybrid Search and Multimodal RAG**: Innovations have focused on hybrid search capabilities and integrating multimodal RAG frameworks. These advancements facilitate dynamic interactions between various data modalities and AI models, thus enhancing processing and retrieval capabilities ([Signity Solutions](https://www.signitysolutions.com/blog/trends-in-active-retrieval-augmented-generation)).\n",
      "\n",
      "2. **Market Growth**: The global RAG market is projected to exceed USD 40 billion by 2035. This growth is primarily driven by increased AI integration across enterprises, emphasizing RAG's role in enhancing decision-making processes and operational efficiencies ([Business Wire](https://www.businesswire.com/news/home/20251010008494/en/Retrieval-Augmented-Generation-RAG-Industry-Report-2025-2035-Global-RAG-Market-to-Surpass-%2440-Billion-by-2035-as-Enterprises-Accelerate-AI-Integration---ResearchAndMarkets.com)).\n",
      "\n",
      "3. **Emerging Techniques**: New methodologies, such as Reciprocal Rank Fusion and the use of Generated Queries, have been integrated into RAG frameworks to improve retrieval precision and reliability ([Prompting Guide](https://www.promptingguide.ai/research/rag)).\n",
      "\n",
      "4. **Enterprise Transformations**: RAG technologies are increasingly transforming enterprise AI by bridging static AI models with dynamic data environments. This integration allows organizations to leverage more sophisticated AI capabilities, driving significant innovations within corporate structures ([Medium](https://dev523.medium.com/the-evolution-of-rag-how-retrieval-augmented-generation-is-transforming-enterprise-ai-in-2025-a0265bc1c297)).\n",
      "\n",
      "5. **Pipeline Implementation**: New implementations involve embedding a smart search layer into large language models, thus improving data retrieval and processing efficiencies across large datasets ([Dextralabs](https://dextralabs.com/blog/rag-pipeline-explained-diagram-implementation/)).\n",
      "\n",
      "These developments highlight RAG's robust progression, its growing application potential, and its relevance in enhancing AI-driven knowledge systems.\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the latest developments in RAG technology in 2025? Are there any new techniques or frameworks that have emerged recently?\"\n",
    "print(f\"User: {query}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "response = chat_with_agent(\n",
    "    orchestrator_key,\n",
    "    orchestrator_session_key,\n",
    "    query,\n",
    "    show_events=True\n",
    ")\n",
    "\n",
    "print(f\"Agent Response:\\n\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "If you want to delete the agents created in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted agent: agt_ai_research_orchestrator_d6b1\n",
      "Deleted agent: agt_research_paper_analyst_084e\n",
      "Deleted agent: agt_documentation_expert_004b\n",
      "Deleted agent: agt_web_search_expert_235c\n",
      "Deleted tool: tol_2221\n"
     ]
    }
   ],
   "source": [
    "# Delete agents\n",
    "agents_to_delete = [\n",
    "    orchestrator_key,\n",
    "    research_analyst_key,\n",
    "    docs_expert_key,\n",
    "    web_search_expert_key\n",
    "]\n",
    "\n",
    "for agent_key in agents_to_delete:\n",
    "    if agent_key:\n",
    "        response = requests.delete(f\"{BASE_URL}/agents/{agent_key}\", headers=headers)\n",
    "        if response.status_code == 204:\n",
    "            print(f\"Deleted agent: {agent_key}\")\n",
    "        else:\n",
    "            print(f\"Error deleting {agent_key}: {response.text}\")\n",
    "\n",
    "# Delete the lambda tool\n",
    "if api_validator_id:\n",
    "    response = requests.delete(f\"{BASE_URL}/tools/{api_validator_id}\", headers=headers)\n",
    "    if response.status_code == 204:\n",
    "        print(f\"Deleted tool: {api_validator_id}\")\n",
    "    else:\n",
    "        print(f\"Error deleting tool: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f10017f-bc24-4360-814d-5c3838f30afd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
