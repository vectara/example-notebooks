{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/vectara/example-notebooks/blob/main/notebooks/mcp/langchain-agent-with-vectara-mcp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Correcting Research Agent with Vectara MCP\n",
    "\n",
    "This notebook demonstrates a **self-correcting research agent** that automatically detects and fixes its own hallucinations using Vectara's MCP tools:\n",
    "\n",
    "- **HHEM** (Hughes Hallucination Evaluation Model) via `eval_factual_consistency` - evaluates factual accuracy\n",
    "- **VHC** (Vectara Hallucination Corrector) via `correct_hallucinations` - fixes hallucinated content\n",
    "\n",
    "The agent combines multiple tools (Wikipedia, Calculator) with HHEM/VHC to:\n",
    "1. Research topics using Wikipedia\n",
    "2. Draft responses based on sources\n",
    "3. **Automatically verify** its responses using HHEM\n",
    "4. **Auto-correct** if the factual consistency score is low\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. Install packages: `pip install vectara-mcp langchain-mcp-adapters langgraph langchain-openai wikipedia python-dotenv`\n",
    "2. Get a Vectara API key from [console.vectara.com](https://console.vectara.com)\n",
    "3. Get an OpenAI API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --quiet langchain-mcp-adapters langgraph langchain-openai langchain-community vectara-mcp wikipedia python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment configured successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set your API keys here or via environment variables\n",
    "os.environ[\"VECTARA_API_KEY\"] = os.getenv(\"VECTARA_API_KEY\", \"<YOUR_VECTARA_API_KEY>\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\", \"<YOUR_OPENAI_API_KEY>\")\n",
    "\n",
    "if os.getenv(\"VECTARA_API_KEY\", \"\").startswith(\"<\"):\n",
    "    raise EnvironmentError(\"Please set VECTARA_API_KEY\")\n",
    "if os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"<\"):\n",
    "    raise EnvironmentError(\"Please set OPENAI_API_KEY\")\n",
    "\n",
    "print(\"Environment configured successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Connect to Vectara MCP Server\n",
    "\n",
    "Connect to the Vectara MCP server to access HHEM and VHC tools for detecting and correcting hallucinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "import sys\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Configure the Vectara MCP server connection\n",
    "mcp_client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"vectara\": {\n",
    "            \"command\": sys.executable,\n",
    "            \"args\": [\"-m\", \"vectara_mcp\", \"--transport\", \"stdio\"],\n",
    "            \"transport\": \"stdio\",\n",
    "            \"env\": {\n",
    "                \"VECTARA_API_KEY\": os.environ[\"VECTARA_API_KEY\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available MCP tools:\n",
      "  - setup_vectara_api_key: \n",
      "    Configure and validate the Vectara API key for the session.\n",
      "\n",
      "    Args:\n",
      "        api_key: str, The Vectara API key to configure - required.\n",
      "\n",
      "    Returns:\n",
      "        str: Success message with masked API key or error message.\n",
      "    \n",
      "\n",
      "  - clear_vectara_api_key: \n",
      "    Clear the stored Vectara API key from server memory.\n",
      "\n",
      "    Returns:\n",
      "        str: Confirmation message.\n",
      "    \n",
      "\n",
      "  - ask_vectara: \n",
      "    Run a RAG query using Vectara, returning search results with generated response.\n",
      "\n",
      "    Args:\n",
      "        query: str, The user query to run - required.\n",
      "        corpus_keys: list[str], List of Vectara corpus keys to use. Required.\n",
      "        n_sentences_before: int, Sentences before answer for context. Default 2.\n",
      "        n_sentences_after: int, Sentences after answer for context. Default 2.\n",
      "        lexical_interpolation: float, Lexical interpolation amount. Default 0.005.\n",
      "        max_used_search_results: int, Max search results to use. Default 10.\n",
      "        generation_preset_name: str, Generation preset name.\n",
      "        response_language: str, Response language. Default \"eng\".\n",
      "\n",
      "    Note: API key must be configured first using 'setup_vectara_api_key' tool\n",
      "\n",
      "    Returns:\n",
      "        dict: Structured response containing:\n",
      "            - \"summary\": Generated AI summary with markdown citations\n",
      "            - \"citations\": List of citation objects with score, text, metadata\n",
      "            - \"factual_consistency_score\": Score if available\n",
      "        On error, returns dict with \"error\" key.\n",
      "    \n",
      "\n",
      "  - search_vectara: \n",
      "    Run a semantic search query using Vectara, without generation.\n",
      "\n",
      "    Args:\n",
      "        query: str, The user query to run - required.\n",
      "        corpus_keys: list[str], List of Vectara corpus keys to use. Required.\n",
      "        n_sentences_before: int, Sentences before answer for context. Default 2.\n",
      "        n_sentences_after: int, Sentences after answer for context. Default 2.\n",
      "        lexical_interpolation: float, Lexical interpolation amount. Default 0.005.\n",
      "\n",
      "    Note: API key must be configured first using 'setup_vectara_api_key' tool\n",
      "\n",
      "    Returns:\n",
      "        dict: Raw search results from Vectara API containing:\n",
      "            - \"search_results\": List of result objects with scores, text, metadata\n",
      "            - Additional response metadata from the API\n",
      "        On error, returns dict with \"error\" key.\n",
      "    \n",
      "\n",
      "  - correct_hallucinations: \n",
      "    Identify and correct hallucinations in generated text using Vectara API.\n",
      "\n",
      "    Args:\n",
      "        generated_text: str, The text to analyze for hallucinations - required.\n",
      "        documents: list[str], Source documents to compare against - required.\n",
      "        query: str, The original user query - optional.\n",
      "\n",
      "    Note: API key must be configured first using 'setup_vectara_api_key' tool\n",
      "\n",
      "    Returns:\n",
      "        dict: Structured response containing:\n",
      "            - \"corrected_text\": Text with hallucinations corrected\n",
      "            - \"corrections\": Array of correction objects with:\n",
      "                * \"original_text\": The hallucinated content\n",
      "                * \"corrected_text\": The factually accurate replacement\n",
      "                * \"explanation\": Detailed reason for the correction\n",
      "        On error, returns dict with \"error\" key.\n",
      "    \n",
      "\n",
      "  - eval_factual_consistency: \n",
      "    Evaluate factual consistency of text against source documents using Vectara.\n",
      "\n",
      "    Args:\n",
      "        generated_text: str, The text to evaluate for factual consistency.\n",
      "        documents: list[str], Source documents to compare against - required.\n",
      "\n",
      "    Note: API key must be configured first using 'setup_vectara_api_key' tool\n",
      "\n",
      "    Returns:\n",
      "        dict: Response containing factual consistency evaluation score.\n",
      "        On error, returns dict with \"error\" key.\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load tools from the MCP server\n",
    "tools = await mcp_client.get_tools()\n",
    "\n",
    "print(\"Available MCP tools:\")\n",
    "for tool in tools:\n",
    "    print(f\"  - {tool.name}: {tool.description}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Add Research Tools\n",
    "\n",
    "Beyond the Vectara MCP tools, we add Wikipedia search and a calculator to create a practical research agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent has 8 tools: ['setup_vectara_api_key', 'clear_vectara_api_key', 'ask_vectara', 'search_vectara', 'correct_hallucinations', 'eval_factual_consistency', 'wikipedia', 'calculate']\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression. Example: calculate('2 + 2 * 3')\"\"\"\n",
    "    try:\n",
    "        # Safe evaluation - only allow math operations\n",
    "        allowed = set('0123456789+-*/.() ')\n",
    "        if all(c in allowed for c in expression):\n",
    "            return str(eval(expression))\n",
    "        return \"Error: Only numeric expressions allowed\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Setup Wikipedia tool\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(top_k_results=2))\n",
    "\n",
    "# Combine all tools: Vectara MCP + Wikipedia + Calculator\n",
    "all_tools = tools + [wikipedia, calculate]\n",
    "print(f\"Agent has {len(all_tools)} tools: {[t.name for t in all_tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Create Self-Correcting Research Agent\n",
    "\n",
    "Create an agent with a system prompt that instructs it to:\n",
    "1. Research using Wikipedia\n",
    "2. Draft a response\n",
    "3. **Automatically verify** using HHEM\n",
    "4. **Auto-correct** with VHC if the score is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-correcting agent created with system prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/qd7p5ft96k7br3ztvfwfbsqc0000gn/T/ipykernel_65921/1824071622.py:12: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent = create_react_agent(\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a research assistant\n",
    "Answer user questions using the following workflow:\n",
    "\n",
    "1. RESEARCH: Use wikipedia to gather source information on the topic\n",
    "2. DRAFT: Write your response based ONLY on the sources you found\n",
    "3. VERIFY: Use eval_factual_consistency to check your draft against the Wikipedia sources\n",
    "4. CORRECT: If HHEM score < 0.5, use correct_hallucinations to fix your response\n",
    "5. RETURN: Provide the final verified response, after correction (if correct_hallucinations) was used.\n",
    "\"\"\"\n",
    "\n",
    "# Create the self-correcting agent with all tools\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=all_tools,\n",
    "    prompt=SYSTEM_PROMPT\n",
    ")\n",
    "\n",
    "print(\"Self-correcting agent created with system prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Research Examples with Auto-Verification\n",
    "\n",
    "The agent researches topics, drafts responses, and automatically verifies/corrects them using HHEM and VHC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2008 financial crisis, also known as the global financial crisis, was primarily caused by several interrelated factors:\n",
      "\n",
      "1. **Housing Bubble and Speculation**: There was excessive speculation on property values by both homeowners and financial institutions, leading to a housing bubble in the United States during the 2000s.\n",
      "\n",
      "2. **Subprime Mortgages and Predatory Lending**: Financial institutions engaged in predatory lending practices, offering high-risk subprime mortgages to low-income homebuyers, often without adequate regulatory oversight.\n",
      "\n",
      "3. **Regulatory Failures**: Deficiencies in financial regulation allowed risky financial practices to proliferate. The repeal of parts of the Glassâ€“Steagall Act in 1999 enabled financial institutions to mix low-risk operations with higher-risk activities, such as investment banking.\n",
      "\n",
      "4. **Mortgage-Backed Securities and Derivatives**: The crisis was exacerbated by the collapse in value of mortgage-backed securities (MBS) and a complex web of derivatives linked to these MBS, which spread the financial contagion globally.\n",
      "\n",
      "5. **Liquidity Crisis**: As subprime mortgage holders began defaulting, lenders went bankrupt, leading to a liquidity crisis that affected global credit markets.\n",
      "\n",
      "6. **Interest Rate Changes**: The Federal Reserve's lowering of interest rates from 2000 to 2003 encouraged risky lending, while subsequent rate increases from 2004 to 2006 raised mortgage costs and reduced housing demand.\n",
      "\n",
      "The crisis reached a critical point with the bankruptcy of Lehman Brothers in September 2008, triggering a stock market crash and bank runs in several countries. In response, governments worldwide implemented massive bailouts and monetary policies to stabilize the financial system.\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Research a historical topic\n",
    "query1 = \"\"\"What were the main causes of the 2008 financial crisis?\"\"\"\n",
    "result1 = await agent.ainvoke({\"messages\": [(\"user\", query1)]})\n",
    "print(result1[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The specific population density of Tokyo in 2023 is not directly available from the current Wikipedia sources. However, Tokyo is known to be one of the most densely populated cities in the world. The city proper has a population of over 14 million, and the Greater Tokyo Area, which includes Tokyo and parts of six neighboring prefectures, is the most populous metropolitan area in the world with 41 million residents as of 2024. For precise and up-to-date figures, consulting official statistics from Tokyo's metropolitan government or other authoritative demographic sources would be necessary.\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Research + Calculation\n",
    "query2 = \"\"\"What is the population density of Tokyo?\"\"\"\n",
    "result2 = await agent.ainvoke({\"messages\": [(\"user\", query2)]})\n",
    "print(result2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRISPR gene editing is a powerful genetic engineering technique that allows for precise modifications to the genomes of living organisms. It is based on a simplified version of the bacterial CRISPR-Cas9 antiviral defense system. The process involves delivering the Cas9 nuclease, complexed with a synthetic guide RNA (gRNA), into a cell. This complex can cut the cell's genome at a specific location, enabling the removal of existing genes or the addition of new ones.\n",
      "\n",
      "The CRISPR-Cas9 system works like genetic scissors, opening both strands of the targeted DNA sequence. This allows for modifications through two main methods:\n",
      "\n",
      "1. **Knock-in Mutations**: This method uses homology-directed repair (HDR) to introduce targeted DNA changes. HDR employs similar DNA sequences to repair the break by incorporating exogenous DNA as a repair template.\n",
      "\n",
      "2. **Knock-out Mutations**: These result from the repair of the double-stranded break via non-homologous end joining (NHEJ) or polymerase theta-mediated end-joining (TMEJ). These pathways can lead to random deletions or insertions, potentially disrupting or altering gene functionality.\n",
      "\n",
      "CRISPR-Cas9 has revolutionized genome editing due to its precision, cost-effectiveness, and efficiency. It has applications in medicine, agriculture, and the creation of genetically modified organisms. It also holds potential for treating genetic diseases and conditions arising from somatic mutations, such as cancer. However, its use in human germline genetic modification is controversial.\n",
      "\n",
      "The development of CRISPR-Cas9 earned Jennifer Doudna and Emmanuelle Charpentier the Nobel Prize in Chemistry in 2020. The technique was also recognized as the Breakthrough of the Year by the AAAS in 2015. In 2023, the first drug using CRISPR gene editing, Exagamglogene autotemcel (brand name \"Casgevy\"), was approved in the UK to treat sickle-cell disease.\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Scientific topic\n",
    "query3 = \"\"\"Explain how CRISPR gene editing works.\"\"\"\n",
    "\n",
    "result3 = await agent.ainvoke({\"messages\": [(\"user\", query3)]})\n",
    "print(result3[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCP client session completed.\n"
     ]
    }
   ],
   "source": [
    "# Close the MCP client connection (cleanup subprocess)\n",
    "try:\n",
    "    await mcp_client.close()\n",
    "    print(\"MCP client closed.\")\n",
    "except AttributeError:\n",
    "    # Some versions may not have explicit close\n",
    "    print(\"MCP client session completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
