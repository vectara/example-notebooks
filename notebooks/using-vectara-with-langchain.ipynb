{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc259945",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/vectara/example-notebooks/blob/main/notebooks/using-vectara-with-langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116e8e57",
   "metadata": {},
   "source": [
    "# Vectara and LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7548c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install langchain-vectara langgraph langchain langchain_openai langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a399ef-5cfb-4707-8ab1-8bbe1d68a169",
   "metadata": {},
   "source": [
    "## About Vectara\n",
    "\n",
    "[Vectara](https://vectara.com/) is the trusted AI Assistant and Agent platform which focuses on enterprise readiness for mission-critical applications.\n",
    "Vectara serverless RAG-as-a-service provides all the components of RAG behind an easy-to-use API, including:\n",
    "1. A way to extract text from files (PDF, PPT, DOCX, etc)\n",
    "2. ML-based chunking that provides state of the art performance.\n",
    "3. The [Boomerang](https://vectara.com/how-boomerang-takes-retrieval-augmented-generation-to-the-next-level-via-grounded-generation/) embeddings model.\n",
    "4. Its own internal vector database where text chunks and embedding vectors are stored.\n",
    "5. A query service that automatically encodes the query into embedding, and retrieves the most relevant text segments, including support for [Hybrid Search](https://docs.vectara.com/docs/api-reference/search-apis/lexical-matching) as well as multiple reranking options such as the [multi-lingual relevance reranker](https://www.vectara.com/blog/deep-dive-into-vectara-multilingual-reranker-v1-state-of-the-art-reranker-across-100-languages), [MMR](https://vectara.com/get-diverse-results-and-comprehensive-summaries-with-vectaras-mmr-reranker/), [UDF reranker](https://www.vectara.com/blog/rag-with-user-defined-functions-based-reranking). \n",
    "6. An LLM to for creating a [generative summary](https://docs.vectara.com/docs/learn/grounded-generation/grounded-generation-overview), based on the retrieved documents (context), including citations.\n",
    "\n",
    "For more information:\n",
    "- [Documentation](https://docs.vectara.com/docs/)\n",
    "- [API Playground](https://docs.vectara.com/docs/rest-api/)\n",
    "- [Quickstart](https://docs.vectara.com/docs/quickstart)\n",
    "\n",
    "The main benefits of using Vectara RAG-as-a-service to build your application are:\n",
    "* **Accuracy and Quality**: Vectara provides an end-to-end platform that focuses on eliminating hallucinations, reducing bias, and safeguarding copyright integrity.\n",
    "* **Security**: Vectara's platform provides acess control--protecting against prompt injection attacks--and meets SOC2 and HIPAA compliance.\n",
    "* **Explainability**: Vectara makes it easy to troubleshoot bad results by clearly explaining rephrased queries, LLM prompts, retrieved results, and agent actions.\n",
    "\n",
    "In this notebook, we will demonstrate some of the great ways you can use Vectara together with LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2f945f-eff4-498a-974b-cf93f3202df6",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "To get started, use the following steps:\n",
    "1. If you don't already have one, [Sign up](https://www.vectara.com/integrations/langchain) for your free Vectara trial.\n",
    "2. Within your account you can create one or more corpora. Each corpus represents an area that stores text data upon ingest from input documents. To create a corpus, use the **\"Create Corpus\"** button. You then provide a name to your corpus as well as a description. Optionally you can define filtering attributes and apply some advanced options. If you click on your created corpus, you can see its name and corpus ID right on the top.\n",
    "3. Next you'll need to create API keys to access the corpus. Click on the **\"Access Control\"** tab in the corpus view and then the **\"Create API Key\"** button. Give your key a name, and choose whether you want query-only or query+index for your key. Click \"Create\" and you now have an active API key. Keep this key confidential. \n",
    "\n",
    "To use LangChain with Vectara, you'll need to have these two values: `corpus_key` and `api_key`.\n",
    "You can provide `VECTARA_API_KEY` to LangChain in two ways:\n",
    "\n",
    "1. Include in your environment these two variables: `VECTARA_API_KEY`.\n",
    "\n",
    "   For example, you can set these variables using os.environ and getpass as follows:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"VECTARA_API_KEY\"] = getpass.getpass(\"Vectara API Key:\")\n",
    "```\n",
    "\n",
    "2. Add them to the `Vectara` vectorstore constructor:\n",
    "\n",
    "```python\n",
    "vectara = Vectara(\n",
    "    vectara_api_key=vectara_api_key\n",
    ")\n",
    "```\n",
    "\n",
    "In this notebook we assume they are provided in the environment. Some examples uses OPENAI as well. Please set the OPENAI API KEY as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0c4d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"VECTARA_API_KEY\"] = \"<VECTARA_API_KEY>\"\n",
    "os.environ[\"VECTARA_CORPUS_KEY\"] = \"VECTARA_CORPUS_KEY\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\"\n",
    "\n",
    "from langchain_vectara import Vectara\n",
    "from langchain_vectara.vectorstores import (\n",
    "    ChainReranker,\n",
    "    CorpusConfig,\n",
    "    CustomerSpecificReranker,\n",
    "    File,\n",
    "    GenerationConfig,\n",
    "    MmrReranker,\n",
    "    SearchConfig,\n",
    "    VectaraQueryConfig,\n",
    ")\n",
    "\n",
    "vectara = Vectara(vectara_api_key=os.getenv(\"VECTARA_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9788095c-3c37-4e35-8e45-a93714e6292c",
   "metadata": {},
   "source": [
    "## Data Ingestion\n",
    "\n",
    "You can ingest data into Vectara directly using Vectara's [indexing API](https://docs.vectara.com/docs/api-reference/indexing-apis/indexing) API, using a tool like [vectara-ingest](https://github.com/vectara/vectara-ingest), or via the Vectara Langchain component directly. We will demonstrate data ingest via LangChain `add_files` method.\n",
    "\n",
    "First we load the state-of-the-union text into Vectara.\n",
    "\n",
    "Note that we use the `add_files` interface which does not require any local processing or chunking - Vectara receives the file content and performs all the necessary pre-processing, chunking and embedding of the file into its knowledge store.\n",
    "\n",
    "In this case it uses a .txt file but the same works for many other [file types](https://docs.vectara.com/docs/api-reference/indexing-apis/file-upload/file-upload-filetypes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdabb28d-1983-453a-bddb-8d844bb969a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state_of_the_union.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_key = os.getenv(\"VECTARA_CORPUS_KEY\")\n",
    "file_obj = File(\n",
    "    file_path=\"../data/state_of_the_union.txt\",\n",
    "    metadata={\"source\": \"text_file\"},\n",
    ")\n",
    "vectara.add_files([file_obj], corpus_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30c859b-0886-4f50-bf7b-e56ef93554fd",
   "metadata": {},
   "source": [
    "You can also use `add_texts` (or `add_documents` which is similar with a lightly different interface) method as well for the data ingestion.\n",
    "\n",
    "For `add_texts` the input is simply a set of text strings:\n",
    "\n",
    "```python\n",
    "vectara.add_texts([\"to be or not to be\", \"that is the question\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb5848a-783d-4f9e-8d92-19938de4a8bf",
   "metadata": {},
   "source": [
    "## Vectara: RAG-as-a-service\n",
    "\n",
    "Vectara is not a vector DB, it's much more than that - it is a full **RAG-as-a-service** platform. \n",
    "Yes, we have our own internal implementation of a scalable and serverless vector database, but that is just one piece of a whole set of components needed to implement RAG. The other components include text extraction, chunking, the Boomerang embedding model, advanced retrieval such as hybrid search or MMR, multi-lingual reranker, and more.\n",
    "\n",
    "We now create a `VectaraQueryConfig` object to control the retrieval and summarization options:\n",
    "* We enable summarization, specifying we would like the LLM to pick the top 7 matching chunks and respond in English\n",
    "\n",
    "Using this configuration, let's create a LangChain `Runnable` object that encpasulates the full Vectara RAG pipeline, using the `as_rag` method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66910837-637f-4682-9c35-925783e70beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"President Biden discussed several key topics in his recent statements. He emphasized the importance of keeping schools open and noted that with a high vaccination rate and reduced hospitalizations, most Americans can safely return to normal activities without masks [1]. He addressed the need to hold social media platforms accountable for their impact on children and called for stronger privacy protections and mental health services [2]. Biden also announced measures against Russia, including preventing its central bank from defending the Ruble and targeting Russian oligarchs' assets, as well as closing American airspace to Russian flights [3], [7]. Additionally, he highlighted the need to protect women's rights, specifically the right to choose as affirmed in Roe v. Wade [5].\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    max_used_search_results=7,\n",
    "    response_language=\"eng\",\n",
    "    generation_preset_name=\"vectara-summary-ext-24-05-med-omni\",\n",
    "    enable_factual_consistency_score=True,\n",
    ")\n",
    "search_config = SearchConfig(\n",
    "    corpora=[CorpusConfig(corpus_key=corpus_key)],\n",
    "    limit=25,\n",
    "    reranker=ChainReranker(\n",
    "        rerankers=[\n",
    "            CustomerSpecificReranker(reranker_id=\"rnk_272725719\", limit=100),\n",
    "            MmrReranker(diversity_bias=0.2, limit=100),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "config = VectaraQueryConfig(\n",
    "    search=search_config,\n",
    "    generation=generation_config,\n",
    ")\n",
    "\n",
    "query_str = \"what did Biden say?\"\n",
    "\n",
    "rag = vectara.as_rag(config)\n",
    "rag.invoke(query_str)[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82365b4-be8e-43d0-ac20-28f76c3b76d9",
   "metadata": {},
   "source": [
    "We can also use the streaming interface like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f00358c8-de06-400e-93ca-7ad7872ac0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "President Biden discussed several key topics in his recent statements. He emphasized the importance of keeping schools open and noted that with a high vaccination rate and reduced hospitalizations, most Americans can safely return to normal activities [1]. He addressed the need to hold social media platforms accountable for their impact on children and called for stronger privacy protections and mental health services [2]. Biden also announced measures against Russia, including preventing its central bank from defending the Ruble and targeting Russian oligarchs' assets, as well as closing American airspace to Russian flights [3], [7]. Additionally, he reaffirmed the need to protect women's rights, particularly the right to choose as affirmed in Roe v. Wade [5]."
     ]
    }
   ],
   "source": [
    "output = {}\n",
    "curr_key = None\n",
    "for chunk in rag.stream(query_str):\n",
    "    for key in chunk:\n",
    "        if key not in output:\n",
    "            output[key] = chunk[key]\n",
    "        else:\n",
    "            output[key] += chunk[key]\n",
    "        if key == \"answer\":\n",
    "            print(chunk[key], end=\"\", flush=True)\n",
    "        curr_key = key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47738d47-b9b0-4d11-a670-aaf069685721",
   "metadata": {},
   "source": [
    "Notice how simple the RAG pipeline is here. It does not require access to an OpenAI key or any other external service for that matter, everything gets done inside the Vectara RAG platform. \n",
    "\n",
    "To set things up we have configured:\n",
    "- `GenerationConfig`: used to specify parameters for the generative summarizer, such as the language of the response, the number of top_k results to include in the summary, or the summarizer (prompt) name.\n",
    "- `SearchConfig`: used to control corpus level parameteres and reranking, providing options like MMR or the multi-lingual reranker\n",
    "- `VectaraQueryConfig` providing the overall configuration structure to control the RAG pipeline.\n",
    "\n",
    "With this configuration, all you have to do is call `vectara.as_rag(config)` and you get a LangChain `Runnable` object on which you can run `invoke()` or `stream()`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29de2540-3cf9-46f9-a6cb-e3a642cf08fa",
   "metadata": {},
   "source": [
    "## Hallucination detection and Factual Consistency Score\n",
    "\n",
    "Vectara created [HHEM](https://huggingface.co/vectara/hallucination_evaluation_model) - an open source model that can be used to evaluate RAG responses for factual consistency.\n",
    "\n",
    "As part of the Vectara RAG, the \"Factual Consistency Score\" (or FCS), which is an improved version of the open source HHEM is made available via the API. This is automatically included in the output of the RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a2acb95-21a8-46db-86e9-484c43d3199c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "President Biden addressed several key issues in his recent statements. He emphasized the importance of keeping schools open and noted that with a high vaccination rate and reduced hospitalizations, most Americans can safely return to normal activities [1]. He also highlighted the need to hold social media platforms accountable for their impact on children and called for stronger privacy protections and mental health services [2]. On international matters, Biden announced measures to weaken Russia's economy and military by targeting Russian oligarchs and closing American airspace to Russian flights [3], [7]. Additionally, he reaffirmed the commitment to protect women's rights, particularly the right to choose as affirmed in Roe v. Wade [5].\n",
      "Vectara FCS = 0.6191406\n"
     ]
    }
   ],
   "source": [
    "resp = rag.invoke(query_str)\n",
    "print(resp[\"answer\"])\n",
    "print(f\"Vectara FCS = {resp['fcs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a8367-cb2f-45cb-8282-cfaceaaa92db",
   "metadata": {},
   "source": [
    "## Vectara as a Retriever\n",
    "\n",
    "You can also integrate Vectara just as a powerful semantic search engine. Similar to other vector stores in Langchain, in this case you can use Vectara as a `retriever`, and take advantage of the stadnard `similarity_search` method (or `similarity_search_with_score`), which takes a query string and returns a list of results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2218c2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'X-TIKA:detectedEncoding': 'UTF-8', 'X-TIKA:encodingDetector': 'UniversalEncodingDetector', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'text_file', 'framework': 'langchain'}, page_content='The U.S. Department of Justice is assembling a dedicated task force to go after the crimes of Russian oligarchs. We are joining with our European allies to find and seize your yachts your luxury apartments your private jets. We are coming for your ill-begotten gains. And tonight I am announcing that we will join our allies in closing off American air space to all Russian flights – further isolating Russia – and adding an additional squeeze –on their economy. The Ruble has lost 30% of its value.'),\n",
       " Document(metadata={'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'X-TIKA:detectedEncoding': 'UTF-8', 'X-TIKA:encodingDetector': 'UniversalEncodingDetector', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'text_file', 'framework': 'langchain'}, page_content='When they came home, many of the world’s fittest and best trained warriors were never the same. Dizziness. \\n\\nA cancer that would put them in a flag-draped coffin. I know. \\n\\nOne of those soldiers was my son Major Beau Biden. We don’t know for sure if a burn pit was the cause of his brain cancer, or the diseases of so many of our troops. But I’m committed to finding out everything we can.'),\n",
       " Document(metadata={'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'X-TIKA:detectedEncoding': 'UTF-8', 'X-TIKA:encodingDetector': 'UniversalEncodingDetector', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'text_file', 'framework': 'langchain'}, page_content='He rejected repeated efforts at diplomacy. He thought the West and NATO wouldn’t respond. And he thought he could divide us at home. We were ready.  Here is what we did. We prepared extensively and carefully.'),\n",
       " Document(metadata={'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'X-TIKA:detectedEncoding': 'UTF-8', 'X-TIKA:encodingDetector': 'UniversalEncodingDetector', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'text_file', 'framework': 'langchain'}, page_content='And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson.'),\n",
       " Document(metadata={'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'X-TIKA:detectedEncoding': 'UTF-8', 'X-TIKA:encodingDetector': 'UniversalEncodingDetector', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'text_file', 'framework': 'langchain'}, page_content='Putin’s latest attack on Ukraine was premeditated and unprovoked. He rejected repeated efforts at diplomacy. He thought the West and NATO wouldn’t respond. And he thought he could divide us at home. We were ready.  Here is what we did.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.generation = None\n",
    "config.search.limit = 5\n",
    "retriever = vectara.as_retriever(config=config)\n",
    "retriever.invoke(query_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f16c69-c291-4a31-8773-e0e0bf6301e7",
   "metadata": {},
   "source": [
    "For backwards compatibility, you can also enable summarization with a retriever, in which case the summary is added as an additional Document object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4de5e76-3535-44f6-8cf7-0f42310d73a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'X-TIKA:detectedEncoding': 'UTF-8', 'X-TIKA:encodingDetector': 'UniversalEncodingDetector', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'text_file', 'framework': 'langchain'}, page_content='We won’t be able to compete for the jobs of the 21st Century if we don’t fix that. That’s why it was so important to pass the Bipartisan Infrastructure Law—the most sweeping investment to rebuild America in history. This was a bipartisan effort, and I want to thank the members of both parties who worked to make it happen. We’re done talking about infrastructure weeks. We’re going to have an infrastructure decade.'),\n",
       " Document(metadata={'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'X-TIKA:detectedEncoding': 'UTF-8', 'X-TIKA:encodingDetector': 'UniversalEncodingDetector', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'text_file', 'framework': 'langchain'}, page_content='The U.S. Department of Justice is assembling a dedicated task force to go after the crimes of Russian oligarchs. We are joining with our European allies to find and seize your yachts your luxury apartments your private jets. We are coming for your ill-begotten gains. And tonight I am announcing that we will join our allies in closing off American air space to all Russian flights – further isolating Russia – and adding an additional squeeze –on their economy. The Ruble has lost 30% of its value.'),\n",
       " Document(metadata={'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'X-TIKA:detectedEncoding': 'UTF-8', 'X-TIKA:encodingDetector': 'UniversalEncodingDetector', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'text_file', 'framework': 'langchain'}, page_content='When they came home, many of the world’s fittest and best trained warriors were never the same. Dizziness. \\n\\nA cancer that would put them in a flag-draped coffin. I know. \\n\\nOne of those soldiers was my son Major Beau Biden. We don’t know for sure if a burn pit was the cause of his brain cancer, or the diseases of so many of our troops. But I’m committed to finding out everything we can.'),\n",
       " Document(metadata={'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'X-TIKA:detectedEncoding': 'UTF-8', 'X-TIKA:encodingDetector': 'UniversalEncodingDetector', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'text_file', 'framework': 'langchain'}, page_content='Preventing Russia’s central bank from defending the Russian Ruble making Putin’s $630 Billion “war fund” worthless. We are choking off Russia’s access to technology that will sap its economic strength and weaken its military for years to come. Tonight I say to the Russian oligarchs and corrupt leaders who have bilked billions of dollars off this violent regime no more. The U.S. Department of Justice is assembling a dedicated task force to go after the crimes of Russian oligarchs. We are joining with our European allies to find and seize your yachts your luxury apartments your private jets.'),\n",
       " Document(metadata={'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'X-TIKA:detectedEncoding': 'UTF-8', 'X-TIKA:encodingDetector': 'UniversalEncodingDetector', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'text_file', 'framework': 'langchain'}, page_content='He rejected repeated efforts at diplomacy. He thought the West and NATO wouldn’t respond. And he thought he could divide us at home. We were ready.  Here is what we did. We prepared extensively and carefully.'),\n",
       " Document(metadata={'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'X-TIKA:detectedEncoding': 'UTF-8', 'X-TIKA:encodingDetector': 'UniversalEncodingDetector', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'text_file', 'framework': 'langchain'}, page_content='It delivered immediate economic relief for tens of millions of Americans. Helped put food on their table, keep a roof over their heads, and cut the cost of health insurance. And as my Dad used to say, it gave people a little breathing room. And unlike the $2 Trillion tax cut passed in the previous administration that benefitted the top 1% of Americans, the American Rescue Plan helped working people—and left no one behind. Lots of jobs. \\n\\nIn fact—our economy created over 6.5 Million new jobs just last year, more jobs created in one year  \\nthan ever before in the history of America.'),\n",
       " Document(metadata={'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'X-TIKA:detectedEncoding': 'UTF-8', 'X-TIKA:encodingDetector': 'UniversalEncodingDetector', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'text_file', 'framework': 'langchain'}, page_content='And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson.'),\n",
       " Document(metadata={'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'X-TIKA:detectedEncoding': 'UTF-8', 'X-TIKA:encodingDetector': 'UniversalEncodingDetector', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'text_file', 'framework': 'langchain'}, page_content='All told, we created 369,000 new manufacturing jobs in America just last year. Powered by people I’ve met like JoJo Burgess, from generations of union steelworkers from Pittsburgh, who’s here with us tonight. As Ohio Senator Sherrod Brown says, “It’s time to bury the label “Rust Belt.” It’s time. \\n\\nBut with all the bright spots in our economy, record job growth and higher wages, too many families are struggling to keep up with the bills. Inflation is robbing them of the gains they might otherwise feel.'),\n",
       " Document(metadata={'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'X-TIKA:detectedEncoding': 'UTF-8', 'X-TIKA:encodingDetector': 'UniversalEncodingDetector', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'text_file', 'framework': 'langchain'}, page_content='Putin’s latest attack on Ukraine was premeditated and unprovoked. He rejected repeated efforts at diplomacy. He thought the West and NATO wouldn’t respond. And he thought he could divide us at home. We were ready.  Here is what we did.'),\n",
       " Document(metadata={'X-TIKA:Parsed-By': 'org.apache.tika.parser.csv.TextAndCSVParser', 'Content-Encoding': 'UTF-8', 'X-TIKA:detectedEncoding': 'UTF-8', 'X-TIKA:encodingDetector': 'UniversalEncodingDetector', 'Content-Type': 'text/plain; charset=UTF-8', 'source': 'text_file', 'framework': 'langchain'}, page_content='Danielle says Heath was a fighter to the very end. He didn’t know how to stop fighting, and neither did she. Through her pain she found purpose to demand we do better. Tonight, Danielle—we are. The VA is pioneering new ways of linking toxic exposures to diseases, already helping more veterans get benefits.'),\n",
       " Document(metadata={'summary': True, 'fcs': (0.4260254,)}, page_content='President Biden discussed several key topics in his recent statements. He emphasized the importance of the Bipartisan Infrastructure Law, calling it the most significant investment to rebuild America and highlighting the need for an \"infrastructure decade\" [1]. He also announced measures against Russian oligarchs, including assembling a task force to seize their assets and closing American airspace to Russian flights, as part of efforts to isolate Russia economically [2]. Additionally, Biden expressed his commitment to investigating the health impacts of burn pits on military personnel, referencing his late son, Major Beau Biden [3].')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.generation = GenerationConfig()\n",
    "config.search.limit = 10\n",
    "retriever = vectara.as_retriever(config=config)\n",
    "retriever.invoke(query_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f0fd28-57d2-4c5b-8b0f-ec5718f1d508",
   "metadata": {},
   "source": [
    "## Advanced LangChain query pre-processing with Vectara\n",
    "\n",
    "Vectara's \"RAG as a service\" does a lot of the heavy lifting in creating question answering or chatbot chains. The integration with LangChain provides the option to use additional capabilities such as query pre-processing  like `SelfQueryRetriever` or `MultiQueryRetriever`. Let's look at an example of using the [MultiQueryRetriever](https://python.langchain.com/docs/modules/data_connection/retrievers/MultiQueryRetriever).\n",
    "\n",
    "Since MQR uses an LLM we have to set that up - here we choose `ChatOpenAI`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e613aa4-1429-4902-bc09-c4178a7374f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The latest news on Biden's public statements includes several key announcements. President Biden has announced initiatives to address the climate crisis, including building a national network of 500,000 electric vehicle charging stations and replacing lead pipes to ensure clean water for all Americans. He also plans to fix over 65,000 miles of highway and 1,500 bridges, emphasizing the use of American products to support jobs [1]. Additionally, Biden has announced a crackdown on foreign-owned ocean carriers that have been overcharging American businesses and consumers during the pandemic [2]. Furthermore, he has stated that the U.S. will join European allies in closing American airspace to Russian flights and targeting Russian oligarchs' assets as part of efforts to isolate Russia economically [4].\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "mqr = MultiQueryRetriever.from_llm(retriever=retriever, llm=llm)\n",
    "\n",
    "\n",
    "def get_summary(documents):\n",
    "    return documents[-1].page_content\n",
    "\n",
    "\n",
    "(mqr | get_summary).invoke(query_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b16f2eb-65d1-4189-9c60-203344a8920d",
   "metadata": {},
   "source": [
    "## Vectara Chat\n",
    "\n",
    "In most uses of LangChain to create chatbots, one must integrate a special `memory` component that maintains the history of chat sessions and then uses that history to ensure the chatbot is aware of conversation history.\n",
    "\n",
    "With Vectara Chat - all of that is performed in the backend by Vectara automatically. You can look at the [Chat](https://docs.vectara.com/docs/api-reference/chat-apis/chat-apis-overview) documentation for the details, to learn more about the internals of how this is implemented, but with LangChain all you have to do is turn that feature on in the Vectara vectorstore.\n",
    "\n",
    "Let's see an example. We'll create a Chat Runnable using the `as_chat` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ed80843-4bdc-40fd-989b-9dc73ae97c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    max_used_search_results=7,\n",
    "    response_language=\"eng\",\n",
    "    generation_preset_name=\"vectara-summary-ext-24-05-med-omni\",\n",
    "    enable_factual_consistency_score=True,\n",
    ")\n",
    "search_config = SearchConfig(\n",
    "    corpora=[CorpusConfig(corpus_key=corpus_key, limit=25)],\n",
    "    reranker=MmrReranker(diversity_bias=0.2),\n",
    ")\n",
    "\n",
    "config = VectaraQueryConfig(\n",
    "    search=search_config,\n",
    "    generation=generation_config,\n",
    ")\n",
    "\n",
    "\n",
    "bot = vectara.as_chat(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22bb52f3-c987-48a6-82a1-2d51370da76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The president stated that nominating someone to serve on the United States Supreme Court is one of the most serious constitutional responsibilities he has. He nominated Circuit Court of Appeals Judge Ketanji Brown Jackson, describing her as one of the nation’s top legal minds who will continue Justice Breyer’s legacy of excellence [1].'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.invoke(\"What did the president say about Ketanji Brown Jackson?\")[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4bb23d-9e2f-456b-a85d-caedb702ee36",
   "metadata": {},
   "source": [
    "Here's an example of asking a question with some chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7921c40-56cd-4253-a7ff-95dd061f0152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, the president mentioned that Ketanji Brown Jackson succeeded Justice Breyer [1].'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.invoke(\"Did he mention who she suceeded?\")[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0841f05-f905-4fc0-a239-913837dfdfb5",
   "metadata": {},
   "source": [
    "## Chat with streaming\n",
    "\n",
    "Of course the chatbot interface also supports streaming.\n",
    "Instead of the `invoke` method you simply use `stream`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b66e926-34b6-473c-ad79-c9403b9ec85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The president acknowledged the significant impact of COVID-19 on the nation and emphasized the need to stop viewing it as a partisan issue, instead recognizing it as a severe disease that has caused much loss of life. He highlighted the progress made in combating the virus, including vaccination efforts, and noted that severe cases have decreased significantly. The president also mentioned new CDC guidelines allowing most Americans to be mask-free, indicating a move towards more normal routines [3], [4], [7]."
     ]
    }
   ],
   "source": [
    "output = {}\n",
    "curr_key = None\n",
    "for chunk in bot.stream(\"what did he said about the covid?\"):\n",
    "    for key in chunk:\n",
    "        if key not in output:\n",
    "            output[key] = chunk[key]\n",
    "        else:\n",
    "            output[key] += chunk[key]\n",
    "        if key == \"answer\":\n",
    "            print(chunk[key], end=\"\", flush=True)\n",
    "        curr_key = key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00784590-2e82-4059-be19-20e63a95e580",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "For additional capabilities you can use chaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23c19a5a-6f85-44a7-b73c-009f7c42de16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The president talked about how the COVID-19 sickness has affected many people in the country. He said he knows that people are tired and upset about it. The president also mentioned that we are doing better at fighting the virus by giving people vaccines and helping them with money. He said that things are getting better because fewer people are getting very sick, and now most people can stop wearing masks. The president asked everyone to work together and not fight about COVID-19 because it's something we all need to deal with as a team.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that explains the stuff to a five year old.  Vectara is providing the answer.\",\n",
    "        ),\n",
    "        (\"human\", \"{vectara_response}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def get_vectara_response(question: dict) -> str:\n",
    "    \"\"\"\n",
    "    Calls Vectara as_chat and returns the answer string.  This encapsulates\n",
    "    the Vectara call.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = bot.invoke(question[\"question\"])\n",
    "        return response[\"answer\"]\n",
    "    except Exception as e:\n",
    "        return \"I'm sorry, I couldn't get an answer from Vectara.\"\n",
    "\n",
    "\n",
    "# Create the chain\n",
    "chain = get_vectara_response | prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "# Invoke the chain\n",
    "result = chain.invoke({\"question\": \"what did he say about the covid?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d12cc05-7431-4b9d-971c-2769d82a81b8",
   "metadata": {},
   "source": [
    "## Use Vectara tools to create agent\n",
    "\n",
    "The code below demonstrates how to use Vectara with LangChain to create an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0072afb-e9de-4bd1-b29f-62cb504c96d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is an API key? What is a JWT token? When should I use one or the other?', additional_kwargs={}, response_metadata={}, id='ea7f3516-892e-4377-b538-2dcc50e427b7'),\n",
       "  AIMessage(content=\"An API key and a JWT (JSON Web Token) are both methods used for authentication and authorization in web applications, but they serve different purposes and have different characteristics.\\n\\n### API Key\\n- **Definition**: An API key is a unique identifier used to authenticate a client making requests to an API. It is typically a long string of characters that is passed along with the API request.\\n- **Usage**: API keys are often used for simple authentication scenarios where the client needs to be identified, but there is no need for complex user authentication or session management.\\n- **Security**: API keys are generally less secure than JWTs because they do not provide a way to verify the identity of the user making the request. If an API key is compromised, it can be used by anyone who has it.\\n- **When to Use**: Use API keys for server-to-server communication, public APIs, or when you need a simple way to track usage without requiring user authentication.\\n\\n### JWT (JSON Web Token)\\n- **Definition**: A JWT is a compact, URL-safe means of representing claims to be transferred between two parties. It consists of three parts: a header, a payload, and a signature. The signature is used to verify that the sender of the JWT is who it claims to be and to ensure that the message wasn't changed along the way.\\n- **Usage**: JWTs are commonly used for user authentication and authorization. After a user logs in, a JWT can be issued to them, which they can then use to access protected resources.\\n- **Security**: JWTs are more secure than API keys because they can include expiration times, and the signature can be verified to ensure the token's integrity. They can also carry more information (claims) about the user.\\n- **When to Use**: Use JWTs when you need to authenticate users, manage sessions, or when you need to pass user information securely between parties.\\n\\n### Summary\\n- **API Key**: Simple, less secure, used for identifying clients, suitable for public APIs or server-to-server communication.\\n- **JWT**: More complex, secure, used for user authentication and authorization, suitable for applications requiring user sessions and claims.\\n\\nIn general, if you need to authenticate users and manage sessions, go with JWT. If you just need to identify a client without user context, an API key may suffice.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 482, 'prompt_tokens': 66, 'total_tokens': 548, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BPaOLguR68G6omF1CLqdWRrM2kX8l', 'finish_reason': 'stop', 'logprobs': None}, id='run-8f58e72b-c8a0-4d81-8067-ae11773c5beb-0', usage_metadata={'input_tokens': 66, 'output_tokens': 482, 'total_tokens': 548, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from langchain_vectara.tools import VectaraRAG\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "vectara_rag_tool = VectaraRAG(\n",
    "        name=\"rag-tool\",\n",
    "        description=\"Get answers about state of the union\",\n",
    "        vectorstore=vectara,\n",
    "        corpus_key=corpus_key,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "# Set up the tools and LLM\n",
    "tools = [vectara_rag_tool]\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "\n",
    "# Construct the ReAct agent\n",
    "agent_executor = create_react_agent(llm, tools)\n",
    "\n",
    "question = \"What is an API key? What is a JWT token? When should I use one or the other?\"\n",
    "input_data = {\"messages\": [HumanMessage(content=question)]}\n",
    "\n",
    "\n",
    "agent_executor.invoke(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a584bf88-1f09-4a89-a8f1-72fac59b1c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectara-env",
   "language": "python",
   "name": "vectara-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
