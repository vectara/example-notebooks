{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eadcc8ad-f349-43da-ba1f-e1585c241fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b29d6e5-6b9c-467e-a728-5560b551a7c4",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Here I'm going to make up something that is not true: that I invented a famous technique for summarizing information. I call it HPS, but again it does not exist.\n",
    "As is not uncommon with LLMs, when I ask the LLM what HPS is, it hallucinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e25aeb3-55ad-42e8-88be-afb18f96a8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ofer's HPS technique for creating effective summaries is a structured approach that stands for \"Hook, Point, and Summary.\" This technique is designed to make summaries engaging and informative by following a specific structure:\n",
      "\n",
      "1. **Hook**: Start with an engaging opening that captures the reader's attention. This could be an interesting fact, a provocative question, or a compelling statement related to the content. The goal is to draw the reader in and make them want to learn more.\n",
      "\n",
      "2. **Point**: Clearly state the main point or thesis of the content. This is the core message or the most important takeaway that you want the reader to understand. It should be concise and directly related to the content being summarized.\n",
      "\n",
      "3. **Summary**: Provide a brief overview of the key details or supporting points that elaborate on the main point. This section should include the essential information that supports the thesis, without going into too much detail. The summary should be clear and concise, giving the reader a good understanding of the content's overall message.\n",
      "\n",
      "By following the HPS technique, you can create summaries that are not only informative but also engaging and well-structured, making it easier for readers to grasp the essential points quickly.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is Ofer's famous HPS technique to make the summary have effective structure\"}\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc0d044-5e2a-40b6-83d7-7474b9b6fedb",
   "metadata": {},
   "source": [
    "## Normal Summarization\n",
    "Now that we know what HPS is, let's do a little test.\n",
    "First, I'm going to create a few sentences (facts) that I'd like the LLM to summarize for me:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0dd0325-c32a-4f08-bd9b-fc537968a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "facts = [\n",
    "    \"AI in healthcare leverages patient data to tailor personalized treatments, improving diagnostic accuracy and treatment outcomes\",\n",
    "    \"Vectara RAG provides a platform for building AI applications to answer questions about medical literature\",\n",
    "    \"AI streamlines administrative tasks in healthcare, such as medical coding and billing, reducing manual efforts and enhancing workflow efficiency\",\n",
    "    \"AI-driven tools in healthcare enable predictive diagnostics, helping identify potential health issues before they become critical\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a022b40-13ce-415e-b0ab-e091c1301b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(task, facts):\n",
    "    prompt = f\"\"\"\n",
    "    {task}\n",
    "    <facts>\n",
    "    {'\\n'.join(facts)}\n",
    "    </facts>\n",
    "    Summary:\n",
    "    \"\"\"\n",
    "    \n",
    "    client = OpenAI()\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bb2cb54-4c46-484f-a6f3-a77163eee1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI in healthcare utilizes patient data to create personalized treatments, enhancing diagnostic accuracy and treatment outcomes. It also streamlines administrative tasks like medical coding and billing, improving workflow efficiency. AI-driven tools enable predictive diagnostics, identifying potential health issues early. Additionally, platforms like Vectara RAG support the development of AI applications for querying medical literature.\n"
     ]
    }
   ],
   "source": [
    "task1 = \"\"\"\n",
    "You task is to summarize the provided facts.\n",
    "\"\"\"\n",
    "\n",
    "print(predict(task1, facts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f37429-dd3b-4690-8be3-59ee71943514",
   "metadata": {},
   "source": [
    "As we can see: nothing wrong here. It's as we expect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c3b6de-026b-4604-a7c9-6fe329a30dfd",
   "metadata": {},
   "source": [
    "## What is a Misguided Hallucination?\n",
    "\n",
    "Now comes the funny part: \n",
    "\n",
    "I'm going to give the LLM the same task - summarizing the facts. But I'm going to ask the LLM to do this using the HPS technique.\n",
    "\n",
    "The result... a misguided hallucination.\n",
    "In essence, the LLM is following guidance that itself is a hallucination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0be7dad9-1a50-47cf-825d-7011ce0b5db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Summary:**\n",
      "\n",
      "**Hypothesis:** AI is revolutionizing the healthcare industry by enhancing various aspects of patient care and administrative efficiency.\n",
      "\n",
      "**Problem:** Traditional healthcare systems often face challenges such as inefficiencies in administrative tasks, limited diagnostic accuracy, and a one-size-fits-all approach to treatment.\n",
      "\n",
      "**Solution:** AI addresses these issues by leveraging patient data to create personalized treatment plans, improving diagnostic accuracy, and predicting potential health issues before they become critical. Additionally, AI streamlines administrative tasks like medical coding and billing, reducing manual efforts and enhancing workflow efficiency. Platforms like Vectara RAG further support the development of AI applications to answer complex questions about medical literature, contributing to more informed healthcare decisions.\n"
     ]
    }
   ],
   "source": [
    "task2 = \"\"\"\n",
    "You task is to summarize the provided facts.\n",
    "Using Ofer's famous HPS technique to make the summary have effective structure.\n",
    "\"\"\"\n",
    "\n",
    "print(predict(task2, facts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320f1518-e703-468c-b898-08531e9dbb23",
   "metadata": {},
   "source": [
    "In fact, the LLM hallucinated \"HPS\" differently each time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5d1bf4-6135-4338-943d-c19635becdd8",
   "metadata": {},
   "source": [
    "## Why is misguided hallucination important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff45a2ae-4012-41eb-acbc-e52fcfe2895b",
   "metadata": {},
   "source": [
    "If you write prompts for LLM, it's important to realize that writing concise instructions is very important.\n",
    "In many cases, we can write something in the LLM prompt that provides instructions for what we want to get done, only for the LLM to not understand what we want and hallucinate guidance, resulting in a bad outcome. In this case it was quite obvious, but it may not be that way every time.\n",
    "\n",
    "So \"prompt carefully!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d4d854-b3e8-4d45-8c17-0d9c9f1e84e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
