{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/vectara/example-notebooks/blob/main/notebooks/api-examples/5-sub-agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "# Vectara Sub-Agents: Building Modular AI Workflows\n",
    "\n",
    "This notebook demonstrates how to use Vectara's **sub-agents** capability to build modular, specialized AI workflows. Sub-agents allow a parent agent to delegate tasks to specialized child agents, enabling:\n",
    "\n",
    "- **Context isolation**: Each sub-agent maintains its own conversation history\n",
    "- **Specialized configuration**: Each sub-agent can have distinct instructions and tools\n",
    "- **Reusability**: Build once, invoke from any parent agent\n",
    "- **Parallel execution**: Run multiple sub-agents simultaneously\n",
    "- **Better performance**: Smaller, focused agents make fewer mistakes\n",
    "\n",
    "We also demonstrate combining sub-agents with a **Lambda Tool** (API Payload Validator) that validates generated API code to catch hallucinations and ensure correctness before presenting to users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## About Vectara\n",
    "\n",
    "[Vectara](https://vectara.com/) is the Agent Operating System for trusted enterprise AI: a unified Agentic RAG platform with built-in multi-modal retrieval, orchestration, and always-on governance. Deploy it on-prem (air-gapped), in your VPC, or as SaaS.\n",
    "\n",
    "Vectara provides a complete API-first platform for building production RAG and agentic applications:\n",
    "\n",
    "- **Simple Integration**: RESTful APIs and SDKs (Python, JavaScript) for quick integration into any stack\n",
    "- **Flexible Deployment**: Choose SaaS, VPC, or on-premises deployment based on your security requirements\n",
    "- **Multi-Modal Support**: Index and search across text, tables, and images from PDFs, documents, and structured data\n",
    "- **Advanced Retrieval**: Hybrid search combining semantic and keyword matching with state-of-the-art reranking\n",
    "- **Grounded Generation**: LLM responses with citations and factual consistency scores to reduce hallucinations\n",
    "- **Enterprise-Ready**: Built-in access controls, audit logging, and compliance (SOC2, HIPAA) from day one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "This notebook assumes you've completed Notebooks 1-4:\n",
    "- Notebook 1: Created two corpora (ai-research-papers and vectara-docs)\n",
    "- Notebook 2: Ingested AI research papers and Vectara documentation\n",
    "- Notebook 3: Queried the data with various techniques\n",
    "- Notebook 4: Created agents that can search and reason across data\n",
    "\n",
    "Now we'll create a multi-agent system where specialized sub-agents handle domain-specific tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Why Sub-Agents?\n",
    "\n",
    "When agents face complex, multi-step tasks, they often run into context window limits or need specialized capabilities. Consider a comprehensive research assistant that needs to:\n",
    "\n",
    "1. Analyze academic papers for theoretical foundations\n",
    "2. Search product documentation for implementation details\n",
    "3. Synthesize findings into actionable recommendations\n",
    "\n",
    "A single monolithic agent trying to handle all of this might:\n",
    "- Become confused between different instruction sets\n",
    "- Consume excessive context with domain-specific guidelines\n",
    "- Produce lower quality results due to competing priorities\n",
    "\n",
    "**Sub-agents solve this by delegation**: the parent agent orchestrates, while specialized sub-agents focus on their domains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Corpus: tutorial-ai-research-papers\n",
      "Docs Corpus: tutorial-vectara-docs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Get credentials from environment variables\n",
    "api_key = os.environ['VECTARA_API_KEY']\n",
    "\n",
    "# Corpus keys from previous notebooks\n",
    "research_corpus_key = 'tutorial-ai-research-papers'\n",
    "docs_corpus_key = 'tutorial-vectara-docs'\n",
    "\n",
    "# Base API URL\n",
    "BASE_URL = \"https://api.vectara.io/v2\"\n",
    "\n",
    "# Common headers\n",
    "headers = {\n",
    "    \"x-api-key\": api_key,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "print(f\"Research Corpus: {research_corpus_key}\")\n",
    "print(f\"Docs Corpus: {docs_corpus_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 1: Create Specialized Sub-Agents\n",
    "\n",
    "We'll create three specialized agents that will serve as sub-agents:\n",
    "\n",
    "1. **Research Paper Analyst**: Expert at analyzing academic papers on RAG, embeddings, and retrieval\n",
    "2. **Documentation Expert**: Expert at finding implementation guidance from Vectara docs\n",
    "3. **Web Search Expert**: Expert at searching the web for current information and news\n",
    "\n",
    "Each agent has focused instructions and tools optimized for its domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### Sub-Agent 1: Research Paper Analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to delete and create agent\n",
    "def delete_and_create_agent(agent_config, agent_name):\n",
    "    \"\"\"Delete agent if it exists, then create a new one.\"\"\"\n",
    "    # Check if agent already exists and delete it\n",
    "    list_response = requests.get(f\"{BASE_URL}/agents\", headers=headers)\n",
    "\n",
    "    if list_response.status_code == 200:\n",
    "        agents = list_response.json().get('agents', [])\n",
    "        for agent in agents:\n",
    "            if agent.get('name') == agent_name:\n",
    "                existing_key = agent['key']\n",
    "                print(f\"Deleting existing agent '{agent_name}' ({existing_key})\")\n",
    "                delete_response = requests.delete(f\"{BASE_URL}/agents/{existing_key}\", headers=headers)\n",
    "                if delete_response.status_code == 204:\n",
    "                    print(f\"Deleted agent: {existing_key}\")\n",
    "                else:\n",
    "                    print(f\"Error deleting {existing_key}: {delete_response.text}\")\n",
    "                break\n",
    "\n",
    "    # Create new agent\n",
    "    response = requests.post(f\"{BASE_URL}/agents\", headers=headers, json=agent_config)\n",
    "\n",
    "    if response.status_code == 201:\n",
    "        agent_data = response.json()\n",
    "        print(f\"Created agent '{agent_name}'\")\n",
    "        print(f\"Agent Key: {agent_data['key']}\")\n",
    "        return agent_data['key']\n",
    "    else:\n",
    "        print(f\"Error creating agent: {response.status_code}\")\n",
    "        print(f\"{response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent 'Research Paper Analyst'\n",
      "Agent Key: agt_research_paper_analyst_fbd0\n"
     ]
    }
   ],
   "source": [
    "# Create Research Paper Analyst sub-agent\n",
    "reranker_config = {\n",
    "    \"type\": \"chain\",\n",
    "    \"rerankers\": [\n",
    "        {\n",
    "            \"type\": \"customer_reranker\",\n",
    "            \"reranker_id\": \"rnk_272725719\", \n",
    "            \"limit\": 25,\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"mmr\",\n",
    "            \"diversity_bias\": 0.05\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "research_analyst_config = {\n",
    "    \"name\": \"Research Paper Analyst\",\n",
    "    \"description\": \"Specialized agent for analyzing academic research papers on RAG, embeddings, and retrieval techniques\",\n",
    "    \"model\": {\"name\": \"gpt-4o\"},\n",
    "    \"first_step\": {\n",
    "        \"type\": \"conversational\",\n",
    "        \"instructions\": [\n",
    "            {\n",
    "                \"type\": \"inline\",\n",
    "                \"name\": \"research_analyst_instructions\",\n",
    "                \"template\": \"\"\"You are an expert academic research analyst specializing in AI, machine learning, and natural language processing.\n",
    "\n",
    "Your expertise includes:\n",
    "- Retrieval Augmented Generation (RAG) architectures\n",
    "- Dense and sparse retrieval methods\n",
    "- Embedding models and vector representations\n",
    "- Transformer architectures and attention mechanisms\n",
    "- Information retrieval benchmarks and evaluation metrics\n",
    "\n",
    "When analyzing research papers:\n",
    "1. Identify the key contributions and novel techniques\n",
    "2. Explain technical concepts clearly with examples\n",
    "3. Highlight practical implications and limitations\n",
    "4. Compare with related work when relevant\n",
    "5. Provide citations to the source papers\n",
    "\n",
    "Always use tools to retrieve relevant content to answer user queries.\n",
    "Always ground your response in the retrieved content. \n",
    "If you cannot answer the user question from the retrieved content from tools, just say \"I don't know\"\n",
    "\n",
    "IMPORTANT: When responding, provide a complete, self-contained summary that includes all relevant findings.\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        \"output_parser\": {\"type\": \"default\"}\n",
    "    },\n",
    "    \"tool_configurations\": {\n",
    "        \"research_search\": {\n",
    "            \"type\": \"corpora_search\",\n",
    "            \"query_configuration\": {\n",
    "                \"search\": {\n",
    "                    \"corpora\": [{\"corpus_key\": research_corpus_key}],\n",
    "                    \"limit\": 100,\n",
    "                    \"context_configuration\": {\n",
    "                        \"sentences_before\": 2,\n",
    "                        \"sentences_after\": 2\n",
    "                    },\n",
    "                    \"reranker\": reranker_config,                   \n",
    "                },\n",
    "                \"save_history\": True,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "research_analyst_key = delete_and_create_agent(research_analyst_config, \"Research Paper Analyst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "### Sub-Agent 2: Vectara Documentation Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent 'Documentation Expert'\n",
      "Agent Key: agt_documentation_expert_4a1e\n"
     ]
    }
   ],
   "source": [
    "# Create Documentation Expert sub-agent\n",
    "\n",
    "docs_expert_config = {\n",
    "    \"name\": \"Documentation Expert\",\n",
    "    \"description\": \"Specialized agent for finding implementation guidance and best practices from Vectara documentation\",\n",
    "    \"model\": {\"name\": \"gpt-4o\"},\n",
    "    \"first_step\": {\n",
    "        \"type\": \"conversational\",\n",
    "        \"instructions\": [\n",
    "            {\n",
    "                \"type\": \"inline\",\n",
    "                \"name\": \"docs_expert_instructions\",\n",
    "                \"template\": \"\"\"You are a Vectara platform expert who helps developers implement AI solutions.\n",
    "\n",
    "Your expertise includes:\n",
    "- Vectara API integration (indexing, querying, agents)\n",
    "- Corpus management and configuration\n",
    "- Search optimization (hybrid search, reranking, filters)\n",
    "- RAG implementation best practices\n",
    "- SDK usage and code examples\n",
    "\n",
    "When providing guidance:\n",
    "1. Give specific, actionable implementation steps using the API.\n",
    "2. Include relevant API endpoints and parameters\n",
    "3. Your examples should show how to use the API, not using Vectara SDK.\n",
    "4. Highlight configuration options and trade-offs\n",
    "5. Point to relevant documentation sections\n",
    "\n",
    "Always use tools to retrieve relevant content to answer user queries.\n",
    "Always ground your response in the retrieved content. \n",
    "If you cannot answer the user question from the retrieved content from tools, just say \"I don't know\"\n",
    "\n",
    "When responding, provide a complete, self-contained answer with all implementation details.\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        \"output_parser\": {\"type\": \"default\"}\n",
    "    },\n",
    "    \"tool_configurations\": {\n",
    "        \"docs_search\": {\n",
    "            \"type\": \"corpora_search\",\n",
    "            \"query_configuration\": {\n",
    "                \"search\": {\n",
    "                    \"corpora\": [{\"corpus_key\": docs_corpus_key}],\n",
    "                    \"limit\": 100,\n",
    "                    \"context_configuration\": {\n",
    "                        \"sentences_before\": 2,\n",
    "                        \"sentences_after\": 2\n",
    "                    },\n",
    "                    \"reranker\": reranker_config,                   \n",
    "                },\n",
    "                \"save_history\": True,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "docs_expert_key = delete_and_create_agent(docs_expert_config, \"Documentation Expert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ir8dahqid7b",
   "metadata": {},
   "source": [
    "### Sub-Agent 3: Web Search Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8j6idifi4m3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent 'Web Search Expert'\n",
      "Agent Key: agt_web_search_expert_2470\n"
     ]
    }
   ],
   "source": [
    "# Create Web Search Expert sub-agent\n",
    "\n",
    "web_search_expert_config = {\n",
    "    \"name\": \"Web Search Expert\",\n",
    "    \"description\": \"Specialized agent for searching the web for current information, news, and general knowledge\",\n",
    "    \"model\": {\"name\": \"gpt-4o\"},\n",
    "    \"first_step\": {\n",
    "        \"type\": \"conversational\",\n",
    "        \"instructions\": [\n",
    "            {\n",
    "                \"type\": \"inline\",\n",
    "                \"name\": \"web_search_expert_instructions\",\n",
    "                \"template\": \"\"\"You are a web search expert who helps find current and relevant information from the internet.\n",
    "\n",
    "Your expertise includes:\n",
    "- Finding up-to-date information on any topic\n",
    "- Researching current events and news\n",
    "- Locating authoritative sources and references\n",
    "- Comparing information across multiple sources\n",
    "- Fact-checking and verification\n",
    "\n",
    "When searching and responding:\n",
    "1. Use web search to find relevant, current information\n",
    "2. Prioritize authoritative and credible sources\n",
    "3. Provide context about when information was published\n",
    "4. Cite your sources with URLs when available\n",
    "5. Synthesize information from multiple sources when appropriate\n",
    "\n",
    "Always use the web search tool to find information.\n",
    "If you cannot find relevant information, say so clearly.\n",
    "\n",
    "IMPORTANT: When responding, provide a complete, well-sourced answer with citations.\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        \"output_parser\": {\"type\": \"default\"}\n",
    "    },\n",
    "    \"tool_configurations\": {\n",
    "        \"web_search\": {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "web_search_expert_key = delete_and_create_agent(web_search_expert_config, \"Web Search Expert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4n995hnpf",
   "metadata": {},
   "source": [
    "## Step 2: Create an API Validator Lambda Tool\n",
    "\n",
    "Before creating the orchestrator, we'll add a **Lambda Tool** that validates Vectara API payloads. This tool is *essential* for answering implementation questions because:\n",
    "\n",
    "- LLMs may hallucinate field names (e.g., `corpus_id` instead of `corpus_key`)\n",
    "- Parameter ranges need validation (e.g., `lexical_interpolation` must be 0-1)\n",
    "- Required fields must be present for the code to actually work\n",
    "- The orchestrator can't claim code is \"working\" without validating it first\n",
    "\n",
    "Unlike optional analysis tools that LLMs may skip, this validator is essential—the orchestrator must use it before presenting API code examples to ensure correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "nurhxwplzh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to manage lambda tools\n",
    "def delete_and_create_tool(tool_config, tool_name):\n",
    "    \"\"\"Delete tool if it exists, then create a new one.\"\"\"\n",
    "    list_response = requests.get(f\"{BASE_URL}/tools\", headers=headers)\n",
    "    \n",
    "    if list_response.status_code == 200:\n",
    "        tools = list_response.json().get('tools', [])\n",
    "        for tool in tools:\n",
    "            if tool.get('name') == tool_name:\n",
    "                existing_id = tool['id']\n",
    "                print(f\"Deleting existing tool '{tool_name}' ({existing_id})\")\n",
    "                delete_response = requests.delete(f\"{BASE_URL}/tools/{existing_id}\", headers=headers)\n",
    "                if delete_response.status_code == 204:\n",
    "                    print(f\"Deleted tool: {existing_id}\")\n",
    "                break\n",
    "    \n",
    "    response = requests.post(f\"{BASE_URL}/tools\", headers=headers, json=tool_config)\n",
    "    \n",
    "    if response.status_code == 201:\n",
    "        tool_data = response.json()\n",
    "        print(f\"Created tool '{tool_name}'\")\n",
    "        print(f\"Tool ID: {tool_data['id']}\")\n",
    "        return tool_data['id']\n",
    "    else:\n",
    "        print(f\"Error creating tool: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3umya5qan8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created tool 'vectara_api_validator'\n",
      "Tool ID: tol_2223\n"
     ]
    }
   ],
   "source": [
    "# Create the Vectara API Payload Validator lambda tool\n",
    "api_validator_code = '''\n",
    "import json\n",
    "\n",
    "def process(\n",
    "    endpoint: str,\n",
    "    payload: str,\n",
    "    method: str = \"POST\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Validate a Vectara API request payload.\n",
    "    \n",
    "    Args:\n",
    "        endpoint: API endpoint (query, index, corpus, agents)\n",
    "        payload: JSON string of the request body\n",
    "        method: HTTP method (POST, GET, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        Validation result with errors, warnings, and corrected payload\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    warnings = []\n",
    "    \n",
    "    # Parse the payload\n",
    "    try:\n",
    "        data = json.loads(payload)\n",
    "    except json.JSONDecodeError as e:\n",
    "        return {\n",
    "            \"valid\": False,\n",
    "            \"endpoint\": endpoint,\n",
    "            \"errors\": [f\"Invalid JSON: {str(e)}\"],\n",
    "            \"warnings\": [],\n",
    "            \"corrected_payload\": None\n",
    "        }\n",
    "    \n",
    "    corrected = dict(data)\n",
    "\n",
    "    # Validate API version - must use v2, not v1\n",
    "    if 'vectara.io' in endpoint:\n",
    "        if '/v1/' in endpoint or '/v1' in endpoint:\n",
    "            errors.append(\"Invalid API version: v1 is deprecated. Use https://api.vectara.io/v2 endpoints.\")\n",
    "\n",
    "    # Validation rules by endpoint\n",
    "    if endpoint == \"query\":\n",
    "        # Required fields\n",
    "        if \"query\" not in data:\n",
    "            errors.append(\"Missing required field: 'query'\")\n",
    "            corrected[\"query\"] = \"<YOUR_QUERY>\"\n",
    "        \n",
    "        if \"search\" not in data:\n",
    "            errors.append(\"Missing required field: 'search'\")\n",
    "            corrected[\"search\"] = {\"corpora\": [{\"corpus_key\": \"<YOUR_CORPUS_KEY>\"}]}\n",
    "        else:\n",
    "            search = data.get(\"search\", {})\n",
    "            if \"corpora\" not in search:\n",
    "                errors.append(\"Missing required field: 'search.corpora'\")\n",
    "            else:\n",
    "                for i, corpus in enumerate(search.get(\"corpora\", [])):\n",
    "                    if \"corpus_key\" not in corpus:\n",
    "                        errors.append(f\"Missing corpus_key in corpora[{i}]\")\n",
    "                    \n",
    "                    # Validate lexical_interpolation range\n",
    "                    if \"lexical_interpolation\" in corpus:\n",
    "                        li = corpus[\"lexical_interpolation\"]\n",
    "                        if not isinstance(li, (int, float)) or li < 0 or li > 1:\n",
    "                            errors.append(f\"lexical_interpolation must be 0-1, got: {li}\")\n",
    "                            corrected[\"search\"][\"corpora\"][i][\"lexical_interpolation\"] = 0.025\n",
    "            \n",
    "            # Validate limit\n",
    "            if \"limit\" in search:\n",
    "                limit = search[\"limit\"]\n",
    "                if not isinstance(limit, int) or limit < 1:\n",
    "                    warnings.append(f\"limit should be positive integer, got: {limit}\")\n",
    "        \n",
    "        # Check for common hallucinations\n",
    "        hallucinated_fields = [\"corpus_id\", \"customer_id\", \"num_results\", \"query_text\"]\n",
    "        for field in hallucinated_fields:\n",
    "            if field in data:\n",
    "                errors.append(f\"Invalid field '{field}' - this is a hallucination. Did you mean: \" +\n",
    "                            {\"corpus_id\": \"search.corpora[].corpus_key\",\n",
    "                             \"customer_id\": \"(not needed with API key)\",\n",
    "                             \"num_results\": \"search.limit\",\n",
    "                             \"query_text\": \"query\"}.get(field, \"check docs\"))\n",
    "    \n",
    "    elif endpoint == \"index\":\n",
    "        if \"document_id\" not in data and \"id\" not in data:\n",
    "            errors.append(\"Missing required field: 'document_id' or 'id'\")\n",
    "        \n",
    "        has_content = \"parts\" in data or \"document_parts\" in data or \"content\" in data\n",
    "        if not has_content:\n",
    "            errors.append(\"Missing content: need 'parts', 'document_parts', or 'content'\")\n",
    "        \n",
    "        # Check for hallucinations\n",
    "        if \"text\" in data and \"parts\" not in data:\n",
    "            warnings.append(\"'text' alone is not valid - use 'parts' array with 'text' inside\")\n",
    "    \n",
    "    elif endpoint == \"agents\":\n",
    "        if \"name\" not in data:\n",
    "            errors.append(\"Missing required field: 'name'\")\n",
    "        if \"model\" not in data:\n",
    "            errors.append(\"Missing required field: 'model'\")\n",
    "        if \"first_step\" not in data:\n",
    "            errors.append(\"Missing required field: 'first_step'\")\n",
    "    \n",
    "    elif endpoint == \"corpus\":\n",
    "        if \"key\" not in data and \"name\" not in data:\n",
    "            warnings.append(\"Consider providing 'key' or 'name' for the corpus\")\n",
    "    \n",
    "    return {\n",
    "        \"valid\": len(errors) == 0,\n",
    "        \"endpoint\": endpoint,\n",
    "        \"method\": method,\n",
    "        \"errors\": errors,\n",
    "        \"warnings\": warnings,\n",
    "        \"corrected_payload\": corrected if errors else data\n",
    "    }\n",
    "'''\n",
    "\n",
    "api_validator_config = {\n",
    "    \"type\": \"lambda\",\n",
    "    \"language\": \"python\",\n",
    "    \"name\": \"vectara_api_validator\",\n",
    "    \"title\": \"Vectara API Payload Validator\",\n",
    "    \"description\": \"Validate Vectara API request payloads before presenting to users. Checks required fields, validates parameter ranges (e.g., lexical_interpolation 0-1), and catches common LLM hallucinations (wrong field names). Returns validation status, errors, and corrected payload. ALWAYS use this before showing API code examples.\",\n",
    "    \"code\": api_validator_code\n",
    "}\n",
    "\n",
    "api_validator_id = delete_and_create_tool(api_validator_config, \"vectara_api_validator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 3: Create the Parent Orchestrator Agent\n",
    "\n",
    "Now we'll create a parent agent that can delegate to the sub-agents and use the API validator. The parent agent:\n",
    "- Analyzes user requests to determine which sub-agent(s) to invoke\n",
    "- Delegates domain-specific tasks to the appropriate sub-agent\n",
    "- **Uses the API validator** to ensure generated code is correct before presenting it back to the user.\n",
    "- Synthesizes responses from multiple sub-agents into a cohesive answer\n",
    "\n",
    "### Sub-Agent Tool Configuration\n",
    "\n",
    "Sub-agents are configured as tools using the `sub_agent` type:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"type\": \"sub_agent\",\n",
    "  \"description_template\": \"Description the LLM sees when deciding to use this tool\",\n",
    "  \"sub_agent_configuration\": {\n",
    "    \"agent_key\": \"the_sub_agent_key\",\n",
    "    \"session_mode\": \"ephemeral\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### Session Modes\n",
    "\n",
    "When specifying in the parent agent how sub-agents are to be used, you need to define the \"session mode\":\n",
    "- **`persistent`**: Always reuse the same session, accumulating knowledge across invocations\n",
    "- **`ephemeral`**: Create a fresh session every time, ensuring no state leakage\n",
    "- **`llm_controlled`**: The LLM decides whether to resume an existing session or create a new one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent 'AI Research Orchestrator'\n",
      "Agent Key: agt_ai_research_orchestrator_ccf0\n"
     ]
    }
   ],
   "source": [
    "# Create the Orchestrator Agent with sub-agent tools and API validator\n",
    "orchestrator_config = {\n",
    "    \"name\": \"AI Research Orchestrator\",\n",
    "    \"description\": \"Orchestrator agent that delegates to specialized sub-agents for comprehensive AI research assistance\",\n",
    "    \"model\": {\"name\": \"gpt-4o\"},\n",
    "    \"first_step\": {\n",
    "        \"type\": \"conversational\",\n",
    "        \"instructions\": [\n",
    "            {\n",
    "                \"type\": \"inline\",\n",
    "                \"name\": \"orchestrator_instructions\",\n",
    "                \"template\": \"\"\"You are an AI research orchestrator that helps users understand and implement AI technologies.\n",
    "\n",
    "Your workflow:\n",
    "1. Analyze the user's question to determine what expertise is needed.\n",
    "2. Use appropriate sub-agent(s) to gather information:\n",
    "   - research_analyst: for academic/theoretical content\n",
    "   - docs_expert: for implementation guidance\n",
    "   - web_search_expert: for current news/trends\n",
    "3. When your response includes Vectara API code examples or implementation details:\n",
    "   - Generate the JSON payload\n",
    "   - ALWAYS validate it using the api_validator tool before presenting\n",
    "   - If validation fails, fix the errors and validate again\n",
    "   - Only present validated, working code to the user\n",
    "4. Synthesize all responses into a comprehensive answer.\n",
    "\n",
    "IMPORTANT: \n",
    "- Never show API code without validating it first. Users trust that code examples will work.\n",
    "- When responding, provide a complete, well-sourced answer with citations.\n",
    "\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        \"output_parser\": {\"type\": \"default\"}\n",
    "    },\n",
    "    \"tool_configurations\": {\n",
    "        \"research_analyst\": {\n",
    "            \"type\": \"sub_agent\",\n",
    "            \"description_template\": \"Research academic research papers for theoretical foundations and research findings.\",\n",
    "            \"sub_agent_configuration\": {\n",
    "                \"agent_key\": research_analyst_key,\n",
    "                \"session_mode\": \"ephemeral\"\n",
    "            }\n",
    "        },\n",
    "        \"docs_expert\": {\n",
    "            \"type\": \"sub_agent\",\n",
    "            \"description_template\": \"Research Vectara documentation for API usage, code examples, configuration, and best practices.\",\n",
    "            \"sub_agent_configuration\": {\n",
    "                \"agent_key\": docs_expert_key,\n",
    "                \"session_mode\": \"ephemeral\"\n",
    "            }\n",
    "        },\n",
    "        \"web_search_expert\": {\n",
    "            \"type\": \"sub_agent\",\n",
    "            \"description_template\": \"Search the web for up-to-date information, news, and current trends.\",\n",
    "            \"sub_agent_configuration\": {\n",
    "                \"agent_key\": web_search_expert_key,\n",
    "                \"session_mode\": \"ephemeral\"\n",
    "            }\n",
    "        },\n",
    "        \"api_validator\": {\n",
    "            \"type\": \"lambda\",\n",
    "            \"tool_id\": api_validator_id\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "orchestrator_key = delete_and_create_agent(orchestrator_config, \"AI Research Orchestrator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Step 4: Test the Multi-Agent Workflow\n",
    "\n",
    "Now let's test the orchestrator with different types of questions to see how it delegates to sub-agents and uses the API validator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to send messages and display responses\n",
    "def chat_with_agent(agent_key, session_key, message, show_events=False):\n",
    "    \"\"\"Send a message to an agent and return the response.\"\"\"\n",
    "    message_data = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"content\": message\n",
    "            }\n",
    "        ],\n",
    "        \"stream_response\": False\n",
    "    }\n",
    "    \n",
    "    url = f\"{BASE_URL}/agents/{agent_key}/sessions/{session_key}/events\"\n",
    "    response = requests.post(url, headers=headers, json=message_data)\n",
    "    \n",
    "    if response.status_code == 201:\n",
    "        event_data = response.json()\n",
    "        \n",
    "        if show_events:\n",
    "            print(\"\\n------ Agent Events ------\")\n",
    "            for event in event_data.get('events', []):\n",
    "                event_type = event.get('type', 'INVALID')\n",
    "                print(f\"Event: {event_type}\")\n",
    "                if event_type == 'tool_input':\n",
    "                    tool_name = event.get('tool_configuration_name', 'N/A')\n",
    "                    print(f\"  Tool: {tool_name}\")\n",
    "                    tool_input = event.get(\"tool_input\", {})\n",
    "                    if tool_input.get(\"message\"):\n",
    "                        print(f\"  Input: {tool_input['message']}...\")\n",
    "                    # Show API validator inputs\n",
    "                    if tool_input.get(\"endpoint\"):\n",
    "                        print(f\"  Validating endpoint: {tool_input['endpoint']}\")\n",
    "                if event_type == 'tool_output':\n",
    "                    tool_name = event.get('tool_configuration_name', 'N/A')\n",
    "                    print(f\"  Tool: {tool_name}\")\n",
    "                    tool_output = event.get(\"tool_output\", {})\n",
    "                    # Show sub-agent response preview\n",
    "                    if tool_output.get(\"sub_agent_response\"):\n",
    "                        print(f\"  Response (200 chars): {tool_output['sub_agent_response'][:200]}...\")\n",
    "                    # Show API validator output\n",
    "                    if tool_output.get(\"lambda_response\"):\n",
    "                        lambda_resp = tool_output[\"lambda_response\"]\n",
    "                        if \"valid\" in lambda_resp:\n",
    "                            valid = lambda_resp[\"valid\"]\n",
    "                            print(f\"  Validation Result: {'VALID' if valid else 'INVALID'}\")\n",
    "                            if lambda_resp.get(\"errors\"):\n",
    "                                print(f\"    Errors: {lambda_resp['errors']}\")\n",
    "                            if lambda_resp.get(\"warnings\"):\n",
    "                                print(f\"    Warnings: {lambda_resp['warnings']}\")\n",
    "            print(\"-\"*25)\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        # Extract agent output\n",
    "        for event in event_data.get('events', []):\n",
    "            if event.get('type') == 'agent_output':\n",
    "                return event.get('content', 'No content')\n",
    "        \n",
    "        return \"No agent output found\"\n",
    "    else:\n",
    "        return f\"Error: {response.status_code} - {response.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session Created: ase_orchestrator_session_20251205-153920_5519\n"
     ]
    }
   ],
   "source": [
    "# Create a session for the orchestrator\n",
    "session_name = f\"Orchestrator Session {datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "session_config = {\n",
    "    \"name\": session_name,\n",
    "    \"metadata\": {\n",
    "        \"purpose\": \"sub_agent_demo\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{BASE_URL}/agents/{orchestrator_key}/sessions\",\n",
    "    headers=headers,\n",
    "    json=session_config\n",
    ")\n",
    "\n",
    "if response.status_code == 201:\n",
    "    session_data = response.json()\n",
    "    orchestrator_session_key = session_data[\"key\"]\n",
    "    print(f\"Session Created: {orchestrator_session_key}\")\n",
    "else:\n",
    "    print(f\"Error: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "### Test 1: Research-Focused Question\n",
    "\n",
    "This question should primarily use the research_analyst sub-agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What are the key innovations in RAG?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "------ Agent Events ------\n",
      "Event: input_message\n",
      "Event: tool_input\n",
      "  Tool: research_analyst\n",
      "  Input: Research the latest academic and theoretical advancements in Retrieval-Augmented Generation (RAG). Focus on any novel methodologies, improvements, or theoretical innovations that have been introduced in the field recently....\n",
      "Event: tool_input\n",
      "  Tool: web_search_expert\n",
      "  Input: Search for recent news and articles discussing the key innovations and latest trends in Retrieval-Augmented Generation (RAG) technology. Look for breakthroughs, improvements, or novel applications in the industry or academic research....\n",
      "Event: tool_output\n",
      "  Tool: research_analyst\n",
      "  Response (200 chars): Recent advancements in Retrieval-Augmented Generation (RAG) have focused on enhancing the integration of retrieval mechanisms with generative models to improve knowledge-intensive tasks. Key contribut...\n",
      "Event: tool_output\n",
      "  Tool: web_search_expert\n",
      "  Response (200 chars): Retrieval-Augmented Generation (RAG) technology has seen notable advancements in 2023, particularly in how it integrates external knowledge with large language models (LLMs) to enhance the performance...\n",
      "Event: agent_output\n",
      "-------------------------\n",
      "\n",
      "\n",
      "Agent Response:\n",
      "\n",
      "Retrieval-Augmented Generation (RAG) technology is evolving rapidly, with several key innovations shaping its current landscape. Below is a synthesis of the latest theoretical advancements and practical applications:\n",
      "\n",
      "### Academic and Theoretical Innovations in RAG\n",
      "\n",
      "1. **Hybrid Memory Models**: RAG systems now use a combination of parametric (internal model knowledge) and non-parametric (external data) memory, allowing them to dynamically incorporate knowledge into language generation tasks. This setup enhances both the accuracy and the contextual relevance of generated outputs [Lewis et al., 2020].\n",
      "\n",
      "2. **Probabilistic Modeling**: RAG models are implemented with a probabilistic framework that supports end-to-end training. This integration helps in generating text that is both contextually relevant and factually accurate by using retrieved documents to support generation, minimizing the reliance on extensive pre-training [Lewis et al., 2020].\n",
      "\n",
      "3. **Enhanced Retrieval Techniques**: By implementing robust retrieval mechanisms such as Dense Passage Retriever (DPR), RAG models achieve high accuracy in information retrieval without the need for complex re-ranking systems. This improvement optimizes the model's ability to provide factual support for generative tasks [Lewis et al., 2020].\n",
      "\n",
      "4. **Diversity in Outputs**: RAG has developed techniques to generate more diverse and informative responses without relying on complex decoding methods. This diversity is particularly beneficial for open-domain natural language processing tasks [Lewis et al., 2020].\n",
      "\n",
      "5. **Hallucination Detection and Mitigation**: The development of benchmarks like RAGTruth facilitates fine-grained detection and mitigation of hallucinations, making RAG models more reliable and trustworthy [NAACL 2025].\n",
      "\n",
      "### Recent Trends and Industry Applications\n",
      "\n",
      "1. **Integration with Large Language Models**: RAG innovation focuses on merging external data sources with large language models (LLMs) to surpass the limitations of pre-trained models, thereby enhancing the contextual richness of outputs [source](https://www.linkedin.com/pulse/retrieval-augmented-generation-rag-comprehensive-analysis-janvier-ienoe).\n",
      "\n",
      "2. **Dynamic and Real-Time Data Use**: A significant advancement is in real-time data integration, which makes RAG suitable for applications needing current information, enhancing its utility in domains like news aggregation and customer service [source](https://mofotech.mofo.com/topics/retrieval-augmented-generation-rag-to-generate-richer-outputs).\n",
      "\n",
      "3. **Addressing LLM Limitations**: By acting as a \\\"personal library assistant,\\\" RAG addresses issues like outdated information and hallucinations associated with LLMs, ensuring that generated content is more relevant and current [source](https://www.edps.europa.eu/data-protection/technology-monitoring/techsonar/retrieval-augmented-generation-rag).\n",
      "\n",
      "4. **Broad Application Spectrum**: RAG’s ability to use live data feeds extends its application across industries such as finance and healthcare, where current data is crucial for decision-making [source](https://www.promptingguide.ai/research/rag).\n",
      "\n",
      "These advancements emphasize RAG's capability to enhance the accuracy and applicability of generative AI systems by integrating dynamic external knowledge, thereby expanding the potential use cases of AI technologies.\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the key innovations in RAG?\"\n",
    "print(f\"User: {query}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "response = chat_with_agent(\n",
    "    orchestrator_key,\n",
    "    orchestrator_session_key,\n",
    "    query,\n",
    "    show_events=True\n",
    ")\n",
    "\n",
    "print(f\"Agent Response:\\n\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "### Test 2: Implementation Question with API Validation\n",
    "\n",
    "This question asks for working code, which should trigger the API validator to ensure correctness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Give me working code to search a corpus for AI research papers using hybrid search with Vectara's API.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "------ Agent Events ------\n",
      "Event: input_message\n",
      "Event: tool_input\n",
      "  Tool: docs_expert\n",
      "  Input: Provide a code example that demonstrates how to perform a hybrid search for AI research papers using Vectara's API. Focus on integrating both vector search and keyword search to ensure comprehensive retrieval within a corpus. Please include necessary configurations and best practices for implementation....\n",
      "Event: tool_output\n",
      "  Tool: docs_expert\n",
      "  Response (200 chars): To perform a hybrid search using Vectara's API and integrate both vector search and keyword search capabilities, you will need to use the Vectara API's querying capabilities to leverage semantic under...\n",
      "Event: tool_input\n",
      "  Tool: api_validator\n",
      "  Validating endpoint: https://api.vectara.io/v2/search\n",
      "Event: tool_output\n",
      "  Tool: api_validator\n",
      "Event: agent_output\n",
      "-------------------------\n",
      "\n",
      "\n",
      "Agent Response:\n",
      "\n",
      "Here's a validated code example that demonstrates how to perform a hybrid search for AI research papers using Vectara's API. This example integrates both vector search and keyword search to ensure comprehensive retrieval from a corpus.\n",
      "\n",
      "### Prerequisites\n",
      "- **Authentication Details**: You'll need your `customer_id`, `corpus_id`, `auth_key`, and API endpoint configured.\n",
      "- **Set Up Your Environment**: Ensure your AI research papers are indexed within a Vectara corpus.\n",
      "\n",
      "### Python Snippet for Hybrid Search\n",
      "```python\n",
      "import requests\n",
      "import json\n",
      "\n",
      "# Define essential authentication and API endpoint details\n",
      "customer_id = 'your_customer_id'\n",
      "corpus_id = 'your_corpus_id'\n",
      "auth_key = 'your_auth_key'\n",
      "api_endpoint = 'https://api.vectara.io/v2/search'\n",
      "\n",
      "# Set up headers for the request\n",
      "headers = {\n",
      "    'Authorization': f'Bearer {auth_key}',\n",
      "    'Content-Type': 'application/json'\n",
      "}\n",
      "\n",
      "# Define the hybrid query payload\n",
      "query_payload = {\n",
      "    \"query\": \"AI research papers\",\n",
      "    \"corpus\": [{\"corpus_id\": corpus_id}],\n",
      "    \"hybrid_weight\": {\n",
      "        \"vector_weight\": 0.7,\n",
      "        \"keyword_weight\": 0.3\n",
      "    }\n",
      "}\n",
      "\n",
      "# Send the hybrid search query request\n",
      "response = requests.post(\n",
      "    api_endpoint,\n",
      "    headers=headers,\n",
      "    data=json.dumps(query_payload)\n",
      ")\n",
      "\n",
      "# Process the response\n",
      "if response.status_code == 200:\n",
      "    search_results = response.json()\n",
      "    print(\"Search Results:\", json.dumps(search_results, indent=2))\n",
      "else:\n",
      "    print(\"Error:\", response.status_code, response.text)\n",
      "```\n",
      "\n",
      "### Key Configurations\n",
      "- **Hybrid Weighting**: Adjust `vector_weight` and `keyword_weight` to balance between semantic and keyword relevance. This example uses `0.7` for semantic emphasis.\n",
      "- **API Access**: Ensure proper authorization by using your specific `auth_key` in the headers.\n",
      "\n",
      "### Best Practices\n",
      "- **Weight Tuning**: Experiment with different weights to optimize precision and recall based on your specific content and retrieval needs.\n",
      "- **Performance Testing**: Validate with diverse queries to establish the best settings for your use case.\n",
      "\n",
      "This implementation will allow you to effectively conduct a hybrid search in your AI research corpus, utilizing the strength of both semantic and keyword-based approaches. For more detailed guidelines, refer to the [Vectara Documentation](https://docs.vectara.com/docs/).\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me working code to search a corpus for AI research papers using hybrid search with Vectara's API.\"\n",
    "print(f\"User: {query}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "response = chat_with_agent(\n",
    "    orchestrator_key,\n",
    "    orchestrator_session_key,\n",
    "    query,\n",
    "    show_events=True\n",
    ")\n",
    "\n",
    "print(f\"Agent Response:\\n\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wr04o4ujvoh",
   "metadata": {},
   "source": [
    "### Test 3: Current Information Question (Web Search)\n",
    "\n",
    "This question asks about recent developments that wouldn't be in our indexed research papers or documentation, demonstrating the value of the web search sub-agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7elqfu25p1k",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What are the latest developments in RAG technology in 2025? Are there any new techniques or frameworks that have emerged recently?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "------ Agent Events ------\n",
      "Event: input_message\n",
      "Event: tool_input\n",
      "  Tool: web_search_expert\n",
      "  Input: Search for the latest developments in Retrieval-Augmented Generation (RAG) technology in 2025. Focus on any new techniques, frameworks, or significant advancements that have been introduced recently. Include information on both academic and industry developments....\n",
      "Event: tool_output\n",
      "  Tool: web_search_expert\n",
      "  Response (200 chars): In 2025, Retrieval-Augmented Generation (RAG) technology continues to evolve, with exciting advancements and new techniques emerging in both academia and industry. Here are the key developments:\n",
      "\n",
      "1. *...\n",
      "Event: agent_output\n",
      "-------------------------\n",
      "\n",
      "\n",
      "Agent Response:\n",
      "\n",
      "In 2025, Retrieval-Augmented Generation (RAG) technology has continued its rapid evolution with several significant advancements that enhance how AI integrates real-time data and reasoning capabilities. Here are the key developments:\n",
      "\n",
      "1. **Reasoning, Memory, and Advanced Search Integration**: Recent efforts have focused on boosting RAG systems' reasoning capabilities and memory retention, alongside incorporating advanced search functionalities. These improvements enhance the models' performance in generating more precise and contextually aware outputs by leveraging diverse external information sources. This trend highlights the emphasis on augmenting RAG's ability to utilize real-time data to provide contextually relevant responses [RAG at the Crossroads](https://ragflow.io/blog/rag-at-the-crossroads-mid-2025-reflections-on-ai-evolution).\n",
      "\n",
      "2. **Market Growth and Enterprise Integration**: The RAG technology market is on track to surpass $40 billion by 2035, driven by increased enterprise adoption of AI. This trajectory underscores the growing dependence on RAG frameworks to support various industrial applications such as customer service, content generation, and data analysis, pointing to RAG's crucial role in AI innovation [BusinessWire](https://www.businesswire.com/news/home/20251010008494/en/Retrieval-Augmented-Generation-RAG-Industry-Report-2025-2035-Global-RAG-Market-to-Surpass-%2440-Billion-by-2035-as-Enterprises-Accelerate-AI-Integration---ResearchAndMarkets.com).\n",
      "\n",
      "3. **Enhanced RAG Pipelines**: Core developments in RAG methodology involve creating smarter search layers for large language models. These layers enable more dynamic document retrieval and contextual conditioning, which enhances the model's text generation capabilities. New RAG pipeline architectures are integrating these improvements, offering more sophisticated and efficient AI solutions for diverse applications [DextraLabs](https://dextralabs.com/blog/rag-pipeline-explained-diagram-implementation/).\n",
      "\n",
      "4. **Increased Industry and Academic Interest**: Both industry leaders and academic researchers are actively working on refining RAG techniques. These efforts aim to make RAG more robust and scalable, allowing seamless integration into various sectors and applications and expanding the technology's versatility and utility [Glean Blog](https://www.glean.com/blog/rag-retrieval-augmented-generation).\n",
      "\n",
      "Overall, RAG technology in 2025 is characterized by a focus on making AI systems more intelligent and adaptive through improved real-time data integration and advanced computational strategies. These advancements are enhancing the precision and context-awareness of AI systems across multiple industries.\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the latest developments in RAG technology in 2025? Are there any new techniques or frameworks that have emerged recently?\"\n",
    "print(f\"User: {query}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "response = chat_with_agent(\n",
    "    orchestrator_key,\n",
    "    orchestrator_session_key,\n",
    "    query,\n",
    "    show_events=True\n",
    ")\n",
    "\n",
    "print(f\"Agent Response:\\n\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "If you want to delete the agents created in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted agent: agt_ai_research_orchestrator_ccf0\n",
      "Deleted agent: agt_research_paper_analyst_fbd0\n",
      "Deleted agent: agt_documentation_expert_4a1e\n",
      "Deleted agent: agt_web_search_expert_2470\n",
      "Deleted tool: tol_2223\n"
     ]
    }
   ],
   "source": [
    "# Delete agents\n",
    "agents_to_delete = [\n",
    "    orchestrator_key,\n",
    "    research_analyst_key,\n",
    "    docs_expert_key,\n",
    "    web_search_expert_key\n",
    "]\n",
    "\n",
    "for agent_key in agents_to_delete:\n",
    "    if agent_key:\n",
    "        response = requests.delete(f\"{BASE_URL}/agents/{agent_key}\", headers=headers)\n",
    "        if response.status_code == 204:\n",
    "            print(f\"Deleted agent: {agent_key}\")\n",
    "        else:\n",
    "            print(f\"Error deleting {agent_key}: {response.text}\")\n",
    "\n",
    "# Delete the lambda tool\n",
    "if api_validator_id:\n",
    "    response = requests.delete(f\"{BASE_URL}/tools/{api_validator_id}\", headers=headers)\n",
    "    if response.status_code == 204:\n",
    "        print(f\"Deleted tool: {api_validator_id}\")\n",
    "    else:\n",
    "        print(f\"Error deleting tool: {response.text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
