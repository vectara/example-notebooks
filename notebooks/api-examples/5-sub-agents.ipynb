{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/vectara/example-notebooks/blob/main/notebooks/api-examples/5-sub-agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "# Vectara Sub-Agents: Building Modular AI Workflows\n",
    "\n",
    "This notebook demonstrates how to use Vectara's **sub-agents** capability to build modular, specialized AI workflows. Sub-agents allow a parent agent to delegate tasks to specialized child agents, enabling:\n",
    "\n",
    "- **Context isolation**: Each sub-agent maintains its own conversation history\n",
    "- **Specialized configuration**: Each sub-agent can have distinct instructions and tools\n",
    "- **Reusability**: Build once, invoke from any parent agent\n",
    "- **Parallel execution**: Run multiple sub-agents simultaneously\n",
    "- **Better performance**: Smaller, focused agents make fewer mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## About Vectara\n",
    "\n",
    "[Vectara](https://vectara.com/) is the Agent Operating System for trusted enterprise AI: a unified Agentic RAG platform with built-in multi-modal retrieval, orchestration, and always-on governance. Deploy it on-prem (air-gapped), in your VPC, or as SaaS.\n",
    "\n",
    "Vectara provides a complete API-first platform for building production RAG and agentic applications:\n",
    "\n",
    "- **Simple Integration**: RESTful APIs and SDKs (Python, JavaScript) for quick integration into any stack\n",
    "- **Flexible Deployment**: Choose SaaS, VPC, or on-premises deployment based on your security requirements\n",
    "- **Multi-Modal Support**: Index and search across text, tables, and images from PDFs, documents, and structured data\n",
    "- **Advanced Retrieval**: Hybrid search combining semantic and keyword matching with state-of-the-art reranking\n",
    "- **Grounded Generation**: LLM responses with citations and factual consistency scores to reduce hallucinations\n",
    "- **Enterprise-Ready**: Built-in access controls, audit logging, and compliance (SOC2, HIPAA) from day one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "This notebook assumes you've completed Notebooks 1-4:\n",
    "- Notebook 1: Created two corpora (ai-research-papers and vectara-docs)\n",
    "- Notebook 2: Ingested AI research papers and Vectara documentation\n",
    "- Notebook 3: Queried the data with various techniques\n",
    "- Notebook 4: Created agents that can search and reason across data\n",
    "\n",
    "Now we'll create a multi-agent system where specialized sub-agents handle domain-specific tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Why Sub-Agents?\n",
    "\n",
    "When agents face complex, multi-step tasks, they often run into context window limits or need specialized capabilities. Consider a comprehensive research assistant that needs to:\n",
    "\n",
    "1. Analyze academic papers for theoretical foundations\n",
    "2. Search product documentation for implementation details\n",
    "3. Synthesize findings into actionable recommendations\n",
    "\n",
    "A single monolithic agent trying to handle all of this might:\n",
    "- Become confused between different instruction sets\n",
    "- Consume excessive context with domain-specific guidelines\n",
    "- Produce lower quality results due to competing priorities\n",
    "\n",
    "**Sub-agents solve this by delegation**: the parent agent orchestrates, while specialized sub-agents focus on their domains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Corpus: tutorial-ai-research-papers\n",
      "Docs Corpus: tutorial-vectara-docs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Get credentials from environment variables\n",
    "api_key = os.environ['VECTARA_API_KEY']\n",
    "\n",
    "# Corpus keys from previous notebooks\n",
    "research_corpus_key = 'tutorial-ai-research-papers'\n",
    "docs_corpus_key = 'tutorial-vectara-docs'\n",
    "\n",
    "# Base API URL\n",
    "BASE_URL = \"https://api.vectara.io/v2\"\n",
    "\n",
    "# Common headers\n",
    "headers = {\n",
    "    \"x-api-key\": api_key,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "print(f\"Research Corpus: {research_corpus_key}\")\n",
    "print(f\"Docs Corpus: {docs_corpus_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 1: Create Specialized Sub-Agents\n",
    "\n",
    "We'll create three specialized agents that will serve as sub-agents:\n",
    "\n",
    "1. **Research Paper Analyst**: Expert at analyzing academic papers on RAG, embeddings, and retrieval\n",
    "2. **Documentation Expert**: Expert at finding implementation guidance from Vectara docs\n",
    "3. **Web Search Expert**: Expert at searching the web for current information and news\n",
    "\n",
    "Each agent has focused instructions and tools optimized for its domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### Sub-Agent 1: Research Paper Analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to delete and create agent\n",
    "def delete_and_create_agent(agent_config, agent_name):\n",
    "    \"\"\"Delete agent if it exists, then create a new one.\"\"\"\n",
    "    # Check if agent already exists and delete it\n",
    "    list_response = requests.get(f\"{BASE_URL}/agents\", headers=headers)\n",
    "\n",
    "    if list_response.status_code == 200:\n",
    "        agents = list_response.json().get('agents', [])\n",
    "        for agent in agents:\n",
    "            if agent.get('name') == agent_name:\n",
    "                existing_key = agent['key']\n",
    "                print(f\"Deleting existing agent '{agent_name}' ({existing_key})\")\n",
    "                delete_response = requests.delete(f\"{BASE_URL}/agents/{existing_key}\", headers=headers)\n",
    "                if delete_response.status_code == 204:\n",
    "                    print(f\"Deleted agent: {existing_key}\")\n",
    "                else:\n",
    "                    print(f\"Error deleting {existing_key}: {delete_response.text}\")\n",
    "                break\n",
    "\n",
    "    # Create new agent\n",
    "    response = requests.post(f\"{BASE_URL}/agents\", headers=headers, json=agent_config)\n",
    "\n",
    "    if response.status_code == 201:\n",
    "        agent_data = response.json()\n",
    "        print(f\"Created agent '{agent_name}'\")\n",
    "        print(f\"Agent Key: {agent_data['key']}\")\n",
    "        return agent_data['key']\n",
    "    else:\n",
    "        print(f\"Error creating agent: {response.status_code}\")\n",
    "        print(f\"{response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent 'Research Paper Analyst'\n",
      "Agent Key: agt_research_paper_analyst_c526\n"
     ]
    }
   ],
   "source": [
    "# Create Research Paper Analyst sub-agent\n",
    "reranker_config = {\n",
    "    \"type\": \"chain\",\n",
    "    \"rerankers\": [\n",
    "        {\n",
    "            \"type\": \"customer_reranker\",\n",
    "            \"reranker_id\": \"rnk_272725719\", \n",
    "            \"limit\": 25,\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"mmr\",\n",
    "            \"diversity_bias\": 0.05\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "generation_config = {\n",
    "    \"generation_preset_name\": \"vectara-summary-table-md-query-ext-jan-2025-gpt-4o\",\n",
    "    \"max_used_search_results\": 10,\n",
    "    \"model_parameters\": {\n",
    "        \"llm_name\": \"gpt-4o\",\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "}\n",
    "\n",
    "research_analyst_config = {\n",
    "    \"name\": \"Research Paper Analyst\",\n",
    "    \"description\": \"Specialized agent for analyzing academic research papers on RAG, embeddings, and retrieval techniques\",\n",
    "    \"model\": {\"name\": \"gpt-4o\"},\n",
    "    \"first_step\": {\n",
    "        \"type\": \"conversational\",\n",
    "        \"instructions\": [\n",
    "            {\n",
    "                \"type\": \"inline\",\n",
    "                \"name\": \"research_analyst_instructions\",\n",
    "                \"template\": \"\"\"You are an expert academic research analyst specializing in AI, machine learning, and natural language processing.\n",
    "\n",
    "Your expertise includes:\n",
    "- Retrieval Augmented Generation (RAG) architectures\n",
    "- Dense and sparse retrieval methods\n",
    "- Embedding models and vector representations\n",
    "- Transformer architectures and attention mechanisms\n",
    "- Information retrieval benchmarks and evaluation metrics\n",
    "\n",
    "When analyzing research papers:\n",
    "1. Identify the key contributions and novel techniques\n",
    "2. Explain technical concepts clearly with examples\n",
    "3. Highlight practical implications and limitations\n",
    "4. Compare with related work when relevant\n",
    "5. Provide citations to the source papers\n",
    "\n",
    "Always use tools to retrieve relevant content to answer user queries.\n",
    "Always ground your response in the retrieved content. \n",
    "If you cannot answer the user question from the retrieved content from tools, just say \"I don't know\"\n",
    "\n",
    "IMPORTANT: When responding, provide a complete, self-contained summary that includes all relevant findings.\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        \"output_parser\": {\"type\": \"default\"}\n",
    "    },\n",
    "    \"tool_configurations\": {\n",
    "        \"research_search\": {\n",
    "            \"type\": \"corpora_search\",\n",
    "            \"query_configuration\": {\n",
    "                \"search\": {\n",
    "                    \"corpora\": [{\"corpus_key\": research_corpus_key}],\n",
    "                    \"limit\": 100,\n",
    "                    \"context_configuration\": {\n",
    "                        \"sentences_before\": 2,\n",
    "                        \"sentences_after\": 2\n",
    "                    },\n",
    "                    \"reranker\": reranker_config,                   \n",
    "                },\n",
    "#                \"generation\": generation_config,\n",
    "                \"save_history\": True,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "research_analyst_key = delete_and_create_agent(research_analyst_config, \"Research Paper Analyst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "### Sub-Agent 2: Documentation Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent 'Documentation Expert'\n",
      "Agent Key: agt_documentation_expert_f9f7\n"
     ]
    }
   ],
   "source": [
    "# Create Documentation Expert sub-agent\n",
    "\n",
    "docs_expert_config = {\n",
    "    \"name\": \"Documentation Expert\",\n",
    "    \"description\": \"Specialized agent for finding implementation guidance and best practices from Vectara documentation\",\n",
    "    \"model\": {\"name\": \"gpt-4o\"},\n",
    "    \"first_step\": {\n",
    "        \"type\": \"conversational\",\n",
    "        \"instructions\": [\n",
    "            {\n",
    "                \"type\": \"inline\",\n",
    "                \"name\": \"docs_expert_instructions\",\n",
    "                \"template\": \"\"\"You are a Vectara platform expert who helps developers implement AI solutions.\n",
    "\n",
    "Your expertise includes:\n",
    "- Vectara API integration (indexing, querying, agents)\n",
    "- Corpus management and configuration\n",
    "- Search optimization (hybrid search, reranking, filters)\n",
    "- RAG implementation best practices\n",
    "- SDK usage and code examples\n",
    "\n",
    "When providing guidance:\n",
    "1. Give specific, actionable implementation steps using the API.\n",
    "2. Include relevant API endpoints and parameters\n",
    "3. Your examples should show how to use the API, not using Vectara SDK.\n",
    "4. Highlight configuration options and trade-offs\n",
    "5. Point to relevant documentation sections\n",
    "\n",
    "Always use tools to retrieve relevant content to answer user queries.\n",
    "Always ground your response in the retrieved content. \n",
    "If you cannot answer the user question from the retrieved content from tools, just say \"I don't know\"\n",
    "\n",
    "When responding, provide a complete, self-contained answer with all implementation details.\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        \"output_parser\": {\"type\": \"default\"}\n",
    "    },\n",
    "    \"tool_configurations\": {\n",
    "        \"docs_search\": {\n",
    "            \"type\": \"corpora_search\",\n",
    "            \"query_configuration\": {\n",
    "                \"search\": {\n",
    "                    \"corpora\": [{\"corpus_key\": docs_corpus_key}],\n",
    "                    \"limit\": 100,\n",
    "                    \"context_configuration\": {\n",
    "                        \"sentences_before\": 2,\n",
    "                        \"sentences_after\": 2\n",
    "                    },\n",
    "                    \"reranker\": reranker_config,                   \n",
    "                },\n",
    "#                \"generation\": generation_config,\n",
    "                \"save_history\": True,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "docs_expert_key = delete_and_create_agent(docs_expert_config, \"Documentation Expert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ir8dahqid7b",
   "metadata": {},
   "source": [
    "### Sub-Agent 3: Web Search Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8j6idifi4m3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent 'Web Search Expert'\n",
      "Agent Key: agt_web_search_expert_5b19\n"
     ]
    }
   ],
   "source": [
    "# Create Web Search Expert sub-agent\n",
    "\n",
    "web_search_expert_config = {\n",
    "    \"name\": \"Web Search Expert\",\n",
    "    \"description\": \"Specialized agent for searching the web for current information, news, and general knowledge\",\n",
    "    \"model\": {\"name\": \"gpt-4o\"},\n",
    "    \"first_step\": {\n",
    "        \"type\": \"conversational\",\n",
    "        \"instructions\": [\n",
    "            {\n",
    "                \"type\": \"inline\",\n",
    "                \"name\": \"web_search_expert_instructions\",\n",
    "                \"template\": \"\"\"You are a web search expert who helps find current and relevant information from the internet.\n",
    "\n",
    "Your expertise includes:\n",
    "- Finding up-to-date information on any topic\n",
    "- Researching current events and news\n",
    "- Locating authoritative sources and references\n",
    "- Comparing information across multiple sources\n",
    "- Fact-checking and verification\n",
    "\n",
    "When searching and responding:\n",
    "1. Use web search to find relevant, current information\n",
    "2. Prioritize authoritative and credible sources\n",
    "3. Provide context about when information was published\n",
    "4. Cite your sources with URLs when available\n",
    "5. Synthesize information from multiple sources when appropriate\n",
    "\n",
    "Always use the web search tool to find information.\n",
    "If you cannot find relevant information, say so clearly.\n",
    "\n",
    "IMPORTANT: When responding, provide a complete, well-sourced answer with citations.\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        \"output_parser\": {\"type\": \"default\"}\n",
    "    },\n",
    "    \"tool_configurations\": {\n",
    "        \"web_search\": {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "web_search_expert_key = delete_and_create_agent(web_search_expert_config, \"Web Search Expert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 2: Create the Parent Orchestrator Agent\n",
    "\n",
    "Now we'll create a parent agent that can delegate to both sub-agents. The parent agent:\n",
    "- Analyzes user requests to determine which sub-agent(s) to invoke\n",
    "- Delegates domain-specific tasks to the appropriate sub-agent\n",
    "- Synthesizes responses from multiple sub-agents into a cohesive answer\n",
    "\n",
    "### Sub-Agent Tool Configuration\n",
    "\n",
    "Sub-agents are configured as tools using the `sub_agent` type:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"type\": \"sub_agent\",\n",
    "  \"description_template\": \"Description the LLM sees when deciding to use this tool\",\n",
    "  \"sub_agent_configuration\": {\n",
    "    \"agent_key\": \"the_sub_agent_key\",\n",
    "    \"session_mode\": \"llm_controlled\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### Session Modes\n",
    "\n",
    "When specifying in the parent agent how sub-agents are to be used, you need to define the \"session mode\":\n",
    "- **`llm_controlled`** (default): The LLM decides whether to resume an existing session or create a new one\n",
    "- **`persistent`**: Always reuse the same session, accumulating knowledge across invocations\n",
    "- **`ephemeral`**: Create a fresh session every time, ensuring no state leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent 'AI Research Orchestrator'\n",
      "Agent Key: agt_ai_research_orchestrator_522e\n"
     ]
    }
   ],
   "source": [
    "# Create the Orchestrator Agent with sub-agent tools\n",
    "orchestrator_config = {\n",
    "    \"name\": \"AI Research Orchestrator\",\n",
    "    \"description\": \"Orchestrator agent that delegates to specialized sub-agents for comprehensive AI research assistance\",\n",
    "    \"model\": {\"name\": \"gpt-4o\"},\n",
    "    \"first_step\": {\n",
    "        \"type\": \"conversational\",\n",
    "        \"instructions\": [\n",
    "            {\n",
    "                \"type\": \"inline\",\n",
    "                \"name\": \"orchestrator_instructions\",\n",
    "                \"template\": \"\"\"You are an AI research orchestrator that helps users understand and implement AI technologies.\n",
    "\n",
    "Your role is to:\n",
    "1. Analyze the user's question to determine what expertise is needed.\n",
    "2. Use appropriate sub-agent(s) to get information needed to answer the user query.\n",
    "3. Synthesize sub-agent responses into a comprehensive answer.\n",
    "4. Bridge theory and practice when both are relevant.\n",
    "\n",
    "When synthesizing, clearly indicate which insights come from research, documentation, or web search.\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        \"output_parser\": {\"type\": \"default\"}\n",
    "    },\n",
    "    \"tool_configurations\": {\n",
    "        \"research_analyst\": {\n",
    "            \"type\": \"sub_agent\",\n",
    "            \"description_template\": \"Delegate academic research analysis tasks to a specialized research paper analyst. Use for: theoretical foundations, algorithm explanations, research paper analysis, academic citations, and comparisons between research approaches.\",\n",
    "            \"sub_agent_configuration\": {\n",
    "                \"agent_key\": research_analyst_key,\n",
    "                \"session_mode\": \"ephemeral\"       # Fresh context for each analysis\n",
    "            }\n",
    "        },\n",
    "        \"docs_expert\": {\n",
    "            \"type\": \"sub_agent\",\n",
    "            \"description_template\": \"Delegate implementation and documentation questions to a Vectara documentation expert. Use for: API usage, code examples, configuration guidance, best practices, and troubleshooting.\",\n",
    "            \"sub_agent_configuration\": {\n",
    "                \"agent_key\": docs_expert_key,\n",
    "                \"session_mode\": \"ephemeral\"\n",
    "            }\n",
    "        },\n",
    "        \"web_search_expert\": {\n",
    "            \"type\": \"sub_agent\",\n",
    "            \"description_template\": \"Delegate web search tasks to find current information, news, and general knowledge from the internet. Use for: recent developments, current events, fact-checking, finding authoritative sources, and information not available in research papers or documentation.\",\n",
    "            \"sub_agent_configuration\": {\n",
    "                \"agent_key\": web_search_expert_key,\n",
    "                \"session_mode\": \"ephemeral\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "orchestrator_key = delete_and_create_agent(orchestrator_config, \"AI Research Orchestrator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Step 3: Test the Multi-Agent Workflow\n",
    "\n",
    "Now let's test the orchestrator with different types of questions to see how it delegates to sub-agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to send messages and display responses\n",
    "def chat_with_agent(agent_key, session_key, message, show_events=False):\n",
    "    \"\"\"Send a message to an agent and return the response.\"\"\"\n",
    "    message_data = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"content\": message\n",
    "            }\n",
    "        ],\n",
    "        \"stream_response\": False\n",
    "    }\n",
    "    \n",
    "    url = f\"{BASE_URL}/agents/{agent_key}/sessions/{session_key}/events\"\n",
    "    response = requests.post(url, headers=headers, json=message_data)\n",
    "    \n",
    "    if response.status_code == 201:\n",
    "        event_data = response.json()\n",
    "        \n",
    "        if show_events:\n",
    "            print(\"\\n------ All Events ------\")\n",
    "            for event in event_data.get('events', []):\n",
    "                event_type = event.get('type', 'INVALID')\n",
    "                print(f\"  Event type: {event_type}\")\n",
    "                if event_type == 'tool_input':\n",
    "                    print(f\"    Tool: {event.get('tool_configuration_name', 'N/A')}\")\n",
    "                    if event.get(\"tool_input\", None):\n",
    "                        print(f\"    Tool input: {event[\"tool_input\"][\"message\"]}\")\n",
    "                if event_type == 'tool_output':\n",
    "                    print(f\"    Tool: {event.get('tool_configuration_name', 'N/A')}\")\n",
    "                    if event.get(\"tool_output\", None):\n",
    "                        print(f\"    Tool output: {event[\"tool_output\"][\"sub_agent_response\"]}...\")\n",
    "            print(\"-\"*20)\n",
    "        \n",
    "        # Extract agent output\n",
    "        for event in event_data.get('events', []):\n",
    "            if event.get('type') == 'agent_output':\n",
    "                return event.get('content', 'No content')\n",
    "        \n",
    "        return \"No agent output found\"\n",
    "    else:\n",
    "        return f\"Error: {response.status_code} - {response.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session Created: ase_orchestrator_session_20251203-225154_0c84\n"
     ]
    }
   ],
   "source": [
    "# Create a session for the orchestrator\n",
    "session_name = f\"Orchestrator Session {datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "session_config = {\n",
    "    \"name\": session_name,\n",
    "    \"metadata\": {\n",
    "        \"purpose\": \"sub_agent_demo\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{BASE_URL}/agents/{orchestrator_key}/sessions\",\n",
    "    headers=headers,\n",
    "    json=session_config\n",
    ")\n",
    "\n",
    "if response.status_code == 201:\n",
    "    session_data = response.json()\n",
    "    orchestrator_session_key = session_data[\"key\"]\n",
    "    print(f\"Session Created: {orchestrator_session_key}\")\n",
    "else:\n",
    "    print(f\"Error: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "### Test 1: Research-Focused Question\n",
    "\n",
    "This question should primarily use the research_analyst sub-agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What are the key innovations in the original RAG paper?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "------ All Events ------\n",
      "  Event type: input_message\n",
      "  Event type: tool_input\n",
      "    Tool: research_analyst\n",
      "    Tool input: Provide a detailed summary of the key innovations introduced in the original Retrieval-Augmented Generation (RAG) paper. Identify the novel aspects of the RAG architecture, any significant improvements it brings over existing methods, and its impact on text generation and information retrieval tasks.\n",
      "  Event type: tool_output\n",
      "    Tool: research_analyst\n",
      "    Tool output: The \"Retrieval-Augmented Generation\" (RAG) model, introduced by Lewis et al. in 2020, presents a novel architecture that combines the flexibility of pre-trained seq2seq parametric models with the ability to augment outputs with non-parametric memory through retrieval from external data sources like Wikipedia. Here are the key innovations and contributions of the RAG architecture:\n",
      "\n",
      "1. **Hybrid Memory System**: RAG incorporates both parametric and non-parametric memory, where the parametric component is a seq2seq model (e.g., BART) that is fine-tuned for various tasks, and the non-parametric component is an indexed set of dense vector representations of a large document corpus created using a dense passage retriever (DPR) [Lewis et al., 2020].\n",
      "\n",
      "2. **End-to-End Training**: The architecture allows for joint end-to-end training of both the retrieval and generation components. This integration ensures that the system is simultaneously optimizing for retrieving the most relevant documents and generating coherent text [Lewis et al., 2020].\n",
      "\n",
      "3. **Novel Probabilistic Model**: RAG uses a probabilistic model where retrieval is treated as part of the generative process. This involves marginalizing over the latent retrieved documents to compute the final probability distribution over the generated output [Lewis et al., 2020].\n",
      "\n",
      "4. **Multiple Retrieval Strategies**: The model supports different retrieval strategies, including using the same set of passages for the entire generated sequence or allowing different passages per token. This flexibility enables the generation of more diverse and contextually appropriate responses [Lewis et al., 2020].\n",
      "\n",
      "5. **Performance Improvements**: Compared to other approaches like REALM or T5+SSM, RAG achieves strong performance without requiring complex pre-training like salient span masking. RAG demonstrates comparable or superior results to systems using complex re-ranking and extractive reader setups [Lewis et al., 2020].\n",
      "\n",
      "6. **Diverse Applications**: The model significantly improves performance on a variety of knowledge-intensive NLP tasks, such as open-domain question answering (QA), where it handles multiple benchmarks including Natural Questions, TriviaQA, and WebQuestions more effectively than previous models [Lewis et al., 2020].\n",
      "\n",
      "The practical implications of RAG are profound, as it shows that retrieval-based augmentation of generation models is a promising direction for enhancing model outputs with real-time, updated information. This not only improves factual accuracy but also reduces the burden of updating model parameters frequently.\n",
      "\n",
      "However, limitations remain, particularly concerning the computational overhead involved in retrieval and the potential for irrelevant document fetching, which can sometimes distract and degrade the quality of the generated answers. Additionally, ensuring that the retrieved documents align with the generative context remains a complex challenge.\n",
      "\n",
      "**Citation**: Lewis, P., Perez, E., & Kiela, D. et. al., (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. Advances in Neural Information Processing Systems, 33: 9459–9474....\n",
      "  Event type: agent_output\n",
      "--------------------\n",
      "Agent Response:\n",
      "The original Retrieval-Augmented Generation (RAG) paper by Lewis et al. introduced several key innovations that significantly advanced the capabilities of language models, especially in knowledge-intensive NLP tasks. Here are the main contributions:\n",
      "\n",
      "1. **Hybrid Memory System**: RAG combines parametric and non-parametric memory, utilizing a seq2seq model (like BART) with an indexed set of dense vector representations of a large document corpus. This integration allows the model to draw on both pre-trained model knowledge and external information.\n",
      "\n",
      "2. **End-to-End Training**: The architecture allows for joint end-to-end training of both retrieval and generation components. This ensures that the system is optimized to retrieve relevant documents and generate coherent text simultaneously.\n",
      "\n",
      "3. **Novel Probabilistic Model**: RAG uses a probabilistic generative approach that incorporates document retrieval as part of the text generation process, by marginalizing over the latent retrievals for the final probability distribution of the output.\n",
      "\n",
      "4. **Flexible Retrieval Strategies**: RAG supports various retrieval strategies, such as using the same set of passages for a sequence or allowing different passages per token. This flexibility contributes to generating diverse and contextually appropriate responses.\n",
      "\n",
      "5. **Performance Improvements**: RAG demonstrated strong performance without the need for complex pre-training methods, surpassing or matching systems with more elaborate pre-training or inference setups like REALM or T5+SSM.\n",
      "\n",
      "6. **Applicability to Diverse Tasks**: The model improves performance on a range of knowledge-intensive tasks, particularly outperforming previous models in open-domain question answering across multiple benchmarks like Natural Questions, TriviaQA, and WebQuestions.\n",
      "\n",
      "The innovations introduced by RAG provide a powerful framework for integrating retrieval into generative models, enhancing their factual accuracy and ease of updating information without frequent parameter adjustments. However, challenges such as computational overhead and the risk of irrelevant retrievals remain areas for further research and optimization.\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the key innovations in the original RAG paper?\"\n",
    "print(f\"User: {query}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "response = chat_with_agent(\n",
    "    orchestrator_key,\n",
    "    orchestrator_session_key,\n",
    "    query,\n",
    "    show_events=True\n",
    ")\n",
    "\n",
    "print(f\"Agent Response:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "### Test 2: Implementation-Focused Question\n",
    "\n",
    "This question should primarily use the docs_expert sub-agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: How do I configure hybrid search with Vectara's API?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "------ All Events ------\n",
      "  Event type: input_message\n",
      "  Event type: tool_input\n",
      "    Tool: docs_expert\n",
      "    Tool input: Provide step-by-step guidance on configuring hybrid search using Vectara's API. Include any necessary API endpoints, parameters, and best practices for setting up a successful hybrid search configuration.\n",
      "  Event type: tool_output\n",
      "    Tool: docs_expert\n",
      "    Tool output: To configure hybrid search using Vectara's API, you'll need to integrate both semantic and lexical search components to enhance search results based on both keyword matching and semantic understanding. Here's a step-by-step guide to setting it up:\n",
      "\n",
      "### Step 1: Indexing Your Content\n",
      "1. **Index Documents:**\n",
      "   - Use the [Indexing API](https://docs.vectara.com/docs/api-reference/indexing-apis/indexing) to add documents to your corpus. This process transforms your data into a format that enables efficient search and retrieval.\n",
      "   - Example Request:\n",
      "     ```http\n",
      "     POST https://api.vectara.io/v2/corpora/{corpus_key}/index\n",
      "     Headers:\n",
      "       Authorization: Bearer {your_api_key}\n",
      "       Content-Type: application/json\n",
      "     Body:\n",
      "     {\n",
      "       \"documents\": [\n",
      "         {\n",
      "           \"document_parts\": [\n",
      "             {\n",
      "               \"text\": \"Your document text here\",\n",
      "               \"metadata\": {\n",
      "                 \"key1\": \"value1\",\n",
      "                 \"key2\": \"value2\"\n",
      "               }\n",
      "             }\n",
      "           ]\n",
      "         }\n",
      "       ]\n",
      "     }\n",
      "     ```\n",
      "\n",
      "### Step 2: Configuring Hybrid Search\n",
      "2. **Search Setup:**\n",
      "   - Configure your search request to include both semantic and lexical components using the semantic-linguistic hybrid approach.\n",
      "   - In your search request, adjust the `lexical_interpolation` parameter to determine the mix of semantic and lexical search. A higher value increases reliance on lexical matching.\n",
      "\n",
      "3. **Search Request Example:**\n",
      "   - Example of setting up a search request using the Vectara API:\n",
      "     ```http\n",
      "     POST https://api.vectara.io/v2/query\n",
      "     Headers:\n",
      "       Authorization: Bearer {your_api_key}\n",
      "       Content-Type: application/json\n",
      "     Body:\n",
      "     {\n",
      "       \"query\": \"Your search query here\",\n",
      "       \"search\": {\n",
      "         \"corpora\": [\n",
      "           {\n",
      "             \"corpus_key\": \"your_corpus_key\",\n",
      "             \"lexical_interpolation\": 0.5\n",
      "           }\n",
      "         ],\n",
      "         \"limit\": 10\n",
      "       }\n",
      "     }\n",
      "     ```\n",
      "   - Here, the `lexical_interpolation` is set to `0.5`, balancing between semantic understanding and lexical matching.\n",
      "\n",
      "### Step 3: Fine-Tuning and Testing\n",
      "4. **Tuning the Hybrid Search:**\n",
      "   - Experiment with different values for `lexical_interpolation` to achieve the desired balance. Values closer to `1.0` are more lexical, while closer to `0.0` are more semantic.\n",
      "\n",
      "5. **Testing:**\n",
      "   - Test your configuration within the Vectara Console or your development environment to ensure that it meets the quality and relevance requirements.\n",
      "\n",
      "### Best Practices\n",
      "- **Metadata Filtering:** Utilize metadata for more precise filtering of search results. This can improve the relevancy of results by narrowing down the search scope.\n",
      "- **Security:** Protect your API key or OAuth tokens and ensure they have the right permissions for your corpora and operations.\n",
      "- **Monitor Performance:** Use query graphs and logs in the Vectara Console to monitor and optimize search performance.\n",
      "\n",
      "For more details, you can refer to Vectara's documentation on [API Quick Start](https://docs.vectara.com/docs/api-recipes) which includes various example requests and configurations....\n",
      "  Event type: agent_output\n",
      "--------------------\n",
      "Agent Response:\n",
      "To configure hybrid search using Vectara's API, you'll integrate both semantic and lexical search elements. Here’s a step-by-step guide:\n",
      "\n",
      "### Step 1: Indexing Your Content\n",
      "\n",
      "1. **Index Documents:**\n",
      "   - Use the [Indexing API](https://docs.vectara.com/docs/api-reference/indexing-apis/indexing) to add documents to your corpus, ensuring they're formatted for efficient search and retrieval.\n",
      "   - Example Request:\n",
      "     ```http\n",
      "     POST https://api.vectara.io/v2/corpora/{corpus_key}/index\n",
      "     Headers:\n",
      "       Authorization: Bearer {your_api_key}\n",
      "       Content-Type: application/json\n",
      "     Body:\n",
      "     {\n",
      "       \"documents\": [\n",
      "         {\n",
      "           \"document_parts\": [\n",
      "             {\n",
      "               \"text\": \"Your document text here\",\n",
      "               \"metadata\": {\n",
      "                 \"key1\": \"value1\",\n",
      "                 \"key2\": \"value2\"\n",
      "               }\n",
      "             }\n",
      "           ]\n",
      "         }\n",
      "       ]\n",
      "     }\n",
      "     ```\n",
      "\n",
      "### Step 2: Configuring Hybrid Search\n",
      "\n",
      "2. **Search Setup:**\n",
      "   - Configure your search request to include both semantic and lexical components, adjusting the `lexical_interpolation` parameter to balance between these modes.\n",
      "\n",
      "3. **Search Request Example:**\n",
      "   - Example Request:\n",
      "     ```http\n",
      "     POST https://api.vectara.io/v2/query\n",
      "     Headers:\n",
      "       Authorization: Bearer {your_api_key}\n",
      "       Content-Type: application/json\n",
      "     Body:\n",
      "     {\n",
      "       \"query\": \"Your search query here\",\n",
      "       \"search\": {\n",
      "         \"corpora\": [\n",
      "           {\n",
      "             \"corpus_key\": \"your_corpus_key\",\n",
      "             \"lexical_interpolation\": 0.5\n",
      "           }\n",
      "         ],\n",
      "         \"limit\": 10\n",
      "       }\n",
      "     }\n",
      "     ```\n",
      "   - The `lexical_interpolation` could be set to `0.5` for a balanced approach between semantic and lexical.\n",
      "\n",
      "### Step 3: Fine-Tuning and Testing\n",
      "\n",
      "4. **Tuning the Hybrid Search:**\n",
      "   - Experiment with `lexical_interpolation` values to achieve the desired balance (closer to 1.0 is more lexical; 0.0 is more semantic).\n",
      "\n",
      "5. **Testing:**\n",
      "   - Test in the Vectara Console or other environments to ensure result relevance and quality.\n",
      "\n",
      "### Best Practices\n",
      "\n",
      "- **Metadata Filtering:** Use metadata for precise filtering to enhance result relevance.\n",
      "- **Security:** Protect your API key and tokens, ensuring appropriate permissions.\n",
      "- **Monitor Performance:** Utilize query graphs and logs in Vectara Console to optimize search performance.\n",
      "\n",
      "Refer to Vectara's [API Quick Start](https://docs.vectara.com/docs/api-recipes) for more detailed examples and configurations.\n"
     ]
    }
   ],
   "source": [
    "query = \"How do I configure hybrid search with Vectara's API?\"\n",
    "print(f\"User: {query}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "response = chat_with_agent(\n",
    "    orchestrator_key,\n",
    "    orchestrator_session_key,\n",
    "    query,\n",
    "    show_events=True,\n",
    ")\n",
    "\n",
    "print(f\"Agent Response:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "### Test 3: Comprehensive Question (multiple sub-agents)\n",
    "\n",
    "This question should use both sub-agents and synthesize their responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Explain how dense retrieval works theoretically, and show me how to implement it with Vectara.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "------ All Events ------\n",
      "  Event type: input_message\n",
      "  Event type: tool_input\n",
      "    Tool: research_analyst\n",
      "    Tool input: Explain the theoretical foundation of dense retrieval in the context of information retrieval. Focus on how it differs from traditional sparse retrieval methods, the underlying algorithms such as dense vector representations, and their usage in neural networks for search tasks.\n",
      "  Event type: tool_input\n",
      "    Tool: docs_expert\n",
      "    Tool input: Provide a step-by-step guide on implementing dense retrieval using Vectara's API. Include details on setting up the API, necessary endpoints, configurations, and any best practices for achieving optimal performance.\n",
      "  Event type: tool_output\n",
      "    Tool: research_analyst\n",
      "    Tool output: Dense retrieval methods represent a significant advancement in information retrieval, contrasting traditional sparse retrieval approaches like BM25. Here's an exploration of the theoretical foundation of dense retrieval, its differences from sparse retrieval, the algorithms involved, and their application in neural networks:\n",
      "\n",
      "### Traditional Sparse Retrieval\n",
      "- **Sparse retrieval** typically relies on term-matching methods, such as TF-IDF or BM25. In these methods, documents and queries are represented as sparse vectors where the positions correspond to terms from the vocabulary.\n",
      "- **BM25**, for instance, uses the frequency of word overlap to score document relevance. Such methods are computationally efficient but can struggle when queries and documents use synonymous terminology without exact word matches.\n",
      "\n",
      "### Dense Retrieval\n",
      "- **Dense retrieval** converts documents and queries into dense vector representations using neural network models, often based on transformers like BERT.\n",
      "- **Dense Passage Retrieval (DPR)** is a common architecture where both queries and documents are mapped into continuous vector spaces. The primary idea is to train models to generate embeddings such that semantically similar documents and queries are close in this vector space.\n",
      "- Unlike sparse methods, dense retrieval excels at capturing semantic similarities beyond exact term overlap, making it particularly powerful in contexts where lexical match is insufficient.\n",
      "\n",
      "### Algorithms and Techniques\n",
      "- **Bi-encoder architecture**: In models like DPR, separate encoders generate embeddings for queries and documents. These are typically implemented using models like BERT. The retrieval task is formulated as a **Maximum Inner Product Search (MIPS)** problem where the most relevant documents for a given query have the closest embeddings.\n",
      "- **End-to-End Training**: Techniques like in *Retrieval-Augmented Generation (RAG)* involve training retrieval components along with generative models, often fine-tuning on specific tasks to improve performance (Lewis et al., 2020).\n",
      "\n",
      "### Neural Networks in Dense Retrieval\n",
      "- Dense vectors are computed through neural networks, utilizing dense layers and nonlinearities to enrich the embeddings.\n",
      "- These models can be trained to optimize retrieval performance using labeled datasets, where relevant documents are known for specific queries.\n",
      "\n",
      "### Practical Implications and Limitations\n",
      "- **Advantages**: Dense retrieval methods typically outperform sparse ones, especially in complex queries or in languages rich with synonyms and contextual phrases.\n",
      "- **Limitations**: Dense methods often require substantial computational resources for training and inference. They also necessitate large datasets for pre-training and fine-tuning to achieve superior performance.\n",
      "- **Collapse and Optimization**: Certain tasks might cause the learning process to collapse to non-informative retrieval due to task-specific characteristics leading to adjustments in retrieval strategies (Brown et al.).\n",
      "\n",
      "These dense retrieval strategies represent a paradigm shift, enabling more sophisticated, contextually aware search capabilities as they harness the power of neural network-based embeddings to go beyond superficial text matching....\n",
      "  Event type: tool_output\n",
      "    Tool: docs_expert\n",
      "    Tool output: Implementing dense retrieval using Vectara's API involves several key steps, including setting up the API, indexing documents, and querying for retrieval. Here's a detailed guide to get you started:\n",
      "\n",
      "### Step 1: Configure Your Vectara API\n",
      "1. **Create an API Key**: Go to the [Vectara Console](https://console.vectara.com) and navigate to the API key management section. Create a new API key for your application.\n",
      "2. **Set Up Authentication**: Use the API key for authentication in your requests. You can either use direct API key authentication or OAuth 2.0 for more secure or automated workflows. Ensure your API requests use Bearer Token authentication with the token being your API key.\n",
      "\n",
      "### Step 2: Index Your Documents\n",
      "1. **Prepare Your Data**: Organize your data into documents that Vectara's indexing API can accept. You can include metadata to enable advanced filtering and retrieval capabilities.\n",
      "2. **Use the Indexing API**: Use the following endpoint to index your documents:\n",
      "   ```\n",
      "   POST /v1/corpora/{corpusId}/docs\n",
      "   ```\n",
      "   Replace `{corpusId}` with your corpus key. This API call transforms and stores your documents, making them searchable.\n",
      "   - **Headers**: Include your Authentication header with the Bearer token.\n",
      "   - **Payload**: Your payload should consist of your documents in JSON format, potentially with metadata if necessary.\n",
      "\n",
      "### Step 3: Query for Dense Retrieval\n",
      "1. **Construct Your Query**: To perform a dense retrieval, use descriptive queries that Vectara can process to find semantically relevant documents.\n",
      "2. **Query API Endpoint**:\n",
      "   ```\n",
      "   POST /v1/corpora/{corpusId}/query\n",
      "   ```\n",
      "   - **Payload**: Include the `query` field with your search term. You can choose to use metadata filters to narrow down your search results.\n",
      "   - **Options and Parameters**: Consider adjusting parameters such as `limit` (to control the number of returned results) and `context_configuration` (to specify surrounding context for each result).\n",
      "   - **Headers**: Again, include your Authentication header with the Bearer token.\n",
      "\n",
      "### Best Practices for Optimal Performance\n",
      "- **Metadata Usage**: Tag your documents with metadata for more refined filtering during retrieval. This can greatly enhance the precision of your searches.\n",
      "- **Tuning Parameters**: Experiment with `lexical_interpolation` and other search parameters to strike the right balance between semantic understanding and lexical matching.\n",
      "- **Response Handling**: Manage your responses by configuring contextual output settings to get more meaningful search results.\n",
      "\n",
      "### Resources and Documentation\n",
      "- **API Reference**: Use Vectara's [interactive API Reference](https://docs.vectara.com/docs/api-reference/indexing-apis/indexing) to experiment with endpoints and understand possible configurations.\n",
      "- **Postman Collection**: Utilize Vectara's Postman Collection to test and simulate API requests in a code-free environment.\n",
      "\n",
      "By following the steps above, you can set up a robust dense retrieval system using Vectara's API to benefit from its advanced semantic search capabilities....\n",
      "  Event type: agent_output\n",
      "--------------------\n",
      "Agent Response:\n",
      "### Theoretical Foundation of Dense Retrieval\n",
      "\n",
      "Dense retrieval represents a transformation from traditional sparse retrieval methods, such as BM25, to approaches that utilize dense vector representations and neural networks for enhanced information retrieval.\n",
      "\n",
      "#### Traditional Sparse Retrieval\n",
      "- **Methods** like TF-IDF and BM25 rely on term-based matching, representing documents and queries as sparse vectors with dimensions equal to vocabulary terms.\n",
      "- **BM25** gauges relevance based on term frequency and word overlap, which limits its effectiveness with synonym-rich queries unless exact term matches occur.\n",
      "\n",
      "#### Dense Retrieval\n",
      "- **Dense retrieval** uses neural networks to transform documents and queries into dense vector representations, often employing transformer models like BERT.\n",
      "- With **Dense Passage Retrieval (DPR)**, both queries and documents are mapped into continuous vector spaces, ensuring semantically similar content is close in this space.\n",
      "- This method excels at identifying semantic relationships beyond simple term matching, addressing the limitations seen in sparse retrieval.\n",
      "\n",
      "#### Algorithms and Techniques\n",
      "- **Bi-encoder Architecture**: Queries and documents are encoded separately to generate dense embeddings, which are then used in **Maximum Inner Product Search (MIPS)** to find the most relevant matches.\n",
      "- **End-to-End Training**: Techniques such as Retrieval-Augmented Generation (RAG) involve jointly training retrieval and generative components for improved task performance.\n",
      "\n",
      "#### Practical Implications\n",
      "- **Advantages**: Superior in handling complex queries and languages with synonyms, improving semantic understanding.\n",
      "- **Considerations**: Computationally demanding, requiring large data sets and resources for training and inference, as well as careful tuning to avoid issues like non-informative retrieval collapses.\n",
      "\n",
      "### Implementing Dense Retrieval with Vectara\n",
      "\n",
      "To implement dense retrieval using Vectara's API, follow these steps:\n",
      "\n",
      "#### Step 1: Configure Your API\n",
      "- **Create an API Key**: Use the [Vectara Console](https://console.vectara.com) for API key management.\n",
      "- **Authentication**: Implement Bearer Token authentication using your API key.\n",
      "\n",
      "#### Step 2: Index Your Documents\n",
      "- **Prepare Data**: Format your documents for indexing, optionally including metadata for enhanced retrieval.\n",
      "- **Indexing API**: Use the indexing endpoint:\n",
      "  ```http\n",
      "  POST /v1/corpora/{corpusId}/docs\n",
      "  ```\n",
      "  Replace `{corpusId}` with your corpus key. Include documents in JSON format along with metadata, if needed.\n",
      "\n",
      "#### Step 3: Query for Dense Retrieval\n",
      "- **Formulate Queries**: Craft queries for semantic relevance.\n",
      "- **Query Endpoint**:\n",
      "  ```http\n",
      "  POST /v1/corpora/{corpusId}/query\n",
      "  ```\n",
      "  - Set the `query` field with your search term.\n",
      "  - Adjust parameters like `limit` for result quantity and `context_configuration` for contextual output.\n",
      "- **Headers**: Use Bearer Token authentication in requests.\n",
      "\n",
      "#### Best Practices\n",
      "- **Refine with Metadata**: Use metadata for more precise filtering.\n",
      "- **Tuning**: Balance semantic and lexical search using parameters like `lexical_interpolation`.\n",
      "- **Response Management**: Configure settings to enhance meaning in responses.\n",
      "\n",
      "For detailed configuration and experimentation, refer to Vectara's [API Reference](https://docs.vectara.com/docs/api-reference/indexing-apis/indexing) and tools such as the Postman Collection provided by Vectara for simplified API testing.\n"
     ]
    }
   ],
   "source": [
    "query = \"Explain how dense retrieval works theoretically, and show me how to implement it with Vectara.\"\n",
    "print(f\"User: {query}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "response = chat_with_agent(\n",
    "    orchestrator_key,\n",
    "    orchestrator_session_key,\n",
    "    query,\n",
    "    show_events=True\n",
    ")\n",
    "\n",
    "print(f\"Agent Response:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wr04o4ujvoh",
   "metadata": {},
   "source": [
    "### Test 4: Current Information Question (Web Search)\n",
    "\n",
    "This question asks about recent developments that wouldn't be in our indexed research papers or documentation, demonstrating the value of the web search sub-agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7elqfu25p1k",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What are the latest developments in RAG technology in 2025? Are there any new techniques or frameworks that have emerged recently?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "------ All Events ------\n",
      "  Event type: input_message\n",
      "  Event type: tool_input\n",
      "    Tool: web_search_expert\n",
      "    Tool input: Find the latest developments in Retrieval-Augmented Generation (RAG) technology as of 2025. Look for new techniques, frameworks, advancements in algorithms, and any notable academic or industry applications that have emerged recently.\n",
      "  Event type: tool_output\n",
      "    Tool: web_search_expert\n",
      "    Tool output: Recent advancements in Retrieval-Augmented Generation (RAG) technology as of 2025 indicate significant developments in both the academic and industrial spheres. Here are some key points:\n",
      "\n",
      "1. **Real-Time Retrieval and Hybrid Search**: RAG technology is being enhanced with capabilities for real-time retrieval and hybrid search. This allows AI systems to incorporate up-to-date information rapidly, improving the accuracy and relevance of generated content. The use of hybrid search techniques combines structured and unstructured search methods to yield more precise results [source](https://www.signitysolutions.com/blog/trends-in-active-retrieval-augmented-generation).\n",
      "\n",
      "2. **Personalized and Multimodal RAG**: The integration of personalized retrieval methods enables RAG systems to tailor outputs specifically to user preferences or contexts. Additionally, the use of multimodal capabilities allows the technology to handle different types of data, such as text, images, and audio simultaneously, which enhances the scope and applicability of RAG in various fields [source](https://www.signitysolutions.com/blog/trends-in-active-retrieval-augmented-generation).\n",
      "\n",
      "3. **On-Device AI Integration**: A prominent trend involves the integration of RAG technologies directly onto devices, which facilitates more efficient and secure data processing. This helps in reducing latency issues associated with cloud-based processing and enhances user privacy by keeping data processing local [source](https://www.signitysolutions.com/blog/trends-in-active-retrieval-augmented-generation).\n",
      "\n",
      "4. **RAG Market Growth**: The RAG market is projected to surpass $40 billion by 2035, largely due to the accelerating integration of AI technologies in enterprises. This growth reflects the increasing reliance on RAG for decision-making processes and content generation across various industries [source](https://www.businesswire.com/news/home/20251010008494/en/Retrieval-Augmented-Generation-RAG-Industry-Report-2025-2035-Global-RAG-Market-to-Surpass-%2440-Billion-by-2035-as-Enterprises-Accelerate-AI-Integration---ResearchAndMarkets.com).\n",
      "\n",
      "These developments underscore the transformative potential of RAG as an intelligence layer within AI systems, enhancing their ability to generate relevant and accurate outputs while reducing the risk of hallucinations in AI-generated content and improving user engagement through personalized and multimodal interactions....\n",
      "  Event type: agent_output\n",
      "--------------------\n",
      "Agent Response:\n",
      "As of 2025, Retrieval-Augmented Generation (RAG) technology has seen several notable advancements:\n",
      "\n",
      "1. **Real-Time Retrieval and Hybrid Search**: RAG systems are now capable of real-time retrieval, allowing them to incorporate the latest information quickly and improve the relevance of generated content. Hybrid search techniques that combine structured and unstructured data sources are being utilized to yield more accurate results.\n",
      "\n",
      "2. **Personalized and Multimodal RAG**: Enhancements in RAG systems include personalized retrieval, which tailors outputs to individual user preferences and contexts. Additionally, the integration of multimodal capabilities allows RAG systems to handle various data types—such as text, images, and audio—simultaneously, expanding their applicability across different domains.\n",
      "\n",
      "3. **On-Device AI Integration**: A significant trend involves integrating RAG technology directly onto user devices. This reduces latency traditionally associated with cloud-based processing and enhances data privacy by keeping data processing local.\n",
      "\n",
      "4. **Market Growth**: The RAG market is anticipated to surpass $40 billion by 2035, driven by the accelerating use of AI in enterprise environments. This growth reflects a broader incorporation of RAG into decision-making processes and content generation tasks across industries.\n",
      "\n",
      "These developments illustrate RAG's evolving role as a crucial component in AI systems, enhancing their ability to produce accurate, contextually relevant outputs and supporting user engagement through personalized and multi-dimensional interactions.\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the latest developments in RAG technology in 2025? Are there any new techniques or frameworks that have emerged recently?\"\n",
    "print(f\"User: {query}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "response = chat_with_agent(\n",
    "    orchestrator_key,\n",
    "    orchestrator_session_key,\n",
    "    query,\n",
    "    show_events=True\n",
    ")\n",
    "\n",
    "print(f\"Agent Response:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "If you want to delete the agents created in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted agent: agt_ai_research_orchestrator_522e\n",
      "Deleted agent: agt_research_paper_analyst_c526\n",
      "Deleted agent: agt_documentation_expert_f9f7\n",
      "Deleted agent: agt_web_search_expert_5b19\n"
     ]
    }
   ],
   "source": [
    "# Delete parent first since it depends on sub-agents\n",
    "\n",
    "agents_to_delete = [\n",
    "    orchestrator_key,\n",
    "    research_analyst_key,\n",
    "    docs_expert_key,\n",
    "    web_search_expert_key\n",
    "]\n",
    "\n",
    "for agent_key in agents_to_delete:\n",
    "    if agent_key:\n",
    "        response = requests.delete(f\"{BASE_URL}/agents/{agent_key}\", headers=headers)\n",
    "        if response.status_code == 204:\n",
    "            print(f\"Deleted agent: {agent_key}\")\n",
    "        else:\n",
    "            print(f\"Error deleting {agent_key}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f10017f-bc24-4360-814d-5c3838f30afd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
